<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>牛犊记</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://calfgz.github.io/"/>
  <updated>2020-05-12T08:00:31.406Z</updated>
  <id>http://calfgz.github.io/</id>
  
  <author>
    <name>calfgz</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>微服务API网关-APISIX初探</title>
    <link href="http://calfgz.github.io//blog/2020/05/api-gateway-apisix.html"/>
    <id>http://calfgz.github.io//blog/2020/05/api-gateway-apisix.html</id>
    <published>2020-05-12T07:55:34.000Z</published>
    <updated>2020-05-12T08:00:31.406Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="资料">资料</span></h2><ul><li><a href="https://github.com/apache/incubator-apisix/" target="_blank" rel="noopener">Github</a></li><li><a href="https://www.apiseven.com/" target="_blank" rel="noopener">商业版</a></li><li><a href="https://github.com/apache/incubator-apisix-docker" target="_blank" rel="noopener">apisix-docker github</a></li></ul><h2><span id="apisix-简介">APISIX 简介</span></h2><p>APISIX 是一个云原生、高性能、可扩展的微服务 API 网关。</p><p>它是基于 OpenResty 和 etcd 来实现，和传统 API 网关相比，APISIX 具备动态路由和插件热加载，特别适合微服务体系下的 API 管理。</p><p>你可以把 Apache APISIX 当做流量入口，来处理所有的业务数据，包括动态路由、动态上游、动态证书、A/B 测试、金丝雀发布(灰度发布)、蓝绿部署、限流限速、抵御恶意攻击、监控报警、服务可观测性、服务治理等。</p><h2><span id="apisix-发展历程">APISIX 发展历程</span></h2><ul><li>2019-06-04    0.4(Non-ASF Release)</li><li>2019-10-17    进入Apache</li><li>2019-11-25    0.9 Release</li><li>2020-01-15    1.0 </li><li>2020-02-24    1.1</li><li>2020-04-20    1.2</li></ul><h2><span id="apache-apisix-和-kong-的比较">Apache APISIX 和 Kong 的比较</span></h2><h3><span id="api-网关核心功能点两者均已覆盖">API 网关核心功能点，两者均已覆盖</span></h3><table><thead><tr><th style="text-align:left"><strong>功能</strong></th><th style="text-align:left"><strong>Apache APISIX</strong></th><th style="text-align:left"><strong>KONG</strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>动态上游</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>动态路由</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>健康检查和熔断器</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>动态SSL证书</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>七层和四层代理</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>分布式追踪</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>自定义插件</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>REST API</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr><tr><td style="text-align:left"><strong>CLI</strong></td><td style="text-align:left">支持</td><td style="text-align:left">支持</td></tr></tbody></table><h3><span id="apache-apisix-的优势-来自apisix数据">Apache APISIX 的优势 (来自APISIX数据)</span></h3><table><thead><tr><th style="text-align:left"><strong>功能</strong></th><th style="text-align:left"><strong>Apache APISIX</strong></th><th style="text-align:left"><strong>KONG</strong></th></tr></thead><tbody><tr><td style="text-align:left">项目归属</td><td style="text-align:left">Apache 软件基金会</td><td style="text-align:left">Kong Inc.</td></tr><tr><td style="text-align:left">技术架构</td><td style="text-align:left">Nginx + etcd</td><td style="text-align:left">Nginx + postgres</td></tr><tr><td style="text-align:left">交流渠道</td><td style="text-align:left">微信群、QQ群、邮件列表、Github、meetup</td><td style="text-align:left">Github、论坛、freenode</td></tr><tr><td style="text-align:left">单核 QPS (开启限流和prometheus插件)</td><td style="text-align:left">18000</td><td style="text-align:left">1700</td></tr><tr><td style="text-align:left">平均延迟</td><td style="text-align:left">0.2 毫秒</td><td style="text-align:left">2 毫秒</td></tr><tr><td style="text-align:left">支持 Dubbo 代理</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">配置回滚</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">支持生命周期的路由</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">插件热更新</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">用户自定义：负载均衡算法、路由</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">resty <--> gRPC 转码</--></td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">支持 Tengine 作为运行时</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">MQTT 协议支持</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">配置生效时间</td><td style="text-align:left">事件通知，低于1毫秒更新</td><td style="text-align:left">定期轮询，5 秒</td></tr><tr><td style="text-align:left">自带控制台</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">对接外部身份认证服务</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">配置中心高可用(HA)</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">指定时间窗口的限速</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr><tr><td style="text-align:left">支持任何 Nginx 变量做路由条件</td><td style="text-align:left">是</td><td style="text-align:left">否</td></tr></tbody></table><h2><span id="apisix-安装部署">APISIX 安装部署</span></h2><p>基于docker安装部署</p><h4><span id="安装etcd-server">安装Etcd Server</span></h4><p>拉取etcd镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull bitnami/etcd:3.3.13-r80</span><br></pre></td></tr></table></figure></p><p>运行etcd容器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run --name etcd-server \</span><br><span class="line">-p 2379:2379 \</span><br><span class="line">-p 2380:2380  \</span><br><span class="line">--env ALLOW_NONE_AUTHENTICATION=yes \</span><br><span class="line">-d bitnami/etcd:3.3.13-r80</span><br></pre></td></tr></table></figure></p><p>测试etcd<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ docker exec -it etcd-server bash</span><br><span class="line">$ etcdctl put test &quot;hello world!&quot;</span><br><span class="line">OK</span><br><span class="line">$ etcdctl get test</span><br><span class="line">test</span><br><span class="line">hello world!</span><br><span class="line">$ etcdctl del test</span><br><span class="line">1</span><br><span class="line">$ etcdctl get test</span><br><span class="line">$</span><br></pre></td></tr></table></figure></p><h4><span id="安装apisix">安装APISIX</span></h4><p>拉取apisix镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull apache/apisix:1.2-centos</span><br></pre></td></tr></table></figure></p><p>修改配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">注释掉 allow_admin ip限制</span><br><span class="line">  # allow_admin:                  # http://nginx.org/en/docs/http/ngx_http_access_module.html#allow</span><br><span class="line">  #  - 127.0.0.0/24              # If we don&apos;t set any IP list, then any IP access is allowed by default.</span><br><span class="line">  #   - &quot;::/64&quot;</span><br><span class="line">  # port_admin: 9180              # use a separate port</span><br><span class="line"></span><br><span class="line">修改etcd IP为etcd 容器ip</span><br><span class="line">etcd:</span><br><span class="line">  host:                           # it&apos;s possible to define multiple etcd hosts addresses of the same etcd cluster.</span><br><span class="line">    - &quot;http://172.17.0.6:2379&quot;     # multiple etcd address</span><br><span class="line">  prefix: &quot;/apisix&quot;               # apisix configurations prefix</span><br><span class="line">  timeout: 3                      # 3 seconds</span><br></pre></td></tr></table></figure></p><p>运行apisix镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run --name apisix-api-gateway \</span><br><span class="line">-v `pwd`/config/apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml \</span><br><span class="line">-v `pwd`/logs/apisix_log:/usr/local/apisix/logs  \</span><br><span class="line">-p 9080:9080 \</span><br><span class="line">-p 9443:9443 \</span><br><span class="line">-d apache/apisix:1.2-centos</span><br></pre></td></tr></table></figure></p><h3><span id="apisix配置">APISIX配置</span></h3><p>更详细的apisix api可查看<a href="https://github.com/apache/incubator-apisix/" target="_blank" rel="noopener">官网</a>,这里仅介绍基本的使用。apisix api也可通过<a href="https://github.com/apache/incubator-apisix-docker" target="_blank" rel="noopener">apisix-dashboard</a>进行可视化配置，更加方便。 <code>dashboard 缺陷:</code> 目前dashboard还存在一些不完善的地方，一些插件的函数配置等不可直接编辑，还是得通过apisix api进行。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">#、常规配置 demo （注：IP、节点等都改为自己的）</span><br><span class="line">## 1、配置upstreams</span><br><span class="line">curl http://127.0.0.1/apisix/admin/upstreams/001 -X PUT -i -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;type&quot;:&quot;roundrobin&quot;,</span><br><span class="line">    &quot;nodes&quot;:&#123;</span><br><span class="line">        &quot;127.0.0.1:9090&quot;:1</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;desc&quot;:&quot;oss&quot;</span><br><span class="line">&#125;</span><br><span class="line">&apos;</span><br><span class="line"></span><br><span class="line">## 2、 配置service （可以将各类插件编辑为service，配合route使用。这只是小编写的其中一个插件的demo，可按需扩展）</span><br><span class="line">curl http://127.0.0.1/apisix/admin/services/001 -X PUT -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;plugins&quot;:&#123;</span><br><span class="line">        &quot;serverless-pre-function&quot;:&#123;</span><br><span class="line">            &quot;phase&quot;:&quot;rewrite&quot;,</span><br><span class="line">            &quot;functions&quot;:[&quot;</span><br><span class="line">                return function()</span><br><span class="line">                    local authorization = ngx.var.cookie_Authorization</span><br><span class="line">                    ngx.req.set_header(\&quot;Authorization\&quot;, authorization)</span><br><span class="line">                end&quot;]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;proxy-rewrite&quot;:&#123;</span><br><span class="line">            &quot;enable_websocket&quot;:true</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;upstream_id&quot;:&quot;001&quot;,</span><br><span class="line">    &quot;desc&quot;:&quot;oss&quot;</span><br><span class="line">&#125;</span><br><span class="line">&apos;</span><br><span class="line"></span><br><span class="line">## 3、配置route</span><br><span class="line">curl http://127.0.0.1/apisix/admin/routes/001 -X PUT -i -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;uris&quot;:[&quot;/*&quot;],</span><br><span class="line">    &quot;hosts&quot;:[</span><br><span class="line">        &quot;local-sandbox.com&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;upstream_id&quot;:&quot;001&quot;,</span><br><span class="line">    &quot;service_id&quot;: &quot;001&quot;,</span><br><span class="line">    &quot;desc&quot;:&quot;oss&quot;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line">## 4、删除route</span><br><span class="line">curl http://127.0.0.1/apisix/admin/routes/001 -X DELETE -i</span><br><span class="line"></span><br><span class="line">## 5、配置上游节点负载均衡+健康检查demo</span><br><span class="line">curl http://127.0.0.1/apisix/admin/routes/015 -X PUT -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;uris&quot;: [&quot;/*&quot;],</span><br><span class="line">    &quot;hosts&quot;: [&quot;local-web.com&quot;],</span><br><span class="line">    &quot;plugins&quot;: &#123;&#125;,</span><br><span class="line">    &quot;upstream&quot;: &#123;</span><br><span class="line">         &quot;nodes&quot;: &#123;</span><br><span class="line">            &quot;127.0.0.1:8081&quot;: 1,</span><br><span class="line">            &quot;127.0.0.1:8082&quot;: 1</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;type&quot;: &quot;roundrobin&quot;,</span><br><span class="line">        &quot;retries&quot;: 2,</span><br><span class="line">        &quot;checks&quot;: &#123;</span><br><span class="line">            &quot;active&quot;: &#123;</span><br><span class="line">                &quot;http_path&quot;: &quot;/status&quot;,</span><br><span class="line">                &quot;host&quot;: &quot;local-web.com&quot;,</span><br><span class="line">                &quot;healthy&quot;: &#123;</span><br><span class="line">                    &quot;interval&quot;: 2,</span><br><span class="line">                    &quot;successes&quot;: 1</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;unhealthy&quot;: &#123;</span><br><span class="line">                    &quot;interval&quot;: 1,</span><br><span class="line">                    &quot;http_failures&quot;: 2</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;req_headers&quot;: [&quot;User-Agent: curl/7.29.0&quot;]</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;passive&quot;: &#123;</span><br><span class="line">                &quot;healthy&quot;: &#123;</span><br><span class="line">                    &quot;http_statuses&quot;: [200, 201],</span><br><span class="line">                    &quot;successes&quot;: 3</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;unhealthy&quot;: &#123;</span><br><span class="line">                    &quot;http_statuses&quot;: [500],</span><br><span class="line">                    &quot;http_failures&quot;: 3,</span><br><span class="line">                    &quot;tcp_failures&quot;: 3</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><h3><span id="优点">优点</span></h3><ul><li>性能优越 (未经验证)</li><li>国内开发，能方便联系作者，沟通方便，有中文文档</li><li>社区活跃，有QQ群沟通，反馈快</li></ul><h3><span id="缺点">缺点</span></h3><ul><li>不够成熟 (有收费的商业版)</li><li>功能还不稳定,bug比较多</li><li>业内生产环境使用很少</li><li>没有经过大型应用验证过</li><li>文档(教程)比较欠缺</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;资料&quot;&gt;资料&lt;/span&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/apache/incubator-apisix/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github&lt;/a&gt;&lt;/li
      
    
    </summary>
    
      <category term="微服务" scheme="http://calfgz.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="微服务" scheme="http://calfgz.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="网站架构" scheme="http://calfgz.github.io/tags/%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84/"/>
    
      <category term="API网关" scheme="http://calfgz.github.io/tags/API%E7%BD%91%E5%85%B3/"/>
    
  </entry>
  
  <entry>
    <title>NIO学习</title>
    <link href="http://calfgz.github.io//blog/2020/02/java-nio.html"/>
    <id>http://calfgz.github.io//blog/2020/02/java-nio.html</id>
    <published>2020-02-29T10:18:07.000Z</published>
    <updated>2020-03-01T07:47:47.186Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="背景">背景</span></h2><p>Java NIO(New IO) 是从Java1.4版本开始引入的一个新的IO API, 可以代替标准的Java IO API. NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。</p><h2><span id="nio与io的主要区别">NIO与IO的主要区别</span></h2><table><thead><tr><th style="text-align:left">IO</th><th style="text-align:left">NIO</th></tr></thead><tbody><tr><td style="text-align:left">面向流 (Stream Oriented)</td><td style="text-align:left">面向缓冲区(Buffer Oriented)</td></tr><tr><td style="text-align:left">阻塞IO (Blocking IO)</td><td style="text-align:left">非阻塞IO (Non Blocking IO)</td></tr><tr><td style="text-align:left">(无)</td><td style="text-align:left">选择器 (Selectors)</td></tr></tbody></table><h2><span id="通道和缓冲区">通道和缓冲区</span></h2><p>Java NIO系统的核心在于：通道(Channel)和缓冲区(Buffer)。通道表示打开到IO设备(例如：文件、套接字)的连接。若需要使用NIO系统，需要获取用于连接IO设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。<br>简而言之，Channel负责传输，Buffer负责存储。</p><h3><span id="缓冲区buffer">缓冲区(Buffer)</span></h3><p>缓冲区：一个用于特定基本数据类型的容器。由java.nio包定义的，所有缓冲区都是Buffer抽象类的子类。<br>Java NIO中的Buffer主要用于与NIO通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的。</p><p>Buffer就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean除外)，有以下Buffer常用子类：</p><ul><li>ByteBuffer</li><li>CharBuffer</li><li>ShortBuffer</li><li>IntBuffer</li><li>LongBuffer</li><li>FloatBuffer</li><li>DoubleBuffer</li></ul><p>上述Buffer类他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个Buffer对象：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> XxxBuffer <span class="title">allocate</span><span class="params">(<span class="keyword">int</span> capacity)</span></span>;    <span class="comment">//创建一个容量为capacity的Buffer对象</span></span><br></pre></td></tr></table></figure></p><h4><span id="缓冲区的基本属性">缓冲区的基本属性</span></h4><p>Buffer中的重要概念</p><ul><li>容量(capacity):表示Buffer最大数据容量，缓冲区容量不能为负，并且创建后不能一更改。</li><li>限制(limit):第一个不应该读取或写入的数据的索引，即位于limit后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。</li><li>位置(position):下一个要读取或写入的数据的索引。缓冲区的位置不能为负，不能大于其限制。</li><li>标记(mark)与重置(reset):标记是一个索引，通过Buffer中的mark()方法指定Buffer中一个特定的position，之后可以通过调用reset()方法恢复到这个position。</li><li>标记、位置、限制、容量遵守以下不变式: 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity</li></ul><h4><span id="buffer的常用方法">Buffer的常用方法</span></h4><table><thead><tr><th style="text-align:left">方法</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">Buffer clear()</td><td style="text-align:left">清空缓冲区并返回对缓冲区的引用</td></tr><tr><td style="text-align:left">Buffer flip()</td><td style="text-align:left">将缓冲区的界限设置为当前位置，并将当前位置重置为0</td></tr><tr><td style="text-align:left">int capacity()</td><td style="text-align:left">返回Buffer的capacity大小</td></tr><tr><td style="text-align:left">boolean hasReaining()</td><td style="text-align:left">判断缓冲区中是否还有元素</td></tr><tr><td style="text-align:left">int limit()</td><td style="text-align:left">返回Buffer的界限(limit)的位置</td></tr><tr><td style="text-align:left">Buffer limit(int n)</td><td style="text-align:left">将设置缓冲区界限为n，并返回一个具有新limit的缓冲区对象</td></tr><tr><td style="text-align:left">Buffer mark()</td><td style="text-align:left">对缓冲区设置标记</td></tr><tr><td style="text-align:left">int position()</td><td style="text-align:left">返回缓冲区的当前位置position</td></tr><tr><td style="text-align:left">Buffer position(int n)</td><td style="text-align:left">将设置缓冲区的当前位置为n，并返回修改后的Buffer对象</td></tr><tr><td style="text-align:left">int remaining()</td><td style="text-align:left">返回position和limit之间的元素个数</td></tr><tr><td style="text-align:left">Buffer reset()</td><td style="text-align:left">将位置position转到以前设置的mark所在位置</td></tr><tr><td style="text-align:left">Buffer rewind()</td><td style="text-align:left">将位置设置为0，取消设置的mark</td></tr></tbody></table><h4><span id="缓冲区的数据操作">缓冲区的数据操作</span></h4><p>Buffer所有子类提供了两个用于数据操作的方法：get()与put()方法。</p><ul><li><p>获取Buffer中的数据</p><ul><li>get(): 读取单个字节</li><li>get(byte[] dst): 批量读取多个字节到dst中</li><li>get(int index): 读取指定索引位置的字节(不会移动position)</li></ul></li><li><p>写入数据到Buffer中</p><ul><li>put(byte b): 将给定单个字节写入缓冲区的当前位置</li><li>put(byte[] src): 将src中的字节写入缓冲区的当前位置</li><li>put(int index, byte b): 将指定字节写入缓冲区的索引位置(不会移动position)</li></ul></li></ul><h4><span id="直接与非直接缓冲区">直接与非直接缓冲区</span></h4><ul><li>非直接缓冲区：磁盘 - 物理内存 - JVM内存 - 应用程序   物理内存和JVM内存会进行copy操作</li><li>直接缓冲区：直接在物理内存中分配单独的空间，物理内存和JVM内存只是映射到该文件</li><li>字节缓冲区要么是直接的，要么是非直接的。如果为直接字节缓冲区，则Java虚拟机会尽最大努力直接在此缓冲区上执行本机I/O操作。也就是说，在每次调用基础操作系统的一个本机I/O操作之前(或之后)，虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中(或从中间缓冲区中复制内容)</li><li>直接字节缓冲区可以通过调用此类的allocateDirect()工厂方法来创建。此方法返回的缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不影响。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机I/O操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。</li><li>直接字节缓冲区还可以通过FileChannel的map()方法将文件区域直接映射到内存中来创建。该方法返回MappedByteBuffer。Java平台的实现有助于通过JNI从本机代码创建直接字节缓冲区。如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。</li><li>字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其 isDirect() 方法来确定。提供此方法是为了能够在性能关键型代码中执行显式缓冲区管理。</li></ul><h3><span id="通道channel">通道(Channel)</span></h3><p>通道(Channel)：由java.nio.channels包定义的。Channel表示IO源与目标打开的连接。Channel类似于传统的“流”。只不过Channel本身不能访问数据，Channel只能与Buffer进行交互。</p><p>Java为Channel接口提供的最主要实现类如下：</p><ul><li>FileChannel: 用于读取、写入、映射和操作文件的通道。</li><li>DatagramChannel: 通过UDP读写网络中的数据通道。</li><li>SocketChannel: 通过TCP读写网络中的数据通道。</li><li>ServerSocketChannel: 可以监听新进来的TCP链接，对每一个新进来的连接都会创建一个SocketChannel。</li></ul><h4><span id="获取通道">获取通道</span></h4><p>获取通道的一种方式是对支持通道的对象调用getChannel()方法。支持通道的类如下：</p><ul><li>FileInputStream</li><li>FileOutputStream</li><li>RandomAccessFile</li><li>DatagramSocket</li><li>Socket</li><li>ServerSocket</li></ul><p>获取通道的其他方式是使用Files类的静态方法newByteChannel()获取字节通道。或者通过通道的静态方法open()打开并返回指定通道。</p><p>通道的数据传输<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将Buffer中的数据写入Channel中</span></span><br><span class="line"><span class="keyword">int</span> bytesWritten = inChannel.write(buf);</span><br><span class="line"></span><br><span class="line"><span class="comment">//从Channel读取数据到Buffer中</span></span><br><span class="line"><span class="keyword">int</span> bytesRead = inChannel.read(buf);</span><br></pre></td></tr></table></figure></p><p>分散读取(Scattering Reads) 是指从Channel中读取的数据“分散”到多个Buffer中。<br>注意：按照缓冲区的顺序，从Channel中读取的数据依次将Buffer填满。</p><p>聚集写入(Gathering Writes) 是指将多个Buffer中的数据“聚集”到Channel。<br>注意：按照缓冲区的顺序，写入position和limit之间的数据到Channel。</p><p>transferFrom()将数据从源通道传输到其它Channel中:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">RandomAccessFile fromFile = <span class="keyword">new</span> RandomAccessFile(<span class="string">"data/fromFile.txt"</span>, <span class="string">"rw"</span>);</span><br><span class="line"><span class="comment">//获取FileChannel</span></span><br><span class="line">FileChannel fromChannel = fromFile.getChannel();</span><br><span class="line"></span><br><span class="line">RandomAccessFile toFile = <span class="keyword">new</span> RandomAccessFile(<span class="string">"data/toFile.txt"</span>, <span class="string">"rw"</span>);</span><br><span class="line">FileChannel toChannel = toFile.getChannel();</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义传输位置</span></span><br><span class="line"><span class="keyword">long</span> positon = <span class="number">0L</span>;</span><br><span class="line"><span class="comment">//最多传输的字节数</span></span><br><span class="line"><span class="keyword">long</span> count = fromChannel.size();</span><br><span class="line"></span><br><span class="line"><span class="comment">//将数据从源通道传输到另一个通道</span></span><br><span class="line">toChannel.transferFrom(fromChannel, count, position);</span><br></pre></td></tr></table></figure></p><p>transferTo()将数据从源通道传输到其它Channel中：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">RandomAccessFile fromFile = <span class="keyword">new</span> RandomAccessFile(<span class="string">"data/fromFile.txt"</span>, <span class="string">"rw"</span>);</span><br><span class="line"><span class="comment">//获取FileChannel</span></span><br><span class="line">FileChannel fromChannel = fromFile.getChannel();</span><br><span class="line"></span><br><span class="line">RandomAccessFile toFile = <span class="keyword">new</span> RandomAccessFile(<span class="string">"data/toFile.txt"</span>, <span class="string">"rw"</span>);</span><br><span class="line">FileChannel toChannel = toFile.getChannel();</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义传输位置</span></span><br><span class="line"><span class="keyword">long</span> positon = <span class="number">0L</span>;</span><br><span class="line"><span class="comment">//最多传输的字节数</span></span><br><span class="line"><span class="keyword">long</span> count = fromChannel.size();</span><br><span class="line"></span><br><span class="line"><span class="comment">//将数据从源通道传输到另一个通道</span></span><br><span class="line">fromChannel.transferTo(position, count, toChannel);</span><br></pre></td></tr></table></figure></p><h4><span id="filechannel的常用方法">FileChannel的常用方法</span></h4><table><thead><tr><th style="text-align:left">方法</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">int read(ByteBuffer dst)</td><td style="text-align:left">从Channel中读取数据到ByteBuffer</td></tr><tr><td style="text-align:left">long read(ByteBuffer[] dsts)</td><td style="text-align:left">将从Channel中的数据“分散”到ByteBuffer[]</td></tr><tr><td style="text-align:left">int write(ByteBuffer src)</td><td style="text-align:left">将ByteBuffer中的数据写入到Channel</td></tr><tr><td style="text-align:left">long write(ByteBuffer[] srcs)</td><td style="text-align:left">将ByteBuffer[]中的数据“聚集”到Channel</td></tr><tr><td style="text-align:left">long position()</td><td style="text-align:left">返回此通道的文件位置</td></tr><tr><td style="text-align:left">FileChannel position(long p)</td><td style="text-align:left">设置此通道的文件位置</td></tr><tr><td style="text-align:left">long size()</td><td style="text-align:left">返回此通道的文件的当前大小</td></tr><tr><td style="text-align:left">FileChannel truncate(long s)</td><td style="text-align:left">将此通道的文件截取为给定大小</td></tr><tr><td style="text-align:left">void force(boolean metaData)</td><td style="text-align:left">强制将所有对此通道的文件更新写入到存储设备中</td></tr></tbody></table><h2><span id="nio的非阻塞式网络通信">NIO的非阻塞式网络通信</span></h2><h3><span id="阻塞与非阻塞">阻塞与非阻塞</span></h3><ul><li><p>传统的 IO 流都是阻塞式的。也就是说，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务。因此，在完成网络通信进行 IO 操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降。</p></li><li><p>Java NIO 是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。因此，NIO 可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端。</p></li></ul><h3><span id="选择器selector">选择器(Selector)</span></h3><p>选择器（Selector） 是 SelectableChannle 对象的多路复用器，Selector 可以同时监控多个 SelectableChannel 的 IO 状况，也就是说，利用 Selector 可使一个单独的线程管理多个 Channel。Selector 是非阻塞 IO 的核心。</p><p>创建Selector: 通过调用Selector.open()方法创建一个Selector。<br>向选择器注册通道：SelectableChannel.register(Selector sel, int ops)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建一个Socket套接字</span></span><br><span class="line">Socket socket = <span class="keyword">new</span> Socket(InetAddress.getByName(<span class="string">"127.0.0.1"</span>), <span class="number">9898</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取SocketChannel</span></span><br><span class="line">SocketChannel channel = socket.getChannel();</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建选择器</span></span><br><span class="line">Selector selector = Selector.open();</span><br><span class="line"></span><br><span class="line"><span class="comment">//将SocketChannel切换到非阻塞模式</span></span><br><span class="line">channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//向Selector注册Channel</span></span><br><span class="line">SelectionKey key = channel.register(selector, SelectionKey.OP_READ);</span><br></pre></td></tr></table></figure><ul><li>当调用register(Selector sel, int ops)将通道注册选择器时，选择器对通道的监听事件，需要通过第二个参数ops指定。</li><li>可以监听的事件类型(可使用SelectionKey的四个常量表示):<ul><li>读: SelectionKey.OP_READ</li><li>写: SelectionKey.OP_WRITE</li><li>连接: SelectionKey.OP_CONNECT</li><li>接收: SelectionKey.OP_ACCEPT</li></ul></li><li>若注册时不止监听一个事件，则可以使用“位或|”操作符连接。</li><li>SelectionKey: 表示SelectableChannel和Selector之间的注册关系。每次向选择器注册通道时就会选择一个事件。选择键包含两个表示为整数值的操作集。操作集的每一位都表示该键的通道所支持的一类可选择操作。</li></ul><h4><span id="管道pipe">管道(Pipe)</span></h4><p>Java NIO管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。</p><p>向管道写数据:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    String str = <span class="string">"测试数据"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建管道</span></span><br><span class="line">    Pipe pipe = Pipe.open();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向管道写输入</span></span><br><span class="line">    Pipe.SinkChannel sinkChannle = pipe.sink();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过SinkChannel的write()方法写数据</span></span><br><span class="line">    ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    buf.clear();</span><br><span class="line">    buf.put(str.getBytes());</span><br><span class="line">    buf.flip();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(buf.hasRemaining()) &#123;</span><br><span class="line">        sinkChannel.write(buf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//从管道读取数据</span></span><br><span class="line">    Pipe.SourceChannel sourceChannel = pipe.source();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用source通道的read()方法来读取数据</span></span><br><span class="line">    ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    sourceChannel.read(buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;背景&quot;&gt;背景&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Java NIO(New IO) 是从Java1.4版本开始引入的一个新的IO API, 可以代替标准的Java IO API. NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲
      
    
    </summary>
    
      <category term="Java" scheme="http://calfgz.github.io/categories/Java/"/>
    
    
      <category term="Java" scheme="http://calfgz.github.io/tags/Java/"/>
    
      <category term="NIO" scheme="http://calfgz.github.io/tags/NIO/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot应用通用的Docker容器镜像</title>
    <link href="http://calfgz.github.io//blog/2019/08/docker-springboot-app.html"/>
    <id>http://calfgz.github.io//blog/2019/08/docker-springboot-app.html</id>
    <published>2019-08-06T13:59:22.000Z</published>
    <updated>2019-08-06T14:30:24.617Z</updated>
    
    <content type="html"><![CDATA[<h3><span id="普通的docker">普通的Docker</span></h3><p>通常情况下制作springboot应用的镜像时，都是将jar包及配置文件直接Add或Copy进入镜像中，把代码有配置文件等都集成到镜像中，这种情况对于发布线上版本来说是很方便的。<br>Dockerfile如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FROM openjdk:8-jdk-alpine</span><br><span class="line">VOLUME /tmp</span><br><span class="line">ADD target/springboot-demo-1.0.jar /app.jar</span><br><span class="line">ADD src/config/*.yml /config/</span><br><span class="line">RUN sh -c &apos;touch /app.jar&apos;</span><br><span class="line">ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;-server&quot;, &quot;app.jar&quot;]</span><br></pre></td></tr></table></figure></p><p>但对于某些场合需要频繁修改更新jar包的情况下，比如在开发或测试环境来说，每次修改更新都需要重新制作新的镜像，对于镜像的发布和部署就比较麻烦了。</p><h3><span id="通用的springboot应用docker镜像">通用的SpringBoot应用Docker镜像</span></h3><p>为了在开发或者测试环境中快速的部署代码更新，有种方法是可以直接进入容器中替换新的jar包和配置文件，然后重启容器。还有一种更简单的方式就是直接在宿主机中修改jar包和配置文件，将宿主机中的jar包和配置文件通过容器卷的方式跟容器共享，这样需要更新时只要在宿主机上更新代码后直接重启容器即可。 我们制作了一个适用于所有SpringBoot应用的Docker镜像，在创建容器时将需要的jar包和配置文件与容器共享即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># springboot应用通用的docker容器, 把jar包和配置文件放于宿主机中，用容器卷的方式挂载到容器中，主要用于开发和测试环境，代码更新后频繁生成新的镜像。</span><br><span class="line"></span><br><span class="line">FROM openjdk:8-jdk-alpine</span><br><span class="line">ENV TZ &apos;Asia/Shanghai&apos;</span><br><span class="line">ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;-server&quot;, &quot;/app.jar&quot;]</span><br></pre></td></tr></table></figure><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run</span><br><span class="line"> -d #本地运行</span><br><span class="line"> --name container-name #容器名</span><br><span class="line"> -p 8080:8080 #端口</span><br><span class="line"> -v /data/springboot-1.0.jar:app.jar #挂载应用jar包</span><br><span class="line"> -v /data/config:/config #挂载外部配置文件</span><br><span class="line"> --privileged=true #给容器于挂载目录的root权限</span><br><span class="line"> -t springboot-docker:v1.0.0 #镜像</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3&gt;&lt;span id=&quot;普通的docker&quot;&gt;普通的Docker&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;通常情况下制作springboot应用的镜像时，都是将jar包及配置文件直接Add或Copy进入镜像中，把代码有配置文件等都集成到镜像中，这种情况对于发布线上版本来说是很方便的。&lt;b
      
    
    </summary>
    
      <category term="Docker" scheme="http://calfgz.github.io/categories/Docker/"/>
    
    
      <category term="docker" scheme="http://calfgz.github.io/tags/docker/"/>
    
      <category term="springboot" scheme="http://calfgz.github.io/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>Docker安装Redis和Kafka环境</title>
    <link href="http://calfgz.github.io//blog/2019/07/docker-install-redis-kafka.html"/>
    <id>http://calfgz.github.io//blog/2019/07/docker-install-redis-kafka.html</id>
    <published>2019-07-19T14:04:34.000Z</published>
    <updated>2019-07-19T14:26:11.083Z</updated>
    
    <content type="html"><![CDATA[<h3><span id="docker安装redis">Docker安装Redis</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载redis</span></span><br><span class="line">docker pull redis</span><br><span class="line"></span><br><span class="line"><span class="comment">#运行redis</span></span><br><span class="line">docker run --name redis -p 6379:6379 --restart=always -v /data/docker/redis:/data -d redis --appendonly yes</span><br><span class="line">-d     本地运行</span><br><span class="line">-p 6379:6379  本地端口:Docker端口</span><br><span class="line">-v     指定驱动盘</span><br><span class="line">redis  docker的镜像名</span><br><span class="line">--appendonly yes   开启持久化</span><br><span class="line">--name    执行这个运行的名称</span><br><span class="line">--restart=always  Docker启动容器就启动</span><br></pre></td></tr></table></figure><h3><span id="docker安装zookeeper">Docker安装zookeeper</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载zookeeper</span></span><br><span class="line">docker pull zookeeper</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动zookeeper</span></span><br><span class="line">docker run -d --name zookeeper -p 2181:2181 -t zookeeper</span><br></pre></td></tr></table></figure><h3><span id="docker安装kafka">Docker安装Kafka</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载kafka</span></span><br><span class="line">docker pull wurstmeister/kafka:2.11-0.11.0.3</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动kafka</span></span><br><span class="line">docker run -d --name kafka --publish 9092:9092 \</span><br><span class="line">--link zookeeper \</span><br><span class="line">--env KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \</span><br><span class="line">--env KAFKA_ADVERTISED_HOST_NAME=192.168.11.123 \</span><br><span class="line">--env KAFKA_ADVERTISED_PORT=9092  \</span><br><span class="line">--volume /etc/localtime:/etc/localtime \</span><br><span class="line">wurstmeister/kafka:2.11-0.11.0.3</span><br></pre></td></tr></table></figure><h3><span id="docker-其它">Docker 其它</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进入docker容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it containerId /bin/bash</span><br><span class="line"><span class="comment">#如果/bin/bash进不了就换/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看docker容器日志</span></span><br><span class="line">docker logs -t -f --tail=200 containerId</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3&gt;&lt;span id=&quot;docker安装redis&quot;&gt;Docker安装Redis&lt;/span&gt;&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1
      
    
    </summary>
    
      <category term="Docker" scheme="http://calfgz.github.io/categories/Docker/"/>
    
    
      <category term="docker" scheme="http://calfgz.github.io/tags/docker/"/>
    
      <category term="redis" scheme="http://calfgz.github.io/tags/redis/"/>
    
      <category term="kafka" scheme="http://calfgz.github.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Vim操作指令</title>
    <link href="http://calfgz.github.io//blog/2019/04/vim-command.html"/>
    <id>http://calfgz.github.io//blog/2019/04/vim-command.html</id>
    <published>2019-04-28T08:17:50.000Z</published>
    <updated>2019-04-28T08:31:54.295Z</updated>
    
    <content type="html"><![CDATA[<h3><span id="光标移动">光标移动</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">k       上</span><br><span class="line">j       下</span><br><span class="line">h       左</span><br><span class="line">l       右</span><br><span class="line">z       重画屏幕</span><br><span class="line">ctrl+f  跳到下一页</span><br><span class="line">ctrl+b  跳到上一页</span><br></pre></td></tr></table></figure><h3><span id="打开保存与退出-save-amp-exit">打开，保存与退出 （save &amp; exit)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">:w          保存文件 (write file)</span><br><span class="line">:w!         强制保存 (force write)</span><br><span class="line">:q          退出文件 (exit file without save)</span><br><span class="line">:q!         强制退出 (force quite without save)</span><br><span class="line">:e filename     打开一个文件名为 filename 的文件 (open file to edit)</span><br><span class="line">:e! filename    强制打开一个文件，所有未保存的东西会丢失 (force open, drop dirty buffer)</span><br><span class="line">:saveas filename    另存为 filename (save file as filename)</span><br></pre></td></tr></table></figure><h3><span id="编辑指令-edit">编辑指令 (edit)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">a       在光表后插入 (append after cursor)</span><br><span class="line">A       在一行的结尾插入 (append at end of the line)</span><br><span class="line">i       在光标前插入 (insert before cursor)</span><br><span class="line">I       在第一个非空白字符前插入 (insert before first non-blank)</span><br><span class="line">o       光标下面插入一个新行 (open line below)</span><br><span class="line">O       光标上面插入一个新行 (open line above)</span><br><span class="line">x       删除光标下（或者之后）的东西 (delete under and after cursor) #例如 x 就是删除当前光标下，3x 就是删除光标下+光标后 2 位字符</span><br><span class="line">X       删除光标前的字符 (delete before cursor)</span><br><span class="line">d       删除 (delete)</span><br><span class="line">dw      删除单词</span><br><span class="line">dd      删除一行</span><br><span class="line">J       将下一行提到这行来 (join line)</span><br><span class="line">r       替换个字符 (replace characters)</span><br><span class="line">R       替换多个字符 (replace mode – continue replace)</span><br><span class="line">gr      不影响格局布置的替换 (replace without affecting layout)</span><br><span class="line">c       跟 d 键一样，但是删除后进入输入模式 (same as “d” but after delete, in insert mode)</span><br><span class="line">S       删除一行(好像 dd 一样）但是删除后进入输入模式 (same as “dd” but after delete, in insert mode)</span><br><span class="line">s       删除字符，跟(d)一样，但是删除后进入输入模式 (same as “d” but after delete, in insert mode)</span><br><span class="line">s4s     会删除 4 个字符，进入输入模式 (delete 4 char and put in insert mode)</span><br><span class="line">~       更改大小写，大变小，小变大 (change case upper-&gt; lower or lower-&gt;upper)</span><br><span class="line">gu      变成小写 (change to lower case)</span><br><span class="line">#例如 guG 会把光标当前到文件结尾全部变成小写 (change lower case all the way to the end)</span><br><span class="line">gU      变成大写 (change to upper case)</span><br><span class="line">例如 gUG 会把光标当前到文件结尾全部变成大写 (change upper case all the way to the end)</span><br></pre></td></tr></table></figure><h3><span id="复制与粘贴-copy-amp-paste">复制与粘贴 (copy &amp; paste)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">y               复制 (yank line)</span><br><span class="line">yw              复制一个词</span><br><span class="line">yy              复制当前行 (yank current line)</span><br><span class="line">“&#123;a-zA-Z&#125;y      把信息复制到某个寄存中 (yank the link into register &#123;a-zA-Z&#125;)</span><br><span class="line">#例如我用 “ayy 那么在寄存 a，就复制了一行，然后我再用“byw 复制一个词在寄存 b粘贴的时候，我可以就可以选择贴 a 里面的东西还是 b 里面的，这个就好像是多个复制版一样</span><br><span class="line">“*y             这个是把信息复制进系统的复制版（可以在其他程序中贴出来）(yank to OS buffer)</span><br><span class="line">p               当前光标下粘贴 (paste below)</span><br><span class="line">P               当前光标上粘贴 (paste above)</span><br><span class="line">“&#123;a-zA-Z&#125;p      将某个寄存的内容贴出来 (paste from register)</span><br><span class="line">#例如“ap 那么就在当前光标下贴出我之前在寄存 a 中 的内容。“bP 就在当前光标上贴出我之前寄存 b 的内容</span><br><span class="line">“*p             从系统的剪贴板中读取信息贴入 vim (paste from OS buffer to vim)</span><br><span class="line">reg             显示所有寄存中的内容 (list all registers)</span><br></pre></td></tr></table></figure><h3><span id="跳跃指令jumps">跳跃指令(jumps)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CTRL+] 跟着 link/tag 转入 (follow link/tag)</span><br><span class="line">CTRL+o 回到上一次的 jump (go back)</span><br><span class="line">CTRL+i 跳回下一个 (go forward)</span><br><span class="line">:ju 显示所有的可以跳跃的地方 (print jump list)</span><br></pre></td></tr></table></figure><h3><span id="重做回复">重做/回复</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">u undo</span><br><span class="line">CTRL+r redo</span><br><span class="line">vim 的 undo 是树结构的，你可以回到这个结构中的任何地方</span><br><span class="line">:undo 2 undo 到结构的 2 层 (undo to tree 2)</span><br><span class="line">:undolist 显示所有的 undo 列表 (show undo list)</span><br><span class="line">:earlier 10s undo 到 10 秒前的编辑 (undo to 10 seconds ago)</span><br><span class="line">:earlier 10h undo 到 10 小时前的编辑 (back to 10 hours ago)</span><br><span class="line">:earlier 1m undo 到 1 分钟前 (back to 1 minutes ago)</span><br></pre></td></tr></table></figure><h3><span id="格式-format">格式 (format)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">:set ff=unix 设定文件成 unix 格式 (set file in unix format)</span><br><span class="line">:set ff=dos 设定文件成 dos 格式 (set file in dos format)</span><br><span class="line">:set ff? 检查当前文件格式 (check the format of current file)</span><br></pre></td></tr></table></figure><h3><span id="加密-encryption">加密 (encryption)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim -x 文件名 (filename) 输入 2 次密码，保存后文件每次都会要密码才能进入 (encrypt the file with password)</span><br><span class="line">#vim 处理加密文件的时候，并不会作密码验证，也就是说，当你打开文件的时候，vim 不管你输入的密码是否正确， #直接用密码对本文进行解密。如果密码错误，你看到的就会是乱码， #而不会提醒你密码错误（这样增加了安全性，没有地方可以得知密码是否正确）当然了， #如果用一个够快的机器作穷举破解，vim 还是可以揭开的</span><br></pre></td></tr></table></figure><h3><span id="vim-语法显示-syntax">vim 语法显示 (syntax)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">:syntax enable 打开语法的颜色显示 (turn on syntax color)</span><br><span class="line">:syntax clear 关闭语法颜色 (remove syntax color)</span><br><span class="line">:syntax off 完全关闭全部语法功能 (turn off syntax)</span><br><span class="line">:syntax manual 手动设定语法 (set the syntax manual, when need syntax use :set syntax=ON)</span><br></pre></td></tr></table></figure><h3><span id="运行外部命令-using-an-external-program">运行外部命令 (using an external program)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">:! 直接运行 shell 中的一个外部命令 (call any external program)</span><br><span class="line">:!make 就直接在当前目录下运行 make 指令了 (run make on current path)</span><br><span class="line">:r !ls 读取外部运行的命令的输入，写入当然 vim 中。这里读取 ls 的输出 (read the output of ls and append the result to file)</span><br><span class="line">:3r !date -u 将外部命令 date -u 的结果输入在 vim 的第三行中 (read the date -u, and append result to 3rd line of file)</span><br><span class="line">:w !wc 将 vim 的内容交给外部指令来处理。这里让 wc 来处理 vim 的内容 (send vim’s file to external command. this will send the current file to wc command)</span><br><span class="line">vim 对于常用指令有一些内建，例如 wc (算字数）(vim has some buildin functions, such like wc)</span><br><span class="line">g CTRL-G 计算当前编译的文件的字数等信息 (word count on current buffer)</span><br><span class="line">!!date 插入当前时间 (insert current date)</span><br></pre></td></tr></table></figure><h3><span id="多个文件的编辑-edit-multifiles">多个文件的编辑 (edit multifiles)</span></h3><p>vim 可以编辑多个文件，例如 vim a.txt b.txt c.txt 就打开了 3 个文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">:next 编辑下一个文件 (next file in buffer)</span><br><span class="line">:next! 强制编辑下个文件，这里指如果更改了第一个文件 (force to next file in buffer if current buffer changed)</span><br><span class="line">:wnext 保存文件，编辑下一个 (save the file and goto next)</span><br><span class="line">:args 查找目前正在编辑的文件名 (find out which buffer is editing now)</span><br><span class="line">:previous 编辑上个文件 (previous buffer)</span><br><span class="line">:previous! 强制编辑上个文件，同 :next! (force to previous buffer, same as :next!)</span><br><span class="line">:last 编辑最后一个文件 (last buffer)</span><br><span class="line">:first 编辑最前面的文件 (first buffer)</span><br><span class="line">:set autowrite 设定自动保存，当你编辑下一个文件的时候，目前正在编辑的文件如果改动，将会自动保存 (automatic write the buffer when you switch to next buffer)</span><br><span class="line">:set noautowrite 关闭自动保存 (turn autowrite off)</span><br><span class="line">:hide e abc.txt 隐藏当前文件，打开一个新文件 abc.txt 进行编辑 (hide the current buffer and edit abc.txt)</span><br><span class="line">:buffers 显示所有 vim 中的文件 (display all buffers)</span><br><span class="line">:buffer2 编辑文件中的第二个 (edit buffer 2)</span><br><span class="line"></span><br><span class="line">                    vim中很多东西可以用简称来写，就不用打字那么麻烦了，例如 :edit=:e, :next=:n 这样.</span><br></pre></td></tr></table></figure><h3><span id="分屏-split">分屏 (split)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">vim 提供了分屏功能（跟 screen 里面的 split 一样）</span><br><span class="line">:split 将屏幕分成 2 个 (split screen)</span><br><span class="line">:split abc.txt 将屏幕分成两个，第二个新的屏幕中显示 abc.txt 的内容 (split the windows, on new window, display abc.txt)</span><br><span class="line">:vsplit 竖着分屏 (split vertically)</span><br><span class="line">:&#123;d&#125;split 设定分屏的行数，例如我要一个屏幕只有 20 行，就可以下:20split (split the windows with &#123;d&#125; line. 20split: open new windows with 3 lines)</span><br><span class="line">:new 分屏并且在新屏中建立一个空白文件 (split windows with a new blank file)</span><br><span class="line">CTRL-w+j/k/h/l 利用 CTRL 加 w 加上 j/k/h/l 在不同的屏内切换 (switch, move between split screens)</span><br><span class="line">CTRL-w+ -/+ 增减分屏的大小 (change split size)</span><br><span class="line">CTRL-w+t 移动到最顶端的那个屏 (move to the top windows)</span><br><span class="line">CTRL-w+b 移动到最下面的屏 (move to bottom window)</span><br><span class="line">:close 关闭一个分出来的屏 (close splited screen)</span><br><span class="line">:only 只显示光标当前屏 ，其他将会关闭(only display current active screen, close all others )</span><br><span class="line">:qall 退出所有屏 (quite all windows)</span><br><span class="line">:wall 保存所有屏 （write to all windows）</span><br><span class="line">:wqall 保存并退出所有屏 (write and quite all windows)</span><br><span class="line">:qall! 退出所有屏，不保存任何变动 (quite all windows without save)</span><br><span class="line">开启文件的时候，利用 -o 选项，就可以直接开启多个文件在分屏中 (with -o option from command line, it will open files and display in split mode)</span><br><span class="line">vim -o a.txt b.txt</span><br><span class="line"></span><br><span class="line">vimdiff a.txt b.txt 如果直接给 -d 选项是一样的 vim -d a.txt b.txt</span><br><span class="line">:diffsplit abc.txt 如果你现在已经开启了一个文件，想 vim 帮你区分你的文件跟 abc.txt 有什么区别，可以在 vim 中用 diffsplit 的方式打开第二个文件，这个时 候 vim 会用 split 的方式开启第二个文件，并且通过颜色，fold 来显示两个文件的区别</span><br><span class="line">这样 vim 就会用颜色帮你区分开 2 个文件的区别。如果文件比较大（源码）重复的部分会帮你折叠起来（折叠后面会说）</span><br><span class="line">现在来说 patch</span><br><span class="line">:diffpatch filename 通过:diffpatch 你的 patch 的文件名，就可以以当前文件加上你的 patch 来显示。vim 会 split 一个新的屏，显示 patch 后的信息并且用颜色标明区别。</span><br><span class="line">如果不喜欢上下对比，喜欢左右（比较符合视觉）可以在前面加 vert，例如：</span><br><span class="line">:vert diffsplit abc.txt</span><br><span class="line">:vert diffpatch abc.txt</span><br><span class="line">看完 diff，用: only 回到原本编辑的文件，觉 得 diff 的讨厌颜色还是在哪里，只要用:diffoff 关闭就好了。</span><br><span class="line">还有个常用的 diff 中的就是 :diffu 这个是 :diffupdate 的简写，更新用</span><br></pre></td></tr></table></figure><h3><span id="标签-tab">标签 tab</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">:tab split filename 这个就用 tab 的方式来显示多个文件 (use tab to display buffers)</span><br><span class="line">gt 到下一个 tab (go to next tab)</span><br><span class="line">gT 到上一个 tab (go to previous tab)</span><br><span class="line">vim 大多数东西都是可一给数字来执行的，tab 也是一样</span><br><span class="line">0gt 跳到第一个 tab (switch to 1st tab)</span><br><span class="line">5gt 跳到第五个 tab (switch to 5th tab)</span><br><span class="line">关闭所有的 tab 可以使用 qall 的指令。</span><br><span class="line">当需要更改多个 tab 中的文件的时候，可以用 :tabdo 这个指令 这个就相当于 loop 到你的所有的 tab 中然后运行指令。</span><br><span class="line">例如有 5 个文件都在 tab 里面，需要更改一个变量名称：abc 到 def， 就可以用 :tabdo %s/abc/def/g 这样所有的 5 个 tab 里面的 abc 就都变成 def 了</span><br></pre></td></tr></table></figure><h3><span id="折叠-folding">折叠 (folding)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">zfap 按照段落折叠 (fold by paragraph)</span><br><span class="line">zo 打开一个折叠 (open fold)</span><br><span class="line">zc 关闭一个折叠 (close fold)</span><br><span class="line">zf 创建折叠 (create fold) 这个可以用 v 视觉模式，可以直接给行数等等</span><br><span class="line">zr 打开一定数量的折叠，例如 3rz (reduce the folding by number like 3zr)</span><br><span class="line">zm 折叠一定数量（之前你定义好的折叠） (fold by number)</span><br><span class="line">zR 打开所有的折叠 (open all fold)</span><br><span class="line">zM 关闭所有的摺叠 (close all fold)</span><br><span class="line">zn 关闭折叠功能 (disable fold)</span><br><span class="line">zN 开启折叠功能 (enable fold)</span><br><span class="line">zO 将光标下所有折叠打开 (open all folds at the cursor line)</span><br><span class="line">zC 将光标下所有折叠关闭 (close all fold at cursor line)</span><br><span class="line">zd 将光标下的折叠删除，这里不是删除内容，只是删除折叠标记 (delete fold at cursor line)</span><br><span class="line">zD 将光标下所有折叠删除 (delete all folds at the cursor line)</span><br><span class="line">按照 tab 来折叠，python 最好用的 (ford by indent, very useful for python)</span><br><span class="line">:set foldmethod=indent 设定后用 zm 跟 zr 就可以的开关关闭了 (use zm zr)</span><br><span class="line"></span><br><span class="line">对于 vim 来说，如果你设定了折叠，但是退出文件，不管是否保持文件，折叠部分会自动消失的。这样来说非常不方便。所以 vim 给你方法去保存折 叠，标签，书签等等记录。最厉害的是，vim 对于每个文件可以保存最多 10 个 view，也就是说你可以对同一个文件有 10 种不同的标记方法，根据你的需 要，这些东西都会保存下来。</span><br><span class="line">:mkview 保存记录 (save setting)</span><br><span class="line">:loadview 读取记录 (load setting)</span><br><span class="line">:mkview 2 保存记录在寄存 2 （save view to register 2)</span><br><span class="line">:loadview 3 从寄存 3 中读取记录 (load view from register 3)</span><br></pre></td></tr></table></figure><h3><span id="常用指令-commands">常用指令 (commands)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">:set ic 设定为搜索时不区分大小 写 (search case insensitive)</span><br><span class="line">:set noic 搜索时区分大小写。 vim 内定是这个(case sensitive )</span><br><span class="line">&amp; 重复上次的”:s” (repeat previous “:s”)</span><br><span class="line">. 重复上次的指令 (repeat last command)</span><br><span class="line">K 在 man 中搜索当前光标下的词 (search man page under cursor)</span><br><span class="line">&#123;0-9&#125;K 查找当前光标下 man 中的章节，例如 5K 就是同等于 man 5 (search section of man. 5K search for man 5)</span><br><span class="line">:history 查看命令历史记录 (see command line history)</span><br><span class="line">q: 打开 vim 指令窗口 (open vim command windows)</span><br><span class="line">:e 打开一个文件，vim 可以开启 http/ftp/scp 的文件 (open file. also works with http/ftp/scp)</span><br><span class="line">:e http://www.google.com/index.html 这里就在 vim 中打开 google 的 index.html (open google’s index.html)</span><br><span class="line">:cd 更换 vim 中的目录 (change current directory in vim)</span><br><span class="line">:pwd 显示 vim 当前目录 (display pwd in vim)</span><br><span class="line">gf 打开文件。例如你在 vim 中有一行写了#include 那么在 abc.h 上面按 gf，vim 就会把 abc.h 这个文件打开 (look for file. if you have a file with #include , then the cursor is on abc.h press gf, it will open the file abc.h in vim )</span><br></pre></td></tr></table></figure><h3><span id="记录指令-record">记录指令 (record)</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">q&#123;a-z&#125; 在某个寄存中记录指令 (record typed char into register)</span><br><span class="line">q&#123;A-Z&#125; 将指令插入之前的寄存器 (append typed char into register&#123;a-z&#125;)</span><br><span class="line">q 结束记录 (stop recording)</span><br><span class="line">@&#123;a-z&#125; 执行寄存中的指令 (execute recording)</span><br><span class="line">@@ 重复上次的指令 (repeat previours :@&#123;a-z&#125;)</span><br><span class="line">还是给个例子来说明比较容易明白</span><br><span class="line">我现在在一个文件中下 qa 指令,然后输入 itest 然后 ESC 然后 q</span><br><span class="line">这里 qa 就是说把我的指令记录进 a 寄存，itest 实际是分 2 步，i 是插入 (insert) 写入的文字是 text 然后用 ESC 退回指令模式 q 结束记录。这样我就把 itest 记录再一个寄存了。</span><br><span class="line">下面我执行@a 那么就会自动插入 test 这个词。@@就重复前一个动作，所以还是等于@a</span><br></pre></td></tr></table></figure><h3><span id="搜索-search">搜索 (search)</span></h3><p>vim 超级强大的一个功能就是搜索跟替换了。要是熟悉正表达(regular expressions)这个搜索跟后面的替换将会是无敌利器（支持 RE 的编辑器不多吧）<br>从简单的说起</p><p>光标下正向搜索关键词 (search the word under cursor forward)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/ 向下搜索 (search forward)</span><br><span class="line">? 向上搜索 (search back)</span><br><span class="line">% 查找下一个结束，例如在”(“下查找下一个”)”，可以找”()”, “[]” 还有 shell 中常用的 if, else 这些 (find next brace, bracket, comment or #if/#else/#endif)</span><br></pre></td></tr></table></figure><p>下面直接用几个例子说话</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">/a* 这个会搜到 a aa aaa</span><br><span class="line">/\(ab\)* 这个会搜到 ab abab ababab</span><br><span class="line">/ab\+ 这个会搜到 ab abb abbb</span><br><span class="line">/folers\= 这个会搜到 folder folders</span><br><span class="line">/ab\&#123;3,5&#125; 这个会搜到 abbb abbbb abbbbb</span><br><span class="line">/ab\&#123;-1,3&#125; 这个会在 abbb 中搜到 ab (will match ab in abbb)</span><br><span class="line">/a.\&#123;-&#125;b 这个会在 axbxb 中搜到 axb (match ‘axb’ in ‘axbxb’)</span><br><span class="line">/a.*b 会搜索到任何 a 开头后面有 b 的 (match a*b any)</span><br><span class="line">/foo\|bar 搜索 foo 或者 bar，就是同时搜索 2 个词 (match ‘foo’ or ‘bar’)</span><br><span class="line">/one\|two\|three 搜索 3 个词 (match ‘one’, ‘two’ or ‘three’)</span><br><span class="line">/\(foo\|bar\)\+ 搜索 foo, foobar, foofoo, barfoobar 等等 (match ‘foo’, ‘foobar’, ‘foofoo’, ‘barfoobar’ … )</span><br><span class="line">/end\(if\|while\|for\) 搜索 endif, endwhile endfor (match ‘endif’, ‘endwhile’, ‘endfor’)</span><br><span class="line">/forever\&amp;… w&gt; 这个会在 forever 中搜索到”for”但是不会在 fortuin 中搜索到”for” 因为我们这里给了&amp;…的限制 (match ‘for’ in ‘forever’ will not match ‘fortuin’)</span><br><span class="line"></span><br><span class="line">特殊字符前面加^就可以 (for special character, user “^” at the start of range)</span><br><span class="line">/”[^&quot;]\*”</span><br><span class="line">这里解释一下</span><br><span class="line">” 双引号先引起来 (double quote)</span><br><span class="line">[^&quot;] 任何不是双引号的东西(any character that is not a double quote)</span><br><span class="line"></span><br><span class="line">- 所有的其他 (as many as possible)</span><br><span class="line">  ” 结束最前面的引号 (double quote close)</span><br><span class="line">  上面那个会搜到“foo” “3!x”这样的包括引号 (match “foo” -&gt; and “3!x” include double quote)</span><br><span class="line"></span><br><span class="line">更多例子，例如搜索车牌规则，假设车牌是 “1MGU103” 也就是说，第一个是数字，3 个大写字幕，3 个数字的格式。那么我们可以直接搜索所有符合这个规则的字符</span><br><span class="line">(A sample license plate number is “1MGU103″. It has one digit, three upper case</span><br><span class="line">letters and three digits. Directly putting this into a search pattern)</span><br><span class="line">这个应该很好懂，我们搜索</span><br><span class="line">\数字\大写字母\大写字母\大写字母\数字\数字\数字</span><br><span class="line"></span><br><span class="line">/\d\u\u\u\d\d\d</span><br><span class="line"></span><br><span class="line">另外一个方法，是直接定义几位数字（不然要是 30 位，难道打 30 个\u 去？）</span><br><span class="line">(specify there are three digits and letters with a count)</span><br><span class="line"></span><br><span class="line">/\d\u\&#123;3&#125;\d\&#123;3&#125;</span><br><span class="line"></span><br><span class="line">也可以用范围来搜索 (Using [] ranges)</span><br><span class="line">/[0-9][a-z]\&#123;3&#125;[0-9]\&#123;3&#125;</span><br><span class="line"></span><br><span class="line">用到范围搜索，列出一些范围(range)</span><br><span class="line">这个没什么好说了，看一下就都明白了，要全部记住。。。用的多了就记住了，用的少了就忘记了。每次看帮助，呵呵</span><br><span class="line"></span><br><span class="line">/[a-z]</span><br><span class="line">/[0123456789abcdef] = /[0-9a-f]</span><br><span class="line">\e</span><br><span class="line">\t</span><br><span class="line">\r</span><br><span class="line">\b</span><br><span class="line">简写 (item matches equivalent)</span><br><span class="line"></span><br><span class="line">\d digit [0-9]</span><br><span class="line">\D non-digit [^0-9]</span><br><span class="line">\x hex digit [0-9a-fA-F]</span><br><span class="line">\X non-hex digit [^0-9a-fa-f]</span><br><span class="line">\s white space [ ](and)</span><br><span class="line">\S non-white characters [^ ] (not and )</span><br><span class="line">\l lowercase alpha [a-z]</span><br><span class="line">\L non-lowercase alpha [^a-z]</span><br><span class="line">\u uppercase alpha [A-Z]</span><br><span class="line">\U non-uppercase alpha [^a-z]</span><br><span class="line"></span><br><span class="line">:help /[] 特殊的定义的，可以在 vim 中用用 help 来看 (everything about special)</span><br><span class="line">:help /\s 普通的也可以直接看一下 (everything about normal)</span><br></pre></td></tr></table></figure><h3><span id="替换-string-substitute-rx">替换 (string substitute) – RX</span></h3><p>替换其实跟搜索是一样的。只不过替换是 2 个值，一个是你搜索的东西，一个是搜索到之后要替换的 string substitute (use rx)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%s/abc/def/ 替换 abc 到 def (substitute abc to def)</span><br><span class="line">%s/abc/def/c 替换 abc 到 def，会每次都问你确定(substitute on all text with confirmation (y,n,a,q,l))</span><br><span class="line">1,5s/abc/def/g 只替换第一行到第 15 行之间的 abc 到 def (substitute abc to def only between line 1 to 5)</span><br><span class="line">54s/abc/def/ 只替换第 54 行的 abc 到 def (only substitute abc to def on line 54)</span><br><span class="line"></span><br><span class="line">结合上面的搜索正表达式，这个替换功能。。。就十分只强大。linux 中很多地方都是用正表达来做事请的，所以学会了受益无穷。</span><br></pre></td></tr></table></figure><h3><span id="全局-global">全局 (global)</span></h3><p>这个不知道怎么翻译，反正 vim 是叫做 global，可以对搜索到的东西执行一些 vim 的命令。我也是 2-3 个星期前因为读 log 中一些特殊的东 西，才学会用的。 (find the match pater and execute a command)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">global 具体自行方法是 g/pattern/command</span><br><span class="line">:g/abc/p 查找并显示出只有 abc 的行 (only print line with “abc” )</span><br><span class="line">:g/abc/d 删除所有有 abc 的行 (delete all line with “abc”)</span><br><span class="line">:v/abc/d 这个会把凡是不是行里没有 abc 的都删掉 (delete all line without “abc”)</span><br></pre></td></tr></table></figure><h3><span id="信息过滤-filter">信息过滤 (filter)</span></h3><p>vim 又一强大功能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">! 用!就是告诉 vim，执行过滤流程 (tell vim to performing a filter operation)</span><br><span class="line">!5G 从光标下向下 5 行执行过滤程序 (tell vim to start filter under cursor and go down 5 lines)</span><br><span class="line"></span><br><span class="line">正式指令开始，这里用 sort 来做例子：</span><br><span class="line">!5Gsort 从光标下开始执行 sort，一共执行 5 行，就是说我只要 sort5 行而已 (this will sort the text from cursor line down to 5 lines)</span><br><span class="line">!Gsort -k3 可以直接代 sort 的参数，我要 sort 文字中的第三段 (sort to the end of file by column 3)</span><br><span class="line">!! 值过滤当前的这行 (filter the current line)</span><br><span class="line"></span><br><span class="line">如果觉得!这样的方法 5G 这样的方法用起来别扭（我是这么觉得），可以用标准的命令模式来做</span><br><span class="line">!其实就是个:.,而已 （to type the command）</span><br><span class="line">:.,start,end!sort 这里定义:.,起始行，结束行!运行指令</span><br><span class="line">:.,$!sort       从当前这行一直执行至文件结束 (sort from current line to end)</span><br><span class="line">:.0,$!sort 从文件的开始第一个行一直执行到文件结束 (sort from start of file to end)</span><br><span class="line">:.10,15!sort 只在文件的第 10 行到第 15 行之间执行 (sort between line 10 to 15)</span><br></pre></td></tr></table></figure><h3><span id="查找替换">查找替换</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/pattern     向后搜索字符串pattern</span><br><span class="line">?pattern     向前搜索字符串pattern</span><br><span class="line">&quot;\c&quot;         忽略大小写</span><br><span class="line">&quot;\C&quot;         大小写敏感</span><br><span class="line">n            下一个匹配(如果是/搜索，则是向下的下一个，?搜索则是向上的下一个)</span><br><span class="line">N            上一个匹配(同上)</span><br><span class="line">:%s/old/new/g     搜索整个文件，将所有的old替换为new</span><br><span class="line">:%s/old/new/gc     搜索整个文件，将所有的old替换为new，每次都要你确认是否替换</span><br></pre></td></tr></table></figure><h3><span id="切换标签页">切换标签页</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">:tabnew [++opt选项] ［＋cmd］ 文件 建立对指定文件新的tab</span><br><span class="line">:tabc 关闭当前的 tab</span><br><span class="line">:tabo 关闭所有其他的 tab</span><br><span class="line">:tabs 查看所有打开的 tab</span><br><span class="line">:tabp 前一个 tab</span><br><span class="line">:tabn 后一个 tab</span><br><span class="line">#标准模式下：</span><br><span class="line">gT 前一个 tab</span><br><span class="line">gt 后一个 tab</span><br><span class="line">#MacVim 还可以借助快捷键来完成 tab 的关闭、切换</span><br><span class="line">cmd+w 关闭当前的 tab</span><br><span class="line">cmd+&#123; 前一个 tab</span><br><span class="line">cmd+&#125; 后一个 tab</span><br></pre></td></tr></table></figure><h3><span id="nerdtree-快捷键">NERDTree 快捷键</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">ctrl + w + h 光标 focus 左侧树形目录</span><br><span class="line">ctrl + w + l 光标 focus 右侧文件显示窗口</span><br><span class="line">ctrl + w + w 光标自动在左右侧窗口切换</span><br><span class="line">ctrl + w + r 移动当前窗口的布局位置</span><br><span class="line"></span><br><span class="line">?: 快速帮助文档</span><br><span class="line">o: 打开一个目录或者打开文件，创建的是buffer，也可以用来打开书签</span><br><span class="line">go: 打开一个文件，但是光标仍然留在NERDTree，创建的是buffer</span><br><span class="line">t: 打开一个文件，创建的是Tab，对书签同样生效</span><br><span class="line">T: 打开一个文件，但是光标仍然留在NERDTree，创建的是Tab，对书签同样生效</span><br><span class="line">i: 水平分割创建文件的窗口，创建的是buffer</span><br><span class="line">gi: 水平分割创建文件的窗口，但是光标仍然留在NERDTree</span><br><span class="line">s: 垂直分割创建文件的窗口，创建的是buffer</span><br><span class="line">gs: 和gi，go类似</span><br><span class="line">x: 收起当前打开的目录</span><br><span class="line">X: 收起所有打开的目录</span><br><span class="line">e: 以文件管理的方式打开选中的目录</span><br><span class="line">D: 删除书签</span><br><span class="line">P: 大写，跳转到当前根路径</span><br><span class="line">p: 小写，跳转到光标所在的上一级路径</span><br><span class="line">K: 跳转到第一个子路径</span><br><span class="line">J: 跳转到最后一个子路径</span><br><span class="line">&lt;C-j&gt;和&lt;C-k&gt;: 在同级目录和文件间移动，忽略子目录和子文件</span><br><span class="line">C: 将根路径设置为光标所在的目录</span><br><span class="line">u: 设置上级目录为根路径</span><br><span class="line">U: 设置上级目录为跟路径，但是维持原来目录打开的状态</span><br><span class="line">r: 刷新光标所在的目录</span><br><span class="line">R: 刷新当前根路径</span><br><span class="line">I: 显示或者不显示隐藏文件</span><br><span class="line">f: 打开和关闭文件过滤器</span><br><span class="line">q: 关闭NERDTree</span><br><span class="line">A: 全屏显示NERDTree，或者关闭全屏</span><br><span class="line">! 执行此文件</span><br><span class="line">m 显示文件系统菜单（添加、删除、移动操作）</span><br></pre></td></tr></table></figure><h3><span id="vim-config">vim config</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">&quot; Configuration file for mvim</span><br><span class="line"></span><br><span class="line">&quot; Set vundle settings here</span><br><span class="line">&quot; git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</span><br><span class="line">set nocompatible              &quot; be iMproved, required</span><br><span class="line">filetype off                  &quot; required</span><br><span class="line"></span><br><span class="line">&quot; set the runtime path to include Vundle and initialize</span><br><span class="line">set rtp+=~/.vim/bundle/Vundle.vim</span><br><span class="line">call vundle#begin()</span><br><span class="line">&quot; alternatively, pass a path where Vundle should install plugins</span><br><span class="line">&quot;call vundle#begin(&apos;~/some/path/here&apos;)</span><br><span class="line"></span><br><span class="line">&quot; let Vundle manage Vundle, required</span><br><span class="line">Plugin &apos;VundleVim/Vundle.vim&apos;        &quot;https://github.com/VundleVim/Vundle.vim</span><br><span class="line"></span><br><span class="line">&quot; Custom plugins</span><br><span class="line">Plugin &apos;scrooloose/nerdtree&apos;         &quot;https://github.com/scrooloose/nerdtree</span><br><span class="line">Plugin &apos;maciakl/vim-neatstatus&apos;      &quot;https://github.com/maciakl/vim-neatstatus</span><br><span class="line">&quot; Plugin &apos;MattesGroeger/vim-bookmarks&apos; &quot;https://github.com/MattesGroeger/vim-bookmarks</span><br><span class="line"></span><br><span class="line">&quot; All of your Plugins must be added before the following line</span><br><span class="line">call vundle#end()            &quot; required</span><br><span class="line">filetype plugin indent on    &quot; required</span><br><span class="line">&quot; To ignore plugin indent changes, instead use:</span><br><span class="line">&quot;filetype plugin on</span><br><span class="line">&quot;</span><br><span class="line">&quot; Brief help</span><br><span class="line">&quot; :PluginList       - lists configured plugins</span><br><span class="line">&quot; :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate</span><br><span class="line">&quot; :PluginSearch foo - searches for foo; append `!` to refresh local cache</span><br><span class="line">&quot; :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal</span><br><span class="line">&quot;</span><br><span class="line">&quot; see :h vundle for more details or wiki for FAQ</span><br><span class="line">&quot; Put your non-Plugin stuff after this line</span><br><span class="line"></span><br><span class="line">set modelines=0</span><br><span class="line"></span><br><span class="line">&quot; Normally we use vim-extensions. If you want true vi-compatibility</span><br><span class="line">&quot; remove change the following statements</span><br><span class="line">&quot; set nocompatible &quot; Use Vim defaults instead of 100% vi compatibility</span><br><span class="line">set backspace=2  &quot; more powerful backspacing</span><br><span class="line"></span><br><span class="line">&quot; Don&apos;t write backup file if vim is being called by &quot;crontab -e&quot;</span><br><span class="line">&quot; au BufWrite /private/tmp/crontab.* set nowritebackup nobackup</span><br><span class="line">&quot; Don&apos;t write backup file if vim is being called by &quot;chpass&quot;</span><br><span class="line">&quot; au BufWrite /private/etc/pw.* set nowritebackup nobackup</span><br><span class="line"></span><br><span class="line">syntax on&quot; 自动语法高亮</span><br><span class="line">set number &quot; 显示行号</span><br><span class="line">set background=dark&quot;背景颜色</span><br><span class="line">set autoindent&quot; 自动对齐</span><br><span class="line">set smartindent&quot; 开启新行时使用智能自动缩进</span><br><span class="line">set showmatch&quot; 插入括号时，短暂地跳转到匹配的对应括号</span><br><span class="line">&quot; :set mouse=a &quot;</span><br><span class="line">&quot; 在vim所有模式下开鼠标，鼠标选择文档就不会代入行号，但是复制到剪贴板功能失效</span><br><span class="line">set softtabstop=4    &quot; 设置软制表符的宽度</span><br><span class="line">set shiftwidth=4     &quot; (自动) 缩进使用的4个空格</span><br><span class="line">set tabstop=4        &quot; 设置制表符(tab键)的宽度</span><br><span class="line">set expandtab        &quot; 行首tab转换为4个空格</span><br><span class="line">set linebreak        &quot; 整词换行</span><br><span class="line">&quot; set whichwrap=b,s,&lt;,&gt;,[,] &quot; 光标从行首和行末时可以跳到另一行去</span><br><span class="line">set ruler            &quot; 标尺，用于显示光标位置的行号和列号，逗号分隔。每个窗口都有自己的标尺。如果窗口有状态行，标尺在那里显示。否则，它显示在屏幕的最后一行上</span><br><span class="line">set showcmd          &quot; 命令行显示输入的命令</span><br><span class="line">set showmode         &quot; 命令行显示vim当前模式</span><br><span class="line">set incsearch        &quot; 输入字符串就显示匹配点</span><br><span class="line">set enc=utf-8        &quot; 文件编码</span><br><span class="line"></span><br><span class="line">&quot; NERDTree settings</span><br><span class="line">autocmd StdinReadPre * let s:std_in=1</span><br><span class="line">autocmd VimEnter * if argc() == 0 &amp;&amp; !exists(&quot;s:std_in&quot;) | NERDTree | endif</span><br><span class="line"></span><br><span class="line">&quot; key mapping</span><br><span class="line">:inoremap &#123; &#123;&#125;&lt;ESC&gt;i</span><br><span class="line">:map &lt;f2&gt; :NERDTreeToggle&lt;CR&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3&gt;&lt;span id=&quot;光标移动&quot;&gt;光标移动&lt;/span&gt;&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span 
      
    
    </summary>
    
      <category term="Vim" scheme="http://calfgz.github.io/categories/Vim/"/>
    
    
      <category term="Vim" scheme="http://calfgz.github.io/tags/Vim/"/>
    
  </entry>
  
  <entry>
    <title>电商系统之搜索引擎[转]</title>
    <link href="http://calfgz.github.io//blog/2018/10/e-commerce-search.html"/>
    <id>http://calfgz.github.io//blog/2018/10/e-commerce-search.html</id>
    <published>2018-10-31T08:48:41.000Z</published>
    <updated>2019-04-28T07:38:07.345Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="什么搜索引擎">什么搜索引擎</span></h2><p>搜索引擎(search engine)是指根据一定的策略、运用特定的计算机程序搜集互联网上的信息，在对信息进行组织和处理后，为用户提供检索服务的系统。数据其实就是一块块的砖头，当用户需要的时候搜索引擎搬过来。我们的宗旨就是在最短的时间内，让用户找到他们最想要的东西。</p><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrhyx2ympj30hs0apt8l.jpg" alt="搜索引擎"></p><h3><span id="电商搜索业务特点">电商搜索业务特点</span></h3><ul><li>第一点， 电商系统的商品数量『庞大』，搜索页的PV高。某宝2013年有7亿线上商品， List的PV7亿+相当于每秒有 8000个请求</li><li>第二点， 电商的搜索引擎并没有爬虫系统，因为所有的数据都是结构化的，一般都是Mysql或者 Oracle 的数据库，所以不用像百度一样用『爬虫』去不断去别的网站找内容，当然，电商其实也有自己的『爬虫』系统，一般都是抓取友商的价格，再对自己进行调整。</li><li>第三点， 电商搜索引擎的过滤功能其实比搜索功能要常用，甚至大于搜索本身。什么是过滤功能？一般我们网站买东西的时候，搜了一个关健词，比如运动鞋，然后所有相关品牌或者其他分类的选择就会呈现在我们面前。对百度而言，搜什么词就是什么词，如果是新闻的话，可能在时间上会有一个过滤的选项。</li><li>第四点， 电商搜索引擎支持各种维度的排序，包括支持人气、销量、信用、价格、发货地等属性的排序，且对数据的实时性要求非常高。对一般的搜索引擎，只有非常重要的网站，比如一些重量级的门户网站，百度的收录是非常快的，但是对那些流量很小的网站，可能一个月才会爬一次。电商搜索对数据的实时性要求主要体现在价格和库存两个方面。</li><li>第五点， 电商搜索引擎的效果不仅要考虑买家（信息消费方，结果多样性），还得考虑卖家（信息提供方，曝光率）。</li><li>第六点， 电商搜索引擎另一个特点就是不能丢品，比如我们在淘宝、天猫开了个店铺，然后好不容易搞了一次活动，但是却搜不到了，这是无法忍受的。除此之外，电商搜索引擎与推荐系统和广告系统是相互融合的，因为搜索引擎对流量的贡献是最大的，所以大家都希望把广告系统能跟其融合。</li><li>第七点， 保证高可用，容灾、异常保护、降级(降级：QPS维度、在Clustermap上来做，正常来说，我们有20列，如果系统负载高的话查询只分布到10列，这样就高了1倍的QPS) 。异常保护：Latency 、在Searcher上来做，如果系统负载较高的话，Searcher上会直接丢弃一些耗时的Query。</li></ul><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwriewskf2j30hs0bwmx8.jpg" alt></p><p>综上所述，电商系统中搜索引擎的必要性显而易见。</p><h3><span id="搜索引擎页面结构图">搜索引擎页面结构图</span></h3><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrijca5fkj30hs0b6mx5.jpg" alt></p><h3><span id="搜索引擎系统架构图">搜索引擎系统架构图</span></h3><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrik1f8wlj30hs13vgm4.jpg" alt></p><h3><span id="搜索服务系统">搜索服务系统</span></h3><p>该系统真正接受用户请求并响应的系统。为了用户体验的需要，首先增加Query Processor服务，负责查询意图分析提升搜索的准确性。随着访问量的增长，接着增加缓存模块，提升请求处理性能。接着随着数据量（商品量）的增长，将CMS服务从检索服务中独立出去，成为Detail服务。数据量的进一步增长，对数据进行类似数据库分库分表的分片操作。这时候，在线检索服务由多个分片的Searcher列组成。自然而然，需要一个Merger服务，将多个分片的结果进行合并。</p><h3><span id="搜索系统流程说明">搜索系统流程说明</span></h3><ol><li>客户端请求通过Load Blance到Blender；</li><li>Blender调用QP，QP调用运营平台，其中运营平台主要负责将日常运营数据服务化，QP负责分析Query；</li><li>Blender请求Page Cache和Data Cache同时请求Merger调用在线搜索服务；</li><li>Merger调用UserInfoSystem获取用户标签信息；</li><li>Merger将请求发给每列Searcher；</li><li>每个Searcher召回商品并返给Merger；</li><li>Merger合并多列searcher的结果，确定需要输出的商品，请求CMS封装对应的商品信息；</li><li>CMS封装商品信息返给Merger；</li><li>Merger将包装好的商品返给Blender；</li><li>Blender将Merger返回的结果与其他垂直搜索结果进行合并，最终返回给前端。</li></ol><p>为了保证高召回率和低响应延时，搜索服务流程的处理全部放在内存当中进行计算。多个Searcher并发处理请求，同时单个Searcher内部采用线程池技术，即所有线程之间共享倒排索引和商品属性信息，提高内存使用效率；每个查询使用一个独立线程串行执行，保证并发的多个查询线程之间互不影响。此外通过合理的设置线程池的大小，保证系统的CPU资源得到充分利用。并且采用多级缓存来保证系统的高可用。</p><h3><span id="多级缓存策略">多级缓存策略</span></h3><p>Page Cache：由于搜索符合互联网的二八法则，20%热门查询频度非常高，占每天搜索请求量80%。针对这一特点，搜索第一级缓存以查询请求为Key，将返回给用户的页面作为Value。对于完全相同的请求，直接从缓存返回结果。页面缓存策略上线伊始，缓存命中率就接近了30%，基本解决了当时的性能问题。</p><p>Data Cache：随着业务的发展，排序结果需要针对不同用户实现个性化订制，这就导致请求中会包含用户的UserInfo。如果直接将UserInfo放入缓存作为Key，会导致Data Cache的key数量激增，不但需要超大的缓存空间，同时缓存的命中率也会极低，最终会导致线上个性化服务的体验满意度降低。为了解决这个问题，将UserInfo加入Key，但是Value只保存排序好的商品ID，这样需要的缓存空间远远小于Data Cache。当命中缓存后，调用CMS直接进行结果包装。为了进一步提高缓存命中率，利用用户搜索的翻页习惯，即离线统计出用户的翻页数最大值，然后在Value中缓存这些页面涉及到所有的商品ID，从实践效果来看，用户后续的翻页请求大部分会命中Cache。</p><h3><span id="索引系统">索引系统</span></h3><p>该系统是搜索技术的核心，在进入这个系统之前，搜索信息仍然是以商品维度进行存储的。索引系统负责生成一种以关键字维度进行存储的信息，一般称之为倒排索引。系统对于全量和增量的处理是一致的，唯一的区别在于待处理数据量的差异。一般情况下，全量数据索引由于数据量庞大，采用Hadoop进行；实时数据量小，采用单机进行索引生产。</p><h3><span id="索引类型">索引类型</span></h3><h4><span id="倒排索引">倒排索引</span></h4><p>倒排索引（英语：Inverted index），也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射，它是文档检索系统中最常用的数据结构。</p><p>有两种不同的反向索引形式：</p><ul><li>一条记录的水平反向索引（或者反向档案索引）包含每个引用单词的文档的列表。</li><li>一个单词的水平反向索引（或者完全反向索引）又包含每个单词在一个文档中的位置。</li></ul><p>后者的形式提供了更多的兼容性（比如短语搜索），但是需要更多的时间和空间来创建。<br>(REF:<a href="http://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95" target="_blank" rel="noopener">http://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95</a>)</p><h5><span id="如何构建倒排索引">如何构建倒排索引</span></h5><p>Eg. 被索引的文本：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">    T0 = <span class="string">"it is what it is"</span></span><br><span class="line">    T1 = <span class="string">"what is it"</span></span><br><span class="line">    T2 = <span class="string">"it is a banana"</span></span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">得到的倒排索引：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">    <span class="string">"a"</span>:    &#123;<span class="number">2</span>&#125;</span><br><span class="line">    <span class="string">"banana"</span>: &#123;<span class="number">2</span>&#125;</span><br><span class="line">    <span class="string">"is"</span>:  &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>&#125;</span><br><span class="line">    <span class="string">"it"</span>:  &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>&#125;</span><br><span class="line">    <span class="string">"what"</span>:   &#123;<span class="number">0</span>, <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure><p>检索的条件”what”,”is”和”it”将对应集合的交集。</p><p>正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档，很容易看到这个反向的关系。</p><h5><span id="简单索引的文件格式">简单索引的文件格式</span></h5><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwriv1x6epj30hs066q2x.jpg" alt></p><p>Index file可以采用闭链Hash的结构来存储，这样查询效率会很高，但是空间利用率很低。也可以对Key做排序后顺序存储，查询时使用二分查找。查询效率较低，但是不会浪费内存。Doclist file的存储就很简单了，整体来看就是一个Int型的数组，为了提高内存利用率，通常还会对Doclist进行压缩。</p><p><strong>问题1：</strong><br>    假如有7亿的宝贝，其中有1亿宝贝标题中包含”正品”这个词，那么正品这个词的倒排链长度就是1亿</p><p><strong>解决方案：</strong><br>    1，索引压缩<br>         要求：在解压速度快的基础上，压缩比尽量高</p><pre><code>2，索引截断     要求：不影响用户体验的前提下，倒排链尽量短</code></pre><h3><span id="正排索引">正排索引</span></h3><p>一种索引方法，被用来存储在全文搜索下某个文档ID与其对应的部分字段存储位置的映射。正排表是以文档的ID为关键字，表中记录文档中每个字的位置信息，查找时扫描表中每个文档中字的信息直到找出所有包含查询关键字的文档。</p><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrixh33s9j30hs02mdfp.jpg" alt></p><p><strong>问题2：</strong><br>    1，单台机器内存资源有限，如何容纳更多的文档？<br>    2，高并发下如何快速响应请求？</p><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwriympsgoj30hs06xwed.jpg" alt></p><p><strong>分布式的行、列概念</strong></p><p>多行用于做负载均衡、冗余备份。如果我们一行能承担1000的QPS，那么10行就能承担1000*10的QPS，多列用于提高索引量。如果我们一台机器受限于内存只能放1000w的宝贝，那么1亿的宝贝就需要10台机器，也就是10列。<br>在分布式集群里，通常会有多行多列。当然如果数据量足够小，可以只有一列，但是考虑到容灾备份，就算流量非常低也会有至少2行。</p><ul><li>方案一：个性化搜索</li><li>方案二：主搜索<br>   Ksearch与Isearch的区别：Ksearch是按Key来分布数据，而Isearch虽然也支持按Key查询，但是主要功能是分布式。</li></ul><h4><span id="检索过程">检索过程</span></h4><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrj0tz59hj30hs0hvjrf.jpg" alt></p><p><strong>问题3：</strong> 为什么做OR查询会比较影响性能？<br>    1，OR操作分配的内存空间不可预估，而且会很大<br>    2，合并的时候要遍历所有的倒排链<br>    3，倒排链越长意味着最后排序的数据就越多</p><h3><span id="过滤统计排序">过滤统计排序</span></h3><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrj3gd61tj30hs01rt8i.jpg" alt></p><p><strong>问题4：</strong> 在分布式的集群中，假设我们要取销量排序第三页的宝贝，即s=80&amp;n=40。要如何获取？<br><strong>需要考虑的问题：</strong>    </p><pre><code>- 我们的宝贝分布在不同的机器上- 排序效率要高- 也许某台机器上销量最差的宝贝也比其它机器上销量最好的宝贝要好</code></pre><p><strong>解决方案：</strong></p><pre><code>每台Searcher机器返回Top120条结果Merger再将所有机器返回的Top120宝贝混到一起，再Heapsort取出Top 120</code></pre><h3><span id="rank">Rank</span></h3><p>常见问题：</p><ul><li>在人气，或者销量排序的时候马太效应怎么解决？</li><li>马太效应：宝贝销量越高排名越靠前，越靠前销量越好</li></ul><p>首先：宝贝销量越高，确实搜索的排名会靠前，但是排名越靠前，只能说明搜索引导的成交会高一些，但是不会在大程度上影响宝贝的销量，因为搜索本身带来的成交才20-30%</p><h4><span id="常用排序规则">常用排序规则</span></h4><ul><li><p>阿基米德排序：</p><pre><code>相关性(标题类目 亿级) + 下架时间(ends 千万级)  + 宝贝人气(百万级) + 卖家质量分(十万)</code></pre></li><li><p>人气排序：</p><pre><code>标题 （1）+ 类目（1）+ 宝贝人气（1）+ 卖（0.2）肯定不是用户想要的</code></pre></li><li><p>单维度排序：</p><pre><code>按照：销量，信用，价格，总价，单价排序单维度排序下不会做打散，可以认为这是用户的意愿只想找价格低的</code></pre></li><li><p>类目混排：</p><pre><code>类目混排会对宝贝按类目进行分档，档内才按价格排序打散：卖家打散，款式打散</code></pre></li></ul><h3><span id="anti-spam">Anti-spam</span></h3><p>降权与屏蔽<br>常见的作弊类型</p><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrj7jmx7tj30hs02c3yc.jpg" alt> </p><ul><li>为了提升用户体验，保证搜索的公平性，作弊是卖家通过一些不正当的行为，提高自己的搜索排名。</li><li>虚假交易，包括炒作信用和炒作销量。以增加“会员积累信用”为目的或通过炒作商品销量提高商品人气而发布的商品，会被判定为虚假交易商品。</li><li>通过发布完全相同的商品来争取更多的展现机会，直接降低了搜索的精准度，降低了消费者的购物体验，也是搜索控制的重点。</li><li>商品描述不详、无实际商品、仅提供发布者联系方式以及非商品信息的商品，判定为发布广告商品。</li><li>换宝贝：指卖家为了累积销量或人气，修改原有的商品的标题、价格、图片、详情等变成另外一种商品继续出售。</li><li>Sku作弊：滥用商品属性（如：套餐），将常规商品和瑕疵品、单机、样机、模型、二手等非常规商品放在一个宝贝里出售，且一口价为非常规商品的价格。</li></ul><h2><span id="电商系统搜索和门户搜索的不同">电商系统搜索和门户搜索的不同</span></h2><p><img src="https://ws1.sinaimg.cn/large/006ZfUPvgy1fwrj8i8rs7j30hs0ejaaa.jpg" alt></p><p>（注解：网站的PR值（全称为PageRank），是Google搜索排名算法中的一个组成部分，级别从1到10级，10级为满分，PR值越高说明该网页在搜索排名中的地位越重要）</p><h2><span id="小结">小结：</span></h2><p>商业电商搜索算法另外两个重要技术，一个是类目体系建立和应用，另一个是个性化技术。</p><p>类目体系目前主要使用机器学习的方法进行训练，个性化主要通过用户画像进行Query改写来实现。搜索算法是一个非常值得一个电商产品持续投入的技术，一方面如果技术人员要有良好的技术背景，可以借鉴很多成熟的技术，避免重复造轮子； 另一方面，每个产品的搜索都有自身的特点，需要深入研究产品的特性给出合理的解决方案。</p><p>转载: <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1540972907&amp;ver=1215&amp;signature=OasCCvdyowfRZS1DjPxCyF1PoJxnXruAR78UZEqR1FBe6DAF6IZ7S*LqUey7StoANe*aVo8pax3hZI7QAKIHN1R3c51JBqX5l7ja-30zpsdw4gRxDdxeQNx7FgIaM30X&amp;new=1" target="_blank" rel="noopener">米么骚客</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;什么搜索引擎&quot;&gt;什么搜索引擎&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;搜索引擎(search engine)是指根据一定的策略、运用特定的计算机程序搜集互联网上的信息，在对信息进行组织和处理后，为用户提供检索服务的系统。数据其实就是一块块的砖头，当用户需要的时候搜
      
    
    </summary>
    
      <category term="大型分布式网站架构" scheme="http://calfgz.github.io/categories/%E5%A4%A7%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/tags/ElasticSearch/"/>
    
      <category term="分布式架构" scheme="http://calfgz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>服务发现：ZooKeeper vs etcd vs Consul</title>
    <link href="http://calfgz.github.io//blog/2018/08/service-discovery-zookeepervsetcdvsconsul.html"/>
    <id>http://calfgz.github.io//blog/2018/08/service-discovery-zookeepervsetcdvsconsul.html</id>
    <published>2018-08-15T08:54:43.000Z</published>
    <updated>2019-04-28T07:38:07.345Z</updated>
    
    <content type="html"><![CDATA[<p>【编者的话】本文对比了Zookeeper、etcd和Consul三种服务发现工具，探讨了最佳的服务发现解决方案，仅供参考。</p><h2><span id="背景">背景</span></h2><p>如果使用预定义的端口，服务越多，发生冲突的可能性越大，毕竟，不可能有两个服务监听同一个端口。<br>管理一个拥挤的比方说被几百个服务所使用的所有端口的列表，本身就是一个挑战，添加到该列表后，这些服务需要的数据库和数量会日益增多。<br>因此我们应该部署无需指定端口的服务，并且让Docker为我们分配一个随机的端口。唯一的问题是我们需要发现端口号，并且让别人知道。</p><p><img src="https://technologyconversations.files.wordpress.com/2015/09/single-node-docker1.png" alt></p><p>当我们开始在一个分布式系统上部署服务到其中一台服务器上时，事情会变得更加复杂，我们可以选择预先定义哪吧服务器运行哪个服务的方式，但这会导致很多问题。<br>我们应该尽我们所能尽量利用服务器资源，但是如果预先定义每个服务的部署位置，那么要实现尽量利用服务器资源是几乎不可能的。<br>另一个问题是服务的自动伸缩将会非常困难，更不用说自动恢复了，比方说服务器故障。<br>另一方面，如果我们将服务部署到某台只有最少数量的容器在运行的服务器上，我们需要添加IP地址到数据列表中，这些数据需要可以被发现并存储在某处。</p><p><img src="https://technologyconversations.files.wordpress.com/2015/09/multi-node-docker1.png?w=625&amp;h=196" alt></p><p>当我们需要存储和发现一些与正在工作的服务相关的信息时，还有很多其他的例子。</p><p>为了能够定位服务，我们需要至少接下来的两个有用的步骤。</p><ul><li><strong>服务注册</strong>——该步骤存储的信息至少包括正在运行的服务的主机和端口信息</li><li><strong>服务发现</strong>——该步骤允许其他用户可以发现在服务注册阶段存储的信息。</li></ul><p>除了上述的步骤，我们还需要考虑其他方面。<br>如果一个服务停止工作并部署/注册了一个新的服务实例，那么该服务是否应该注销呢？<br>当有相同服务的多个副本时咋办？<br>我们该如何做负载均衡呢？<br>如果一个服务器宕机了咋办？<br>所有这些问题都与注册和发现阶段紧密关联。现在，我们限定只在服务发现的范围里（常见的名字，围绕上述步骤）以及用于服务发现任务的工具，它们中的大多数采用了高可用的分布式键/值存储。</p><h2><span id="服务发现工具">服务发现工具</span></h2><p>服务发现工具的主要目标是用来服务查找和相互对话，为此该工具需要知道每个服务，这不是一个新概念，在Docker之前就已经存在很多类似的工具了，然而，容器带给了这些工具一个全新水平的需求。</p><p>服务发现背后的基本思想是对于服务的每一个新实例（或应用程序），能够识别当前环境和存储相关信息。存储的注册表信息本身通常采用键/值对的格式，由于服务发现经常用于分布式系统，所以要求这些信息可伸缩、支持容错和分布式集群中的所有节点。这种存储的主要用途是给所有感兴趣的各方提供最起码诸如服务IP地址和端口这样的信息，用于它们之间的相互通讯，这些数据还经常扩展到其它类型的信息服务发现工具倾向于提供某种形式的API，用于服务自身的注册以及服务信息的查找。</p><p>比方说我们有两个服务，一个是提供方，另一个是第一个服务的消费者，一旦部署了服务提供方，就需要在服务发现注册表中存储其信息。接着，当消费者试图访问服务提供者时，它首先查询服务注册表，使用获取到的IP地址和端口来调用服务提供者。为了与注册表中的服务提供方的具体实现解耦，我们常常采用某种代理服务。这样消费者总是向固定IP地址的代理请求信息，代理再依次使用服务发现来查找服务提供方信息并重定向请求，在本文中我们稍后通过反向代理来实现。现在重要的是要理解基于三种角色（服务消费者、提供者和代理）的服务发现流程。</p><p>服务发现工具要查找的是数据，至少我们应该能够找出服务在哪里？服务是否健康和可用？配置是什么样的？既然我们正在多台服务器上构建一个分布式系统，那么该工具需要足够健壮，保证其中一个节点的宕机不会危及数据，同时，每个节点应该有完全相同的数据副本，进一步地，我们希望能够以任何顺序启动服务、杀死服务或者替换服务的新版本，我们还应该能够重新配置服务并且查看到数据相应的变化。</p><p>让我们看一下一些常用的选项来完成我们上面设定的目标。</p><h2><span id="手动配置">手动配置</span></h2><p>大多数服务仍然是需要手动管理的，我们预先决定在何处部署服务、如何配置和希望不管什么原因，服务都将继续正常工作，直到天荒地老。这样的目标不是可以轻易达到的。部署第二个服务实例意味着我们需要启动全程的手动处理，我们需要引入一台新的服务器，或者找出哪一台服务器资源利用率较低，然后创建一个新的配置集并启动服务。情况或许会变得越来越复杂，比方说，硬件故障导致的手动管理下的反应时间变得很慢。可见性是另外一个痛点，我们知道什么是静态配置，毕竟是我们预先准备好的，然而，大多数的服务有很多动态生成的信息，这些信息不是轻易可见的，也没有一个单独的地方供我们在需要时参考这些数据。</p><p>反应时间会不可避免的变慢，鉴于存在许多需要手动处理的移动组件，故障恢复和监控也会变得非常难以管理。</p><p>尽管在过去或者当服务/服务器数量很少的时候有借口不做这项工作，随着服务发现工具的出现，这个借口已经不存在了。</p><h2><span id="zookeeper">Zookeeper</span></h2><p><strong>Zookeeper</strong>是这种类型的项目中历史最悠久的之一，它起源于Hadoop，帮助在Hadoop集群中维护各种组件。它非常成熟、可靠，被许多大公司（YouTube、eBay、雅虎等）使用。其数据存储的格式类似于文件系统，如果运行在一个服务器集群中，Zookeper将跨所有节点共享配置状态，每个集群选举一个领袖，客户端可以连接到任何一台服务器获取数据。</p><p>Zookeeper的主要优势是其成熟、健壮以及丰富的特性，然而，它也有自己的缺点，其中采用Java开发以及复杂性是罪魁祸首。尽管Java在许多方面非常伟大，然后对于这种类型的工作还是太沉重了，Zookeeper使用Java以及相当数量的依赖使其对于资源竞争非常饥渴。因为上述的这些问题，Zookeeper变得非常复杂，维护它需要比我们期望从这种类型的应用程序中获得的收益更多的知识。这部分地是由于丰富的特性反而将其从优势转变为累赘。应用程序的特性功能越多，就会有越大的可能性不需要这些特性，因此，我们最终将会为这些不需要的特性付出复杂度方面的代价。</p><p>Zookeeper为其他项目相当大的改进铺平了道路，“大数据玩家“在使用它，因为没有更好的选择。今天，Zookeeper已经老态龙钟了，我们有了更好的选择。</p><h2><span id="etcd-registrator-confd">etcd + Registrator + Confd</span></h2><h3><span id="etcd">etcd</span></h3><p><strong>etcd</strong>是一个采用HTTP协议的健/值对存储系统，它是一个分布式和功能层次配置系统，可用于构建服务发现系统。其很容易部署、安装和使用，提供了可靠的数据持久化特性。它是安全的并且文档也十分齐全。</p><p>etcd比Zookeeper是比更好的选择，因为它很简单，然而，它需要搭配一些第三方工具才可以提供服务发现功能。<br><img src="https://technologyconversations.files.wordpress.com/2015/09/etcd1.png?w=625&amp;h=196" alt="etcd.png"></p><p>现在，我们有一个地方来存储服务相关信息，我们还需要一个工具可以自动发送信息给etcd。但在这之后，为什么我们还需要手动把数据发送给etcd呢？即使我们希望手动将信息发送给etcd，我们通常情况下也不会知道是什么信息。记住这一点，服务可能会被部署到一台运行最少数量容器的服务器上，并且随机分配一个端口。理想情况下，这个工具应该监视所有节点上的Docker容器，并且每当有新容器运行或者现有的一个容器停止的时候更新etcd，其中的一个可以帮助我们达成目标的工具就是Registrator。</p><h3><span id="registrator">Registrator</span></h3><p><strong>Registrator</strong>通过检查容器在线或者停止运行状态自动注册和去注册服务，它目前支持etcd、Consul和SkyDNS 2。</p><p>Registrator与etcd是一个简单但是功能强大的组合，可以运行很多先进的技术。每当我们打开一个容器，所有数据将被存储在etcd并传播到集群中的所有节点。我们将决定什么信息是我们的。<br><img src="https://technologyconversations.files.wordpress.com/2015/09/etcd-registrator2.png?w=625&amp;h=196" alt="etcd-registrator.png"></p><p>上述的拼图游戏还缺少一块，我们需要一种方法来创建配置文件，与数据都存储在etcd，通过运行一些命令来创建这些配置文件。</p><h3><span id="confd">Confd</span></h3><p><strong>Confd</strong>是一个轻量级的配置管理工具，常见的用法是通过使用存储在etcd、consul和其他一些数据登记处的数据保持配置文件的最新状态，它也可以用来在配置文件改变时重新加载应用程序。换句话说，我们可以用存储在etcd（或者其他注册中心）的信息来重新配置所有服务。<br><img src="https://technologyconversations.files.wordpress.com/2015/09/etcd-registrator-confd2.png?w=625&amp;h=196" alt="etcd-registrator-confd.png"></p><h3><span id="对于etcd-registrator和confd组合的最后的思考">对于etcd、Registrator和Confd组合的最后的思考</span></h3><p>当etcd、Registrator和Confd结合时，可以获得一个简单而强大的方法来自动化操作我们所有的服务发现和需要的配置。这个组合还展示了“小”工具正确组合的有效性，这三个小东西可以如我们所愿正好完成我们需要达到的目标，若范围稍微小一些，我们将无法完成我们面前的目标，而另一方面如果他们设计时考虑到更大的范围，我们将引入不必要的复杂性和服务器资源开销。</p><p>在我们做出最后的判决之前，让我们看看另一个有相同目标的工具组合，毕竟，我们不应该满足于一些没有可替代方案的选择。</p><h2><span id="consul">Consul</span></h2><h3><span id="consul">Consul</span></h3><p><strong>Consul</strong>是强一致性的数据存储，使用gossip形成动态集群。它提供分级键/值存储方式，不仅可以存储数据，而且可以用于注册器件事各种任务，从发送数据改变通知到运行健康检查和自定义命令，具体如何取决于它们的输出。</p><p>与Zookeeper和etcd不一样，Consul内嵌实现了服务发现系统，所以这样就不需要构建自己的系统或使用第三方系统。这一发现系统除了上述提到的特性之外，还包括节点健康检查和运行在其上的服务。</p><p>Zookeeper和etcd只提供原始的键/值队存储，要求应用程序开发人员构建他们自己的系统提供服务发现功能。而Consul提供了一个内置的服务发现的框架。客户只需要注册服务并通过DNS或HTTP接口执行服务发现。其他两个工具需要一个亲手制作的解决方案或借助于第三方工具。</p><p>Consul为多种数据中心提供了开箱即用的原生支持，其中的gossip系统不仅可以工作在同一集群内部的各个节点，而且还可以跨数据中心工作。<br><img src="https://technologyconversations.files.wordpress.com/2015/09/consul2.png?w=625&amp;h=204" alt="consul1.png"></p><p>Consul还有另一个不错的区别于其他工具的功能，它不仅可以用来发现已部署的服务以及其驻留的节点信息，还通过HTTP请求、TTLs（time-to-live）和自定义命令提供了易于扩展的健康检查特性。</p><h3><span id="registrator">Registrator</span></h3><p><strong>Registrator</strong>有两个Consul协议，其中consulkv协议产生类似于etcd协议的结果。</p><p>除了通常的IP和端口存储在etcd或consulkv协议中之外，Registrator consul协议存储了更多的信息，我们可以得到服务运行节点的信息，以及服务ID和名称。我们也可以借助于一些额外的环境变量按照一定的标记存储额外的信息。<br><img src="https://technologyconversations.files.wordpress.com/2015/09/consul-registrator2.png?w=625&amp;h=204" alt="consul-registrator1.png"></p><h3><span id="consul-template">Consul-template</span></h3><p>confd可以像和etce搭配一样用于Consul，不过Consul有自己的模板服务，其更适配Consul。</p><p>通过从Consul获得的信息，Consul-template是一个非常方便的创建文件的途径，还有一个额外的好处就是在文件更新后可以运行任意命令，正如confd，Consul-template也可以使用Go模板格式。<br><img src="https://technologyconversations.files.wordpress.com/2015/09/consul-registrator-consul-template2.png?w=625&amp;h=204" alt="consul-registrator-consul-template1.png"></p><h3><span id="consul健康检查-web界面和数据中心">Consul健康检查、Web界面和数据中心</span></h3><p>监控集群节点和服务的健康状态与测试和部署它们一样的重要。虽然我们应该向着拥有从来没有故障的稳定的环境努力，但我们也应该承认，随时会有意想不到的故障发生，时刻准备着采取相应的措施。例如我们可以监控内存使用情况，如果达到一定的阈值，那么迁移一些服务到集群中的另外一个节点，这将是在发生“灾难”前执行的一个预防措施。另一方面，并不是所有潜在的故障都可以被及时检测到并采取措施。单个服务可能会齿白，一个完整的节点也可能由于硬件故障而停止工作。在这种情况下我们应该准备尽快行动，例如一个节点替换为一个新的并迁移失败的服务。Consul有一个简单的、优雅的但功能强大的方式进行健康检查，当健康阀值达到一定数目时，帮助用户定义应该执行的操作。</p><p>如果用户Google搜索“etcd ui”或者“etec dashboard”时，用户可能看到只有几个可用的解决方案，可能会问为什么我们还没有介绍给用户，这个原因很简单，etcd只是键/值对存储，仅此而已。通过一个UI呈现数据没有太多的用处，因为我们可以很容易地通过etcdctl获得这些数据。这并不意味着etcd UI是无用的，但鉴于其有限的使用范围，它不会产生多大影响。</p><p>Consu不仅仅是一个简单的键/值对存储，正如我们已经看到的，除了存储简单的键/值对，它还有一个服务的概念以及所属的数据。它还可以执行健康检查，因此成为一个好的候选dashboard，在上面可以看到我们的节点的状态和运行的服务。最后，它支持了多数据中心的概念。所有这些特性的结合让我们从不同的角度看到引入dashboard的必要性。</p><p>通过Consul Web界面，用户可以查看所有的服务和节点、监控健康检查状态以及通过切换数据中心读取设置键/值对数据。<br><img src="https://technologyconversations.files.wordpress.com/2015/09/consul-nodes.png?w=625&amp;h=242" alt="consul-nodes.png"></p><h3><span id="对于consul-registrator-template-健康检查和web-ui的最终思考">对于Consul、Registrator、Template、健康检查和Web UI的最终思考</span></h3><p>Consul以及上述我们一起探讨的工具在很多情况下提供了比etcd更好的解决方案。这是从内心深处为了服务架构和发现而设计的方案，简单而强大。它提供了一个完整的同时不失简洁的解决方案，在许多情况下，这是最佳的服务发现以及满足健康检查需求的工具。</p><h2><span id="结论">结论</span></h2><p>所有这些工具都是基于相似的原则和架构，它们在节点上运行，需要仲裁来运行，并且都是强一致性的，都提供某种形式的键/值对存储。</p><p><strong>Zookeeper</strong>是其中最老态龙钟的一个，使用年限显示出了其复杂性、资源利用和尽力达成的目标，它是为了与我们评估的其他工具所处的不同时代而设计的（即使它不是老得太多）。</p><p><strong>etcd</strong>、<strong>Registrator</strong>和<strong>Confd</strong>是一个非常简单但非常强大的组合，可以解决大部分问题，如果不是全部满足服务发现需要的话。它还展示了我们可以通过组合非常简单和特定的工具来获得强大的服务发现能力，它们中的每一个都执行一个非常具体的任务，通过精心设计的API进行通讯，具备相对自治工作的能力，从架构和功能途径方面都是微服务方式。</p><p><strong>Consul</strong>的不同之处在于无需第三方工具就可以原生支持多数据中心和健康检查，这并不意味着使用第三方工具不好。实际上，在这篇博客里我们通过选择那些表现更佳同时不会引入不必要的功能的的工具，尽力组合不同的工具。使用正确的工具可以获得最好的结果。如果工具引入了工作不需要的特性，那么工作效率反而会下降，另一方面，如果工具没有提供工作所需要的特性也是没有用的。Consul很好地权衡了权重，用尽量少的东西很好的达成了目标。</p><p>Consul使用gossip来传播集群信息的方式，使其比etcd更易于搭建，特别是对于大的数据中心。将存储数据作为服务的能力使其比etcd仅仅只有健/值对存储的特性更加完整、更有用（即使Consul也有该选项）。虽然我们可以在etcd中通过插入多个键来达成相同的目标，Consul的服务实现了一个更紧凑的结果，通常只需要一次查询就可以获得与服务相关的所有数据。除此之外，Registrator很好地实现了Consul的两个协议，使其合二为一，特别是添加Consul-template到了拼图中。Consul的Web UI更是锦上添花般地提供了服务和健康检查的可视化途径。</p><p>我不能说Consul是一个明确的赢家，而是与etcd相比其有一个轻微的优势。服务发现作为一个概念，以及作为工具都很新，我们可以期待在这一领域会有许多的变化。秉承开放的心态，大家可以对本文的建议持保留态度，尝试不同的工具然后做出自己的结论。</p><p>原文链接：<a href="https://technologyconversations.com/2015/09/08/service-discovery-zookeeper-vs-etcd-vs-consul/" target="_blank" rel="noopener">Service Discovery: Zookeeper vs etcd vs Consul</a>（翻译：胡震）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;【编者的话】本文对比了Zookeeper、etcd和Consul三种服务发现工具，探讨了最佳的服务发现解决方案，仅供参考。&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;背景&quot;&gt;背景&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;如果使用预定义的端口，服务越多，发生冲突的可能性越大，毕竟，不可能有两个
      
    
    </summary>
    
      <category term="SpringCloud" scheme="http://calfgz.github.io/categories/SpringCloud/"/>
    
    
      <category term="Consul" scheme="http://calfgz.github.io/tags/Consul/"/>
    
      <category term="ZooKeeper" scheme="http://calfgz.github.io/tags/ZooKeeper/"/>
    
      <category term="etcd" scheme="http://calfgz.github.io/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>log4j2的配置说明</title>
    <link href="http://calfgz.github.io//blog/2018/08/log4j2-configration.html"/>
    <id>http://calfgz.github.io//blog/2018/08/log4j2-configration.html</id>
    <published>2018-08-02T08:48:30.000Z</published>
    <updated>2019-04-28T07:38:07.344Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="log4j2配置文件加载顺序">log4j2配置文件加载顺序</span></h2><p>log4j2的配置文件只能用xml、json、jsn三种格式，默认情况下由系统自动加载，系统加载 classpath 目录如下的配置文件。</p><ul><li>log4j-test.json 或者 log4j-test.jsn 文件 </li><li>log4j2-test.xml </li><li>log4j-test.json 或者 log4j-test.jsn 文件 </li><li>log4j2.xml<br>加载优先级由上向下，且只加载其一。</li></ul><h2><span id="log4j配置项说明">log4j配置项说明</span></h2><h3><span id="configration">Configration</span></h3><table><thead><tr><th>字段</th><th>描述</th></tr></thead><tbody><tr><td>status</td><td>日志级别 默认值为最高级别 OFF</td></tr><tr><td>monitorInterval</td><td>监控间隔，例如：monitorInterval=”600” 指log4j2每隔600秒（10分钟），自动监控该配置文件是否有变化，如果变化，则自动根据文件内容重新配置</td></tr></tbody></table><h3><span id="appenders定义输出类型">Appenders定义输出类型</span></h3><h4><span id="child">Child</span></h4><table><thead><tr><th>字段</th><th>描述</th></tr></thead><tbody><tr><td>Layout</td><td>输出类型的模板、布局</td></tr><tr><td>Filters</td><td>过滤器，过滤掉不需要的日志</td></tr></tbody></table><h4><span id="filtersthresholdfilter">Filters.ThresholdFilter</span></h4><table><thead><tr><th>字段</th><th>描述</th></tr></thead><tbody><tr><td>level</td><td>输出级别，例：level=”info”,日志级别为info或者以上(匹配的界别)</td></tr><tr><td>onMatch</td><td>DENY/ACCEPT 禁止或者接受（是否接受匹配）</td></tr><tr><td>onMismatch</td><td>DENY/NEUTRAL （是否接受其他高于level的级别）</td></tr></tbody></table><pre><code>一般的组合为：</code></pre><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"warn"</span> <span class="attr">onMatch</span>=<span class="string">"DENY"</span> <span class="attr">onMismatch</span>=<span class="string">"NEUTRAL"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"info"</span> <span class="attr">onMatch</span>=<span class="string">"ACCEPT"</span> <span class="attr">onMismatch</span>=<span class="string">"DENY"</span>/&gt;</span></span><br></pre></td></tr></table></figure><h3><span id="loggers-注册日志输出对象">Loggers 注册日志输出对象</span></h3><h4><span id="logger-日志输出对象">Logger 日志输出对象</span></h4><table><thead><tr><th>字段</th><th>解释</th></tr></thead><tbody><tr><td>name</td><td>输出对象名称</td></tr><tr><td>level</td><td>日志级别</td></tr><tr><td>additivity</td><td>是否冒泡，既在本层输出日志后是否需要在父对象上输出该日志，默认为 true</td></tr></tbody></table><p>代码说明<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 始祖日志输出对象 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"Appender3"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 父日志输出对象 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">level</span>=<span class="string">"warn"</span> <span class="attr">name</span>=<span class="string">"com.person"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"Appender1"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 继承了com.person 的子日志输出对象 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">logger</span> <span class="attr">level</span>=<span class="string">"info"</span> <span class="attr">name</span>=<span class="string">"com.person.man"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"Appender2"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>在 com.person.man 包下面或者类下面执行以下代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">logger.info(<span class="string">"man info"</span>);    <span class="comment">// Appender1、Appender2 有输出</span></span><br><span class="line">logger.error(<span class="string">"man error"</span>);  <span class="comment">// Appender1、Appender2 有输出</span></span><br><span class="line">logger.warn(<span class="string">"man warn"</span>);    <span class="comment">// Appender1、Appender2 有输出</span></span><br></pre></td></tr></table></figure><h2><span id="log4j2-配置实例">log4j2 配置实例</span></h2><p>Maven引入依赖包<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- slf4j + log4j2 begin --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span> <span class="comment">&lt;!-- 桥接：告诉Slf4j使用Log4j2 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-slf4j-impl<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span> <span class="comment">&lt;!-- 桥接：告诉commons logging使用Log4j2 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-jcl<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>根据日志级别输出到不同文件，按日期进行封存日志</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- configure.status 为设置日志输出级别，级别如下：OFF 、FATAL 、ERROR、WARN、INFO、DEBUG、TRACE 、ALL  --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- configure.monitorInterval 监控间隔</span></span><br><span class="line"><span class="comment">         指log4j2每隔600秒（10分钟），自动监控该配置文件是否有变化，如果变化，则自动根据文件内容重新配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">status</span>=<span class="string">"off"</span> <span class="attr">monitorInterval</span>=<span class="string">"600"</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LOG_HOME"</span>&gt;</span>E:/webbase/logs<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LOG_BACK_HOME"</span>&gt;</span>$&#123;LOG_HOME&#125;/backup<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"ERROR_FILE_NAME"</span>&gt;</span>error<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"WARN_FILE_NAME"</span>&gt;</span>warn<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"INFO_FILE_NAME"</span>&gt;</span>info<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"DEBUG_FILE_NAME"</span>&gt;</span>debug<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Appenders</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Console</span> <span class="attr">name</span>=<span class="string">"Console"</span> <span class="attr">target</span>=<span class="string">"SYSTEM_OUT"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">"%d&#123;HH:mm:ss.SSS&#125; &#123;%t&#125; %-5level %logger&#123;36&#125; - %msg%n"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Console</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置日志输出文件名字     追加读写 --&gt;</span>    </span><br><span class="line">    <span class="comment">&lt;!-- Error console log --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">RollingFile</span> <span class="attr">name</span>=<span class="string">"ErrLog"</span> <span class="attr">fileName</span>=<span class="string">"$&#123;LOG_HOME&#125;/$&#123;ERROR_FILE_NAME&#125;.log"</span> <span class="attr">filePattern</span>=<span class="string">"$&#123;LOG_BACK_HOME&#125;/$$&#123;date:yyyy-MM&#125;/$&#123;ERROR_FILE_NAME&#125;.%d&#123;yyyy-MM-dd&#125;.log"</span> <span class="attr">append</span>=<span class="string">"true"</span>&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 输出格式 --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">"%date&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %level [%thread][%file:%line] - %msg%n"</span>/&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 设置策略 --&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">Policies</span>&gt;</span>    </span><br><span class="line">            <span class="comment">&lt;!-- 基于时间的触发策略。该策略主要是完成周期性的log文件封存工作。有两个参数：  </span></span><br><span class="line"><span class="comment">                interval，integer型，指定两次封存动作之间的时间间隔。单位:以日志的命名精度来确定单位，  </span></span><br><span class="line"><span class="comment">                    比如yyyy-MM-dd-HH 单位为小时，yyyy-MM-dd-HH-mm 单位为分钟  </span></span><br><span class="line"><span class="comment">                modulate，boolean型，说明是否对封存时间进行调制。若modulate=true，  </span></span><br><span class="line"><span class="comment">                    则封存时间将以0点为边界进行偏移计算。比如，modulate=true，interval=4hours，  </span></span><br><span class="line"><span class="comment">                    那么假设上次封存日志的时间为03:00，则下次封存日志的时间为04:00，  </span></span><br><span class="line"><span class="comment">                    之后的封存时间依次为08:00，12:00，16:00  </span></span><br><span class="line"><span class="comment">             --&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">TimeBasedTriggeringPolicy</span> <span class="attr">interval</span>=<span class="string">"1"</span> <span class="attr">modulate</span>=<span class="string">"true"</span> /&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;/<span class="name">Policies</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">Filters</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"error"</span> <span class="attr">onMatch</span>=<span class="string">"ACCEPT"</span> <span class="attr">onMismatch</span>=<span class="string">"DENY"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">Filters</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">RollingFile</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Warn console log --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">RollingFile</span> <span class="attr">name</span>=<span class="string">"WarnLog"</span> <span class="attr">fileName</span>=<span class="string">"$&#123;LOG_HOME&#125;/$&#123;WARN_FILE_NAME&#125;.log"</span> <span class="attr">filePattern</span>=<span class="string">"$&#123;LOG_BACK_HOME&#125;/$$&#123;date:yyyy-MM&#125;/$&#123;WARN_FILE_NAME&#125;.%d&#123;yyyy-MM-dd&#125;.log"</span> <span class="attr">append</span>=<span class="string">"true"</span>&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 输出格式 --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">"%date&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %level [%thread][%file:%line] - %msg%n"</span>/&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 设置策略 --&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">Policies</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;<span class="name">TimeBasedTriggeringPolicy</span> <span class="attr">interval</span>=<span class="string">"1"</span> <span class="attr">modulate</span>=<span class="string">"true"</span> /&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;/<span class="name">Policies</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">Filters</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"error"</span> <span class="attr">onMatch</span>=<span class="string">"DENY"</span> <span class="attr">onMismatch</span>=<span class="string">"NEUTRAL"</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"warn"</span> <span class="attr">onMatch</span>=<span class="string">"ACCEPT"</span> <span class="attr">onMismatch</span>=<span class="string">"DENY"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">Filters</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">RollingFile</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- Info console log --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">RollingFile</span> <span class="attr">name</span>=<span class="string">"InfoLog"</span> <span class="attr">fileName</span>=<span class="string">"$&#123;LOG_HOME&#125;/$&#123;INFO_FILE_NAME&#125;.log"</span> <span class="attr">filePattern</span>=<span class="string">"$&#123;LOG_BACK_HOME&#125;/$$&#123;date:yyyy-MM&#125;/$&#123;INFO_FILE_NAME&#125;.%d&#123;yyyy-MM-dd&#125;.log"</span> <span class="attr">append</span>=<span class="string">"true"</span>&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 输出格式 --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">"%date&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %level [%thread][%file:%line] - %msg%n"</span>/&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 设置策略 --&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">Policies</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;<span class="name">TimeBasedTriggeringPolicy</span> <span class="attr">interval</span>=<span class="string">"1"</span> <span class="attr">modulate</span>=<span class="string">"true"</span> /&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;/<span class="name">Policies</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">Filters</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"warn"</span> <span class="attr">onMatch</span>=<span class="string">"DENY"</span> <span class="attr">onMismatch</span>=<span class="string">"NEUTRAL"</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"info"</span> <span class="attr">onMatch</span>=<span class="string">"ACCEPT"</span> <span class="attr">onMismatch</span>=<span class="string">"DENY"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">Filters</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">RollingFile</span>&gt;</span> </span><br><span class="line">    <span class="comment">&lt;!-- Debug console log --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">RollingFile</span> <span class="attr">name</span>=<span class="string">"DebugLog"</span> <span class="attr">fileName</span>=<span class="string">"$&#123;LOG_HOME&#125;/$&#123;DEBUG_FILE_NAME&#125;.log"</span> <span class="attr">filePattern</span>=<span class="string">"$&#123;LOG_BACK_HOME&#125;/$$&#123;date:yyyy-MM&#125;/$&#123;DEBUG_FILE_NAME&#125;.%d&#123;yyyy-MM-dd&#125;.log"</span> <span class="attr">append</span>=<span class="string">"true"</span>&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 输出格式 --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">"%date&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %level [%thread][%file:%line] - %msg%n"</span>/&gt;</span>  </span><br><span class="line">        <span class="comment">&lt;!-- 设置策略 --&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">Policies</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;<span class="name">TimeBasedTriggeringPolicy</span> <span class="attr">interval</span>=<span class="string">"1"</span> <span class="attr">modulate</span>=<span class="string">"true"</span> /&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;/<span class="name">Policies</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">Filters</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"info"</span> <span class="attr">onMatch</span>=<span class="string">"DENY"</span> <span class="attr">onMismatch</span>=<span class="string">"NEUTRAL"</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ThresholdFilter</span> <span class="attr">level</span>=<span class="string">"debug"</span> <span class="attr">onMatch</span>=<span class="string">"ACCEPT"</span> <span class="attr">onMismatch</span>=<span class="string">"DENY"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">Filters</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">RollingFile</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">Appenders</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Loggers</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Logger</span> <span class="attr">name</span>=<span class="string">"org.webbase"</span> <span class="attr">level</span>=<span class="string">"debug"</span> <span class="attr">additivity</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"DebugLog"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"InfoLog"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Logger</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Root</span> <span class="attr">level</span>=<span class="string">"warn"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"WarnLog"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"ErrLog"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">"Console"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Loggers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3><span id="timebasedtriggeringpolicy">TimeBasedTriggeringPolicy</span></h3><table><thead><tr><th>属性</th><th>解释</th></tr></thead><tbody><tr><td>interval</td><td>（integer）该属性是相对 RollingFile.filePattern 中的。%d{yyyy-MM-dd}值,例：filePattern=”xxx%d{yyyy-MM-dd}xx” interval=”2” 表示将2天一个日志文件；filePattern=”xxx%d{yyyy-MM-dd-HH}xx” interval=”1”表示一个小时一个日志文件</td></tr><tr><td>modulate</td><td>（boolean）以0点为边界进行偏移计算</td></tr></tbody></table><h2><span id="log4j2-logger加载规则">log4j2 logger加载规则</span></h2><ul><li>logger name 相同时，以 level 级别高的为准</li><li>logger name = “org” 会被 name=”org.xxx” 继承</li><li>logger 中的 additivity=”true” 表示子日志所获得的日志也会在父日志中出现，即使 父日志的 level 远高于子日志的 level</li><li>当子日志 level 大于 父日志时，父日志只能接收到子日志过滤后的日志</li></ul><p>转载: <a href="https://blog.csdn.net/u010201484/article/details/51723455" target="_blank" rel="noopener">log4j2入门学习与总结</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;log4j2配置文件加载顺序&quot;&gt;log4j2配置文件加载顺序&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;log4j2的配置文件只能用xml、json、jsn三种格式，默认情况下由系统自动加载，系统加载 classpath 目录如下的配置文件。&lt;/p&gt;
&lt;ul&gt;
&lt;l
      
    
    </summary>
    
      <category term="Log4j" scheme="http://calfgz.github.io/categories/Log4j/"/>
    
    
      <category term="Log4j" scheme="http://calfgz.github.io/tags/Log4j/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch实战应用建议</title>
    <link href="http://calfgz.github.io//blog/2018/07/elasticsearch-suggest.html"/>
    <id>http://calfgz.github.io//blog/2018/07/elasticsearch-suggest.html</id>
    <published>2018-07-10T02:15:15.000Z</published>
    <updated>2019-04-28T07:38:07.344Z</updated>
    
    <content type="html"><![CDATA[<h3><span id="elasticsearch-索引的设计">Elasticsearch 索引的设计</span></h3><h4><span id="单一索引vs基于时间的索引">单一索引VS基于时间的索引</span></h4><h5><span id="单一索引的问题">单一索引的问题：</span></h5><ul><li>不能更新Mapping。<br>  比如：主分片数不可以修改（除非reindex）。</li><li>无法灵活、快速地扩展。</li><li>更适合固定、小型数据集。</li></ul><h5><span id="基于时间的索引面临的问题">基于时间的索引面临的问题：</span></h5><ul><li>如何确定间隔？<ul><li>数据量</li><li>变更频率</li><li>默认尝试每周为单位分割——建议</li></ul></li><li>如何实施？<ul><li>索引模板</li></ul></li></ul><h4><span id="定义索引注意事项">定义索引注意事项</span></h4><p>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;facet_internet_access_minute&quot;:&#123;</span><br><span class="line">        &quot;template&quot;:&quot;ce-index-access-v1-*&quot;,</span><br><span class="line">        &quot;order&quot;:0,</span><br><span class="line">        &quot;settings&quot;:&#123;</span><br><span class="line">            &quot;number_of_shards&quot;:5</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;aliases&quot;:&#123;</span><br><span class="line">            &quot;&#123;index&#125;-query&quot;:&#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;mappings&quot;:&#123;</span><br><span class="line">            &quot;es_doc&quot;:&#123;</span><br><span class="line">                &quot;dynamic&quot;:&quot;strict&quot;,</span><br><span class="line">                &quot;_all&quot;:&#123;</span><br><span class="line">                    &quot;enabled&quot;:false</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;_source&quot;:&#123;</span><br><span class="line">                    &quot;enabled&quot;:false</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;properties&quot;:&#123;</span><br><span class="line">                    &quot;CLF_Timestamp&quot;:&#123;</span><br><span class="line">                        &quot;type&quot;:&quot;long&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;CLF_CustomerID&quot;:&#123;</span><br><span class="line">                        &quot;type&quot;:&quot;keyword&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;CLF_ClientIP&quot;:&#123;</span><br><span class="line">                        &quot;type&quot;:&quot;ip&quot;,</span><br><span class="line">                        &quot;ignore_malformed&quot;:true</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h5><span id="不要在一个索引中定义多个type">不要在一个索引中定义多个type。</span></h5><p>6.X版本已经不支持，7.X版本彻底不支持。<br>扩展问题：5.X版本的父子文档实际实现中是一个索引中定义了多个type，到了6.X中实现方式改变为：join方式。</p><h5><span id="将set-_source设置为false">将Set _source设置为false。</span></h5><p>假设你只关心度量结果，不是原始文件内容。<br>将节省磁盘空间并减少IO。<br>这个点，需要结合实际的业务场景具体问题具体分析。<br>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;_source&quot;:&#123;</span><br><span class="line">&quot;enabled&quot;:false</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure></p><h5><span id="将_all设置为false">将_all设置为false。</span></h5><p>假设你确切地知道你对哪个field做查询操作？<br>能实现性能提升，缩减存储。<br>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;_all&quot;:&#123;</span><br><span class="line">&quot;enabled&quot;:false &#125;,</span><br></pre></td></tr></table></figure></p><h5><span id="设置dynamic-strict">设置dynamic = strict。</span></h5><p>假设你的数据是结构化数据。<br>字段设置严格，避免脏数据注入。<br>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;dynamic&quot;:&quot;strict&quot;,</span><br></pre></td></tr></table></figure></p><h5><span id="使用keyword类型">使用keyword类型</span></h5><p>假设你只关心完全匹配<br>提高性能和缩小磁盘存储空间<br>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;CLF_CustomerID&quot;:&#123;</span><br><span class="line">&quot;type&quot;:&quot;keyword&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure></p><h5><span id="使用别名">使用别名</span></h5><p>如何在不停机的前提从一个索引切换到另一个索引？<br>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;aliases&quot;:&#123;</span><br><span class="line">&quot;&#123;index&#125;-query&quot;:&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>或者你通过head插件创建。</p><h3><span id="elasticsearch分片分配原则">Elasticsearch分片分配原则</span></h3><p>社区和QQ群中经常被问到的问题：</p><ul><li>应该分几个索引、几个分片？</li><li>每个分片大小如何设置？</li><li>副本多少如何设置？</li></ul><p>这里，明确给出实操可行的6个步骤。</p><h4><span id="定义索引">定义索引。</span></h4><p>思考索引中要大致有哪些字段？<br>最好能列一个Excel表统计一下，包含但不限于：<br>序号、名称、类型、作用、备注。<br>以上对计算单条数据大小也有用。</p><h4><span id="评估数据量">评估数据量。</span></h4><p>评估方法举例：<br>1分钟有100条数据，1天=1006024=144000条。<br>1月=144000条30天=432W条数据。 1年=432W12=5184W条数据。<br>假设要保存2年，共=10368W条数据。<br>假设每条数据20KB，共需要存储：10368W*20/1024/1024/1024=1.977TB。</p><h4><span id="评估索引大小和磁盘空间">评估索引大小和磁盘空间。</span></h4><h4><span id="计算分片数">计算分片数。</span></h4><p>细节考虑点：</p><ul><li>每个分片大小应小于30GB。</li><li>分片数量= k *数据节点数目（k = 一个足够小的整数，举例：1,2,3）</li><li>假设你有一个小的索引，并且你有集群中有足够的节点，请尝试使用默认值分片数5。</li></ul><h4><span id="评估索引数和类型">评估索引数和类型。</span></h4><p>（此处可能会有多次反馈迭代）</p><h3><span id="数据去重的思考">数据去重的思考？</span></h3><h4><span id="指定唯一id">指定唯一id</span></h4><p>缺点：</p><ul><li>唯一值无法压缩，不利于存储。</li><li>存在高基数问题。</li></ul><h4><span id="用聚合方法实现">用聚合方法实现</span></h4><p>步骤1：所有文档加一个Hash值；<br>步骤2：检查重复；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">GET *_index/_search &#123;</span><br><span class="line">   &quot;size&quot;:0,</span><br><span class="line">    &quot;aggs&quot;:&#123;</span><br><span class="line">       &quot;duplicate&quot;:&#123;</span><br><span class="line">           &quot;terms&quot;:&#123;</span><br><span class="line">                &quot;field&quot;:&quot;hash&quot;,</span><br><span class="line">                &quot;min_doc_count&quot;:2,</span><br><span class="line">                &quot;size&quot;:5000</span><br><span class="line">           &#125;,</span><br><span class="line">            &quot;aggs&quot;:&#123;</span><br><span class="line">                &quot;documents&quot;:&#123;</span><br><span class="line">                    &quot;top_hits&quot;:&#123;</span><br><span class="line">                        &quot;size&quot;:2</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; &#125;</span><br></pre></td></tr></table></figure></p><p>步骤3：批量删除步骤2中的重复id。<br>以上步骤，不影响写入，可以实现异步。</p><p>缺点：</p><ul><li>存储量大（尤其超过3亿条+）；</li><li>随着数据量增加，聚合受影响，越来越慢。</li><li>存在高基数问题。</li></ul><h4><span id="用distinct-query实现">用distinct query实现</span></h4><p>深入方法待进一步探讨。</p><h3><span id="小结">小结</span></h3><p>以上内容是Elasticsearch南京分享会20180630上的分享核心笔记。<br>具体PPT地址：<a href="https://elasticsearch.cn/slides/115" target="_blank" rel="noopener">https://elasticsearch.cn/slides/115</a><br>很受用的分析步骤和实战经验，实战中都可以用得上。</p><p>转载: <a href="https://mp.weixin.qq.com/s/YocdEQ3cVcPoXRc4tUOxOA" target="_blank" rel="noopener">铭毅天下</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3&gt;&lt;span id=&quot;elasticsearch-索引的设计&quot;&gt;Elasticsearch 索引的设计&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span id=&quot;单一索引vs基于时间的索引&quot;&gt;单一索引VS基于时间的索引&lt;/span&gt;&lt;/h4&gt;&lt;h5&gt;&lt;span id=&quot;单一索引的问
      
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>使用Elasticsearch构建电商搜索平台实践案例[转]</title>
    <link href="http://calfgz.github.io//blog/2018/07/elasticsearch-e-commerce.html"/>
    <id>http://calfgz.github.io//blog/2018/07/elasticsearch-e-commerce.html</id>
    <published>2018-07-05T03:01:12.000Z</published>
    <updated>2019-04-28T07:38:07.344Z</updated>
    
    <content type="html"><![CDATA[<p>##背景</p><p>随着互联网数据规模的爆炸式增长，如何从海量的历史，实时数据中快速获取有用的信息，变得越来越有挑战性。</p><h2><span id="电商数据系统主要类型">电商数据系统主要类型</span></h2><p>一个中等的电商平台，每天都要产生百万条原始数据，上亿条用户行为数据。一般来说，电商数据一般有3种主要类型的数据系统：</p><ul><li>关系型数据库 ，大多数互联网公司会选用mysql作为关数据库的主选，用于存储商品，用户信息等数据。 关系型数据库对于事务性非常高的OLTP操作(比如订单，结算等)支持良好。</li><li>hadoop生态 ，hadoop是数据仓库主要的载体，除了备份关系型数据库的所有版本，还存储用户行为，点击，曝光，互动等海量日志数据，hadoop对于数据分析，数据挖掘等OLAP支持比关系型数据库更加具有扩展性和稳定性。</li><li>搜索引擎 ，以elasticsearch和solr为代表。搜索引擎是获取信息最高效的途径，几乎成为各类网站，应用的基础标配设施(地位仅次于数据库)。</li></ul><p>目前搜索引擎技术已经有非常成熟的开源解决方案，最出名的ElasticSearch和Solr都是基于lucence的。很多中小型互联网公司搜索引擎都是基于这两个开源系统搭建的，但是即便如此，一个搜索引擎团队想把搜索引擎质量做到商用标准，从系统熟悉，服务搭建，功能定制，通常需要花费较长时间。</p><p>通用搜索引擎应用在互联网商用搜索 通常会遇到如下几个问题 ：</p><ul><li>搜索引擎与公司现有数据系统的集成。mysql 和 hadoop是电商的两个主要数据载体，搜索引擎在全量和增量建索引过程中必须和mysql或hadoop无缝集成，才能发挥搜索引擎自身的实时性，水平扩展性(性能与容量和机器数量成正比)等优势。</li><li>商用搜索高度定制化与通用搜索引擎的矛盾。商用搜索的问题有时候超越了搜索引擎本身解决的范围，比如商品的去重，店铺的去重需要很专业的搜索引擎使用技巧; 商品的权重，用户意图的识别需要算法和模型的支持。</li><li>在不了解搜索引擎专业知识的前提下，很难创建对性能友好的索引。结果造成了通用搜索性能很差的假象。</li></ul><p>笔者是有赞大数据架构师，从自身的搜索实践出发，分享搜索引擎实际的架构和解决的问题。</p><h2><span id="搜索引擎架构">搜索引擎架构</span></h2><p>有赞搜索引擎实践，上半部分主要介绍搜索引擎的架构和性能优化方面的经验；下半部分是算法篇，介绍有赞实际需要的搜索算法的问题和解决方案。文章仅仅介绍一个中型电商公司实际的使用现状和笔者个人的经验，不代表搜索引擎最佳实践方法，也不代表可以适用所有的场景。</p><h3><span id="技术架构">技术架构</span></h3><p>有赞搜索引擎基于分布式实时引擎elasticsearch(ES)。ES构建在开源社区最稳定成熟的索引库lucence上，支持多用户租用，高可用，可水平扩展；并有自动容错和自动伸缩的机制。我们同事还实现了es与mysql和hadoop的无缝集成；我们自主开发了高级搜索模块提供灵活的相关性计算框架等功能。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-20-00/doc/4155822960" alt="架构图"></p><h3><span id="索引构建">索引构建</span></h3><p>互联网索引的特点是实时性高，数据量大。时效性要求用户和客户的各种行为能够第一时间进入索引；数据量大要求一个有效分布式方案可以在常数时间内创建不断增长的TB数量级索引。</p><p>实时索引我们采用 面向队列的架构 ，数据首先写入DB(或文件)，然后通过数据库同步机制将数据流写入kafka队列。这种同步机制和数据库主从同步的原理相同，主要的开源产品有mypipe和阿里推出的canal。es通过订阅相应的topic实现实时建立索引。</p><p>如果数据源是文件，则使用flume实时写入Kafka。</p><p>另外一个索引问题是全量索引。有如下几个场景让 全量索引是一个必要过程 ：</p><ul><li>实时更新有可能会丢数据，每次很少的丢失时间长了降低搜索引擎的质量。 周期性的全量更新是解决这个问题的最直接的方法；</li><li>即使能够保证实时更新，业务的发展有可能有重新建索引的需求(比如增加字段，修改属性，修改分词算法等)。</li><li>很多搜索引擎是在业务开始后很久才搭建的，冷启动必须全量创建索引。</li></ul><p>我们采用 Hadoop-es 利用hadoop分布式的特性来创建索引。hadoop-es让分布式索引对用户透明，就像单机更新索引一样。一个是分布式的数据平台，一个是分布式搜索引擎，如果能把这两个结合就能够实现分布式的全量索引过程。Hadoop-es正式我们想要的工具。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-22-07/doc/8749385194" alt="Hadoop-es"></p><p>我们给出一个通过Hive sql创建索引的栗子 ：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> search.goods_index;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> search.goods_index (</span><br><span class="line">is_virtual <span class="built_in">int</span>,</span><br><span class="line">created_time <span class="keyword">string</span>,</span><br><span class="line">update_time <span class="keyword">string</span>,</span><br><span class="line">title <span class="keyword">string</span>,</span><br><span class="line">tag_ids <span class="built_in">array</span></span><br><span class="line">) <span class="keyword">STORED</span> <span class="keyword">BY</span> ‘org.elasticsearch.hadoop.hive.EsStorageHandler’ TBLPROPERTIES (</span><br><span class="line">‘es.batch.size.bytes’=’<span class="number">1</span>mb’,</span><br><span class="line">‘es.batch.size.entries’=’<span class="number">0</span>’,</span><br><span class="line">‘es.batch.write.refresh’=’<span class="literal">false</span>’,</span><br><span class="line">‘es.batch.write.retry.count’=’<span class="number">3</span>’,</span><br><span class="line">‘es.mapping.id’=’<span class="keyword">id</span>’,</span><br><span class="line">‘es.write.operation’=’<span class="keyword">index</span>’,</span><br><span class="line">‘es.nodes’=’<span class="number">192.168</span><span class="number">.1</span><span class="number">.10</span>:<span class="number">9200</span>’,</span><br><span class="line">‘es.resource’=’goods/goods’);</span><br></pre></td></tr></table></figure></p><p>系统把es映射成hive的一个外部表，更新索引就像是写入一个hive表一样。实际上所有分布式问题都被系统透明了。</p><p>不建议从数据库或文件系统来全量索引。一方面这会对业务系统造成很大的压力，另一方面因为数据库和文件系统都不是真正分布式系统，自己写程序保证全量索引的水平扩展性很容易出问题，也没有必要这么做。</p><p>全量索引和增量索引的架构如下图所示。另外一点是hadoop也是订阅kafka备份数据库和日志的。我个人建议一个公司所有DB和文件都存储在hadoop上，这样做起码有二个 好处 ：</p><ul><li>hadoop上使用hive或者spark创建的数据仓库为大数据提供统一的操作接口。</li><li>hadoop数据相对于线上更加稳定，可以作为数据恢复的最后一个防线。</li></ul><p>数据仓库的话题不在本篇文章的讨论范围，这里只是简单提一下。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-23-48/doc/6444274439" alt="索引架构"></p><h4><span id="为什么我们选择kafka">为什么我们选择Kafka？</span></h4><p>Kafka 是一个以高吞吐著名的消息系统。Kafka开启了日志合并(log compaction)功能后，可以永久保存每条消息。每一条消息都有一个key，正好对应数据库的主键，Kafka始终保存一个key最新的一条消息，历史版本会被垃圾回收掉。有了这个特性，Kafka不仅可以保存数据库最新的快照，而且可以实现实时更新的消息系统。</p><p>第一次同步的时候，数据表中每行记录都转化成以主键为key的消息进入Kafka，并且可以被任意数量的broker消费。之后数据库的每次更新(insert，updated，delete)都会被转化成Kafka的消息。如果一行记录频繁被更改，Kafka会识别这些重复的消息，把旧的消息回收掉。</p><p>Kafka既保存数据库最新的全量数据，又提供实时数据流的这个特性为架构的可维护性提供极大便捷。如果你想从零扫描整个数据库，你只需要从开始消费这个Kafka的topic即可完成，当读到topic末端，自动获得实时更新的特性。</p><p>Kakfa的另一个特性是 支持从任意断点读取数据 ，比如我们全量索引是从HDFS中读取，我们可以根据HDFS保存的数据的最后一条的时间戳，直接切换到Kafka读取之后的数据。</p><h3><span id="高级搜索-超越es功能限制">高级搜索： 超越ES功能限制</span></h3><p>高级搜索模块(AS)在商业搜索引擎起到至关重要的作用。在各大商业搜索引擎公司里面AS已经成为标配，也是变更最为频繁的模块。</p><p>AS在商业搜索引擎中主要起到如下作用：</p><ul><li>反向代理，实现基于分片的分布式搜索(实际上es有这个功能); 提供必要的容灾支持</li><li>提供插件化的相关性计算框架</li><li>提供丰富的相关性库，比如query分析库，query改写库，排序库，过滤库等。</li><li>管理不同的搜索业务</li></ul><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-26-48/doc/1686251170" alt="AS"></p><p>AS 一个主要的功 能 是通过一个个业务插件来代表相应的搜索。一个最简单的插件只需要包含对应的ES search API，它实际上就是一个配置项，说明es的地址。 这样AS就是一个纯代理。但是商业搜索的需求都是不是ES本身能够支持的，所以就需要根据需求写相应的Query rewriter，rerank等算法插件。这样就实现了框架和业务分离，AS具有极强的扩展性和复用性。</p><p>AS 另一个功能 是提供通用算法库，实际上它只为每种算法提供编程框架。 算法也是通过插件的方式加入算法库的。这种方法可以让算法工程师抽象公共算法库供业务方使用，避免重新造轮子。一个具体业务要么使用已经存在的算法(并修改参数)，要么自己实现算法。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-29-33/doc/4071445009" alt="AS算法"></p><p>上图是一个 实例 。商品搜索和分销搜索各自实现一个rerank的的算法，同时都调用了系统提供的rerank1的算法库，并加入了自己特有的逻辑。</p><p>AS除了基本proxy功能外，还提供基于query的cache功能用于应用级别的缓存。内部有一个缓冲队列，防止出现雪崩现象。下一节性能优化中会详细说明。</p><h3><span id="es性能优化">ES性能优化</span></h3><p>下面几个小结，我们写了几个我们遇到的性能优化场景。</p><h4><span id="使用应用级队列防止雪崩">使用应用级队列防止雪崩</span></h4><p>ES一个问题是在高峰期时候极容易发生雪崩。ES有健全的线程池系统来保证并发与稳定性问题。 但是在流量突变的情况下(比如双十一秒杀)还是很容易发生瘫痪的现象，主要的原因如下：</p><ul><li>ES几乎为每类操作配置一个线程池; 只能保证每个线程池的资源使用时合理的，当2个以上的线程池竞争资源时容易造成资源响应不过来。</li><li>ES没有考虑网络负载导致稳定的问题。</li></ul><p>在AS里我们实现了面向请求的全局队列来保证稳定性。 它主要做了3件事情。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-31-50/doc/7536067852" alt></p><ul><li>根据业务把请求分成一个个slide，每个slide对应一个队列。 默认一个应用就是一个slide，一个应用也可以区分不同的slide，这样可以保护一个应用内重要的查询。</li><li>每个队列配置一个队列长度，默认为50。</li><li>每个队列计算这个队列的平均响应时间。 当队列平均响应时间超过200ms，停止工作1s，如果请求溢出就写入溢出日志留数据恢复使用。 如果连续10次队列平均响应时间超过500ms就报警，以便工程师第一时间处理。</li></ul><h4><span id="自动降级">自动降级</span></h4><p>应用级队列解决雪崩问题有点粗暴，如果一个应用本身查询就非常慢，很容易让一个应用持续超时很久。我们根据搜索引擎的特点编写了自动降级功能。</p><p>比如商品搜索的例子，商品搜索最基本的功能是布尔查询，但是还需要按照相关性分数和质量度排序等功能，甚至还有个性化需求。完成简单的布尔查询，ES使用bitsets操作就可以做到，但是如果如果需要相关性分，就必须使用倒排索引，并有大量CPU消耗来计算分数。ES的bitsets比倒排索引快50倍左右。</p><p>对于有降级方案的slide，AS在队列响应过慢时候直接使用降级query代替正常query。这种方法让我们在不扩容的情况下成功度过了双十一的流量陡增。</p><h4><span id="善用filtered-query">善用filtered query</span></h4><p>理解lucence filter工作原理对于写出高性能查询语句至关重要。许多搜索性能优化都和filter的使用有关。filter使用bitsets进行布尔运算，quey使用倒排索引进行计算，这是filter比query快的原因。 bitsets的优势 主要体现在：</p><ul><li>bitsetcache在内存里面，永不消失(除非被LRU)。</li><li>bitsets利用CPU原生支持的位运算操作，比倒排索引快个数量级</li><li>多个bitsets的与运算也是非常的快(一个64位CPU可以同时计算64个DOC的与运算)</li><li>bitsets 在内存的存储是独立于query的，有很强的复用性</li><li>如果一个bitset片段全是0，计算会自动跳过这些片段，让bitsets在数据稀疏情况下同样表现优于倒排索引。</li></ul><p>举个例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">query:bool:  </span><br><span class="line">    tag:&apos;mac&apos;</span><br><span class="line">    region:&apos;beijing&apos;</span><br><span class="line">    title: &quot;apple&quot;</span><br></pre></td></tr></table></figure></p><p>lucence处理这个query的方式是在倒排索引中寻找这三个term的倒排链，并使用跳指针技术求交，在运算过程中需要对每个doc进行算分。实际上tag和region对于算分并没有作用，他们充当是过滤器的作用。</p><p>这就是过滤器使用场景，它只存储存在和不存在两种状态。 如果我们把tag和region使用bitsets进行存储，这样这两个过滤器可以一直都被缓存在内存里面，这样会快很多。 另外tag和region之间的求交非常迅速，因为64位机器可以时间一个CPU周期同时处理64个doc的位运算。</p><p>一个lucence金科玉律是： 能用filter就用filter，除非必须使用query(当且仅当你需要算分的时候)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">query:  </span><br><span class="line">    filtered: </span><br><span class="line">        query:  </span><br><span class="line">             title: &quot;apple&quot; </span><br><span class="line">         filter:</span><br><span class="line">            tag:&quot;mac&quot;</span><br><span class="line">             region:&quot;beijing&quot;</span><br></pre></td></tr></table></figure><p>lucence的filtered query会智能的先计算filter语句，然后才计算query语句，尽可能在进行复杂的倒排算法前减少计算空间。</p><h4><span id="其他性能优化">其他性能优化</span></h4><p>线上集群关闭分片自动均衡。分片的自动均衡主要目的防止更新造成各个分片数据分布不均匀。但是如果线上一个节点挂掉后，很容易触发自动均衡，一时间集群内部的数据移动占用所有带宽。建议采用闲时定时均衡策略来保证数据的均匀。</p><p>尽可能延长refresh时间间隔。为了确保实时索引es索引刷新时间间隔默认为1秒，索引刷新会导致查询性能受影响，在确保业务时效性保证的基础上可以适当延长refresh时间间隔保证查询的性能。</p><p>除非有必要把all字段去掉。索引默认除了索引每个字段外，还有额外创建一个all的字段，保存所有文本，去掉这个字段可以把索引大小降低50%。</p><p>创建索引时候，尽可能把查询比较 慢 的索引和 快 的 索引物理分离 。</p><p>本文对es本身的优化写的不多，因为es官网和其他的博客有很多es优化的意见，就不在一一枚举。本文的主要目的是能够对搭建商用电商搜索引擎给读者一个一般性的建议，另外，困扰商用搜索引擎的最常见的问题是排序和算法问题。</p><h2><span id="算法体系架构">算法体系架构</span></h2><p>在上半部分中，我们介绍了有赞搜索引擎的基本框架。搜索引擎主要3个部件构成。第一，hadoop集群，用于生成大规模搜索和实时索引； 第二，ElasticSearch集群，提供分布式搜索方案； 第三，高级搜索集群，用于提供商业搜索的特殊功能。</p><h3><span id="索引过程">索引过程</span></h3><p>创建索引过程从原始数据创建倒排索引的过程。这个过程中我们对商品(doc)进行分析，计算商品静态分，并对商品进行相似度计算。商品的静态分对于提升搜索引擎质量起到至关重要的作用，相当于网页搜索的pagerank，想象一下如果没有pagerank算法，网页搜索的质量会有多么差。在电商搜索中，最常见的问题是相似商品太多，必须在建立索引过程中就对商品间的相似度进行预计算，以便在检索过程中进行有效去重。</p><p>创建索引的过程如下：</p><ul><li>step 1，计算每个doc的静态分；</li><li>step 2，计算两两doc的相似度；</li><li>step 3，根据相似度和其他信息对数据进行分库；</li><li>step 4，建立ES索引。</li></ul><h4><span id="检索过程">检索过程</span></h4><p>检索过程是搜索引擎接收用户的query进行一系列处理并返回相关结果的过程。商业搜索引擎在检索过程中需要考虑2个因素：1) 相关性，2) 重要性。</p><p>相关性是指返回结果和输入query是否相关，这是搜索引擎基本问题之一，目前常用的算法有BM25和空间向量模型。这个两个算法ElasticSearch都支持，一般商业搜索引擎都用BM25算法。BM25算法会计算每个doc和query的相关性分，我们使用Dscore表示。</p><p>重要性是指商品被信赖的程度，我们应该吧最被消费之信赖的商品返回给消费者，而不是让消费之自己鉴别。尤其是在商品充分竞争的电商搜索，我们必须赋予商品合理的重要性分数，才能保证搜索结果的优质。重要性分，又叫做静态分，使用Tscore表示。</p><p>搜索引擎最终的排序依据是：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Score = Dscore * Tscore</span><br></pre></td></tr></table></figure></p><p>即综合考虑静态分和动态分，给用户相关且重要的商品。</p><p>检索的过程大致抽象为如下几个步骤。</p><ul><li>step 1，对原始query进行query分析；</li><li>step 2，在as中根据query分析结果进行query重写；</li><li>step 3，在as中使用重写后的query检索es；</li><li>step 4，在es查询过程中根据静态分和动态分综合排序；</li><li>step 5，在as中吧es返回的结果进行重排；</li><li>step 6，返回结果。</li></ul><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-38-23/doc/6157769375" alt></p><h3><span id="商品静态分计算技术">商品静态分计算技术</span></h3><p>在电商搜索引擎里面商品的静态分是有网页搜索里面的pagerank同等的价值和重要性，他们都是doc固有的和查询query无关的价值度量。pagerank通过doc之间的投票关系进行运算，相对而言商品的静态分的因素会更多一些。商品静态计算过程和pagerank一样 需要解决如下2个问题 ：</p><ul><li>稳定性 。pagerank可以保证一个网站不会因为简单链接堆砌可以线性提升网站的排名。同样，商品静态分的计算不可以让商品可以通过增加单一指标线性增加分值(比如刷单对搜索引擎的质量的影响)。</li><li>区分度 。在保证稳定性的基础上商品静态分要有足够的区分度可以保证同样搜索的条件下，排在前面的商品的质量比排在后面的商品的质量高。</li></ul><p>我们假设商品的静态分有3个决定性因素：1，下单数；2，好评率；3，发货速度。</p><p>静态分我们使用Tsocre表示，Tscore可以写成如下形式:<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tscore = a * f(下单数) + b * g(好评率) + c * h(发货速度)</span><br></pre></td></tr></table></figure></p><p>a，b，c是权重参数，用于平衡各个指标的影响程度。f，g，h是代表函数用于把原始的指标转化成合理的度量。</p><p>首先，我们需要寻找合理的代表函数。</p><ul><li>首先对各个指标取log。log的导数是一个减函数，表示为了获得更好的分数需要花费越来越多的代价。</li><li>标准化。标准化的目的让各个度量可以在同一区间内进行比较。比如下单数的取值是0~10000，而好评率的取值为0~1。这种情况会影响到数据分析的结果和方便性，为了消除指标之间的量纲的影响，需要进行数据标准化处理，以解决数据指标之间的可比性。最常用的标准化方法是z-score标准化方法。</li></ul><h4><span id="z-score-标准化方法">z-score 标准化方法</span></h4><p>“概率论”告诉我们对于满足正态分布的数据来说，均值前后3个z-score的范围可以覆盖99%的数据。经验地，我们把&gt;5个zscore 或者小于 -5个zscore的分数设置成5*zscore或者-5zscore。特别说明的是，我们不建议使用min-max标准化方法。这种方法又叫离差标准化，是对原始数据的线性变换，使结果值映射到[0-1]之间，转化函数如下：</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-40-31/doc/9643910892" alt></p><p>这种方法非常不稳定，假设一个奇异点是第二大的值的1000倍，会让大部分的值都集中在0~0.01，同样失去了归一化的目的。</p><p>图一是使用min-max归一化后的数据分布，显然大部分数据被”压扁”在很小的范围； 图二使用log归一化后的数据分布，由于log缓解了增长速度，可以看出来已经有一个不错的结果了；图三是在log的基础上进行z-score归一化，可以看出来，z-score让数据变得非常平滑。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-41-13/doc/4277078151" alt="图一: min-max归一化"></p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-41-46/doc/7517428031" alt="图二: log归一化"></p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-42-10/doc/0470793701" alt="图三: log-zscore归一化"></p><p>最后，选择合适的权重 经过log-zscore归一化以后，我们基本上吧f，g，h的表示的代表函数说明清楚。Tscore = af(下单数) + bg(好评率) + c*h(发货速度)，下一步就是确定a，b，c的参数。一般有两个方法：</p><ul><li>专家法。根据我们的日常经验动态调整权重参数；</li><li>实验法。首先在专家的帮助下赋一个初始值，然后改变单一变量的方法根据abtest的结果来动态调整参数。</li></ul><h3><span id="商品标题去重">商品标题去重</span></h3><p>商品标题去重在电商搜索中起到重要作用，根据数据，用户通过搜索页购买商品80%选择搜索的前4页。商品标题的重复会导致重要的页面没有含金量，极大降低了搜索的购买率。</p><p>举个例子:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Title1:美味/香蕉/包邮/广东/高州/香蕉/banana<span class="comment">//无/催熟剂/</span></span><br><span class="line">Title2:美味/香蕉/广东/高州/香蕉<span class="comment">//非/粉蕉/包邮/</span></span><br></pre></td></tr></table></figure><p>这里用到 “bag of word” 技术，将词汇表作为空间向量的维度，标题的每个term的词频作为这个feature的值。以这个例子来说。这个词汇的维度为: 美味(0)，香蕉(1)，包邮(2)，广东(3)，高州(4)，banana(5)，无(6)，催熟剂(7)，非(8)，粉蕉(9) 位置: 0，1，2，3，4，5，6，7，8，9</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Title1: <span class="number">1</span>，<span class="number">2</span>，<span class="number">1</span>，<span class="number">1</span>，<span class="number">1</span>，<span class="number">1</span>，<span class="number">1</span>，<span class="number">1</span>，<span class="number">0</span>，<span class="number">0</span></span><br><span class="line">Title2: <span class="number">1</span>，<span class="number">2</span>，<span class="number">1</span>，<span class="number">1</span>，<span class="number">1</span>，<span class="number">0</span>，<span class="number">0</span>，<span class="number">0</span>，<span class="number">1</span>，<span class="number">1</span></span><br></pre></td></tr></table></figure><p>这个每个title都用一个固定长度的向量表示。</p><p>再次，计算两两相似度。</p><p>相似度一般是通过计算两个向量的距离实现的，不失一般性，在这里我们使用1-cosine(x，y)来表示两个向量的距离。这是一个”All Pair Similarity”的问题，即需要两两比较，复杂度在O(n^2)。在商品量巨大的时候单机很难处理。我们给出两种方法用于实现”All Pair Similarity”。</p><p>方法一：spark的矩阵运算。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rddRows = sc.parallelize([“1 0 2 0 0 1”, “0 0 4 2 0 0″])</span><br><span class="line">rddRows.map(lambda x: Vectors.dense([float(each) for each in str(x).split(” “)]))</span><br><span class="line">mat = RowMatrix(rddRows)</span><br><span class="line">simsPerfect = mat.columnSimilarities()</span><br></pre></td></tr></table></figure></p><p>方法二：map-reduce 线性方法。</p><p>这个方法参考论文”Pairwise Document Similarity in Large Collections with MapReduce”。可以实现几乎线性的时间复杂度。相对于矩阵运算在大规模(10亿以上)pair similarity 运算上面有优势。这个方法简单的描述如下: 首先，按照倒排索引的计算方式计算每个term到doc的映射。比如3个doc：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">doc1 = 我 爱 北京</span><br><span class="line">doc2 = 我 北京 天安门</span><br><span class="line">doc3 = 我 天安门</span><br></pre></td></tr></table></figure><p>转化为倒排格式，这个需要一次mapper reduce</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">我     -&gt; doc1, doc2, doc3</span><br><span class="line">爱     -&gt; doc1</span><br><span class="line">北京   -&gt; doc1, doc2</span><br><span class="line">天安门 -&gt; doc2, doc3</span><br></pre></td></tr></table></figure><p>然后，对于value只有一个元素的过滤掉，对于value大于2个doc的两两组合:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">doc1,doc2 &lt;—- from: 我     -&gt; doc1, doc2, doc3</span><br><span class="line">doc1,doc3 &lt;—- from: 我     -&gt; doc1, doc2, doc3</span><br><span class="line">doc2,doc3 &lt;—- form: 我     -&gt; doc1, doc2, doc3</span><br><span class="line">doc1,doc2 &lt;—- from: 北京   -&gt; doc1, doc2</span><br><span class="line">doc2,doc3 &lt;—- from: 天安门 -&gt; doc2, doc3</span><br></pre></td></tr></table></figure><p>最后，对于输出进行聚合，value为重复次数和两个doc乘积开根号的比。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">doc1,doc2 -&gt; 2/(len(doc1)*len(doc2))^1/2 = 0.7</span><br><span class="line">doc1,doc3 -&gt; 1/(len(doc1)*len(doc3))^1/2 = 0.3</span><br><span class="line">doc2,doc3 -&gt; 2/(len(doc2)*len(doc3))^1/2 = 0.3</span><br></pre></td></tr></table></figure><p>对于2个title1，title2，如果X(title1，title2) &gt; 0.7 则认为title1和title2相似，对于相似的两个doc，静态分大的定义为主doc，静态分小的定义为辅doc。主doc和辅doc分别建库。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-43-45/doc/6119062079" alt></p><p>区别于网页搜索(网页搜索直接将辅doc删除)，我们将主doc和辅doc分别建库。每一次搜索按比例分别搜主库和辅库，并将结果融合返回。这样可以保证结果的多样性。</p><h3><span id="店铺去重">店铺去重</span></h3><p>店铺去重和商品标题去重有点不同。由于电商特定场景的需要，不希望搜索结果一家独大，这样会引发强烈的马太效应。店铺去重不能使用如上的方法进行。因为上面的方法的主要依据是文本相似，在结果都相关的前提下，进行适当的取舍。但是店铺去重不是这样的特性。</p><p>设想一下，如果我们根据店铺是否相同，把同一店铺的商品分到主库和从库中，如下图所示。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-44-37/doc/5862986692" alt></p><p>A和B代表不同的店铺。</p><p>在搜索香蕉的时候，的确可以控制A店铺结果的数量，但是在搜索”梨”的时候就错误的吧B店铺的梨排在前面了(假设A：梨比B：梨静态分高)。</p><p>实际上想达到店铺去重的效果通过分桶搜索是很容易做的事情。我们假设每页搜索20个结果，我们把索引库分成4个桶，每个商品对桶数取模得到所在桶的编号。这样可以保证同一店铺的商品仅在一个桶里面。搜索的过程每个桶平均分摊搜索任务的25%，并根据静态分合并成一页的结果。这样同一保证结果的相对顺序，又达到了店铺去重的目的。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-44-54/doc/3912022068" alt></p><p>如上图所示，搜索”香蕉”，虽然A店铺有10个满足需求的结果，但是每页搜索醉倒只有5个结果可以展示。</p><h4><span id="query分析与query改写技术">query分析与Query改写技术</span></h4><p>上面介绍了几个建立索引过程中几项技术，检索过程中的关键技术有很多。其中最著名的是query分析技术。我们使用的query分析技术主要包括核心词识别，同义词拓展，品牌词识别等等。query分析技术大部分都是NLP研究范围，本文就不详细阐述很多理论知识。我们重点介绍同义词拓展技术。这个技术一般都需要根据自己的商品和和用户日志特定训练，无法像分词技术和品牌词识别一样有标准的库可以适用。</p><p>同义词拓展一般是通过分析用户session日志获取。如果一个用户输入”苹果手机”没有得到想要的结果，他接着输入”iphone”，我们在”苹果手机”和”iphone”之间创建一个转移关系。基于统计，我们可以把用户query创建一个相互联系的权重图。</p><p><img src="https://cdn.www.sojson.com/file/16-09-13-17-45-16/doc/5079389763" alt></p><p>用户输入query “苹果手机”，根据query分析，”苹果手机”有 “iphone”0.8，”iphone 6″0.5 两个同义词。0.8和0.5分别表示同义的程度。我们想要”苹果手机”，”iphone”，”iphone 6” 3个query同时输入，并且按照同义的程度对不同的query赋予不同的权重。ElasticSearch提供的BoostingQuery可以支持这个需求。</p><p>原始的query：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    “query”&#123;</span><br><span class="line">        “match”: &#123;</span><br><span class="line">            “query”: ”苹果手机”</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>优化后的query：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;should&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                    &quot;content&quot;: &#123;</span><br><span class="line">                        &quot;query&quot;: &quot;苹果手机&quot;,</span><br><span class="line">                        &quot;boost&quot;: 10</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                    &quot;content&quot;: &#123;</span><br><span class="line">                        &quot;query&quot;: &quot;iphone&quot;,</span><br><span class="line">                        &quot;boost&quot;: 8</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                    &quot;content&quot;: &#123;</span><br><span class="line">                        &quot;query&quot;: &quot;iphone6&quot;,</span><br><span class="line">                        &quot;boost&quot;: 5</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其他比如核心词识别，歧义词纠正等方法差不多，本文不做详细阐述。</p><h3><span id="小结">小结</span></h3><p>商业电商搜索算法另外两个重要技术，一个是类目体系建立和应用，另一个是个性化技术。这个两项技术我们还处在探索阶段。类目体系我们主要使用机器学习的方法进行训练，个性化主要通过用户画像进行Query改写来实现。等我们上线有效果在与大家分享。</p><p>搜索算法是一个非常值得一个电商产品持续投入的技术。一方面如果技术人员要有良好的技术背景，可以借鉴很多成熟的技术，避免重复造轮子； 另一方面，每个产品的搜索都有自身的特点，需要深入研究产品的特性给出合理的解决方案。</p><p>本文给出的案例都具有代表性，灵活的运用搜索的各方面的技术。另外，商业搜索非常看重投入产出比，我们也需要在众多方案中寻找捷径。比如我们在做类目体系时候，没有投入大量的人力资源用于标注数据，而是通过爬虫爬取其他电商的数据进行参考，从而节省了80%的人力资源。由于笔者能力有限，文中的方案不保证是问题的最优解，如果有指正，请联系笔者(<a href="mailto:hongbin@youzan.com" target="_blank" rel="noopener">hongbin@youzan.com</a>)。</p><p>转载: <a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247486428&amp;idx=1&amp;sn=f77bcbf0441df57a919e37688ac2d088&amp;source=41#wechat_redirect" target="_blank" rel="noopener">AI前线 </a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;##背景&lt;/p&gt;
&lt;p&gt;随着互联网数据规模的爆炸式增长，如何从海量的历史，实时数据中快速获取有用的信息，变得越来越有挑战性。&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;电商数据系统主要类型&quot;&gt;电商数据系统主要类型&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;一个中等的电商平台，每天都要产生百万条
      
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/tags/ElasticSearch/"/>
    
      <category term="电商" scheme="http://calfgz.github.io/tags/%E7%94%B5%E5%95%86/"/>
    
  </entry>
  
  <entry>
    <title>用Java和Nodejs获取http30X跳转后的url</title>
    <link href="http://calfgz.github.io//blog/2018/05/http-redirect-java-node.html"/>
    <id>http://calfgz.github.io//blog/2018/05/http-redirect-java-node.html</id>
    <published>2018-05-31T02:57:37.000Z</published>
    <updated>2019-04-28T07:38:07.343Z</updated>
    
    <content type="html"><![CDATA[<h3><span id="301永久重定向">301永久重定向</span></h3><h4><span id="定义">定义</span></h4><p><code>301 Moved Permanently 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个URI之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。</code></p><p>301比较常用的场景是使用域名跳转。</p><p>比如，我们访问 <a href="http://www.baidu.com" target="_blank" rel="noopener">http://www.baidu.com</a> 会跳转到 <a href="https://www.baidu.com，发送请求之后，就会返回301状态码，然后返回一个location，提示新的地址，浏览器就会拿着这个新的地址去访问。" target="_blank" rel="noopener">https://www.baidu.com，发送请求之后，就会返回301状态码，然后返回一个location，提示新的地址，浏览器就会拿着这个新的地址去访问。</a> </p><p>注意： 301请求是可以缓存的， 即通过看status code，可以发现后面写着from cache。</p><p>或者你把你的网页的名称从php修改为了html，这个过程中，也会发生永久重定向。</p><h4><span id="nginx配置">Nginx配置</span></h4><p>rewrite后面接上permenent就代表301跳</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//把来自veryyoung.me的请求301跳到 www.veryyoung.me</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$host</span> != <span class="string">'veryyoung.me'</span>) &#123;</span><br><span class="line">    rewrite ^/(.*)$ http://www.veryyoung.me/<span class="variable">$1</span> permanent;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="302临时重定向">302临时重定向</span></h3><h4><span id="定义">定义</span></h4><p><code>302 Found 请求的资源现在临时从不同的URI响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。</code></p><p>比如未登陆的用户访问用户中心重定向到登录页面。</p><p>访问404页面会重新定向到首页。</p><h4><span id="nginx配置">Nginx配置</span></h4><p>rewrite后面接上redirect就代表302跳</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//把来自veryyoung.me的请求302跳到 www.veryyoung.me</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$host</span> != <span class="string">'veryyoung.me'</span>) &#123;</span><br><span class="line">    rewrite ^/(.*)$ http://www.veryyoung.me/<span class="variable">$1</span> redirect;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="301与302的区别">301与302的区别</span></h3><p>302重定向只是暂时的重定向，搜索引擎会抓取新的内容而保留旧的地址，因为服务器返回302，所以，搜索搜索引擎认为新的网址是暂时的。</p><p>而301重定向是永久的重定向，搜索引擎在抓取新的内容的同时也将旧的网址替换为了重定向之后的网址。</p><h3><span id="java实现获取301或302跳转后的url">Java实现获取301或302跳转后的URL</span></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">findLink</span><span class="params">(String url)</span> </span>&#123;</span><br><span class="line">    String result = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        URL serverUrl = <span class="keyword">new</span> URL(url);</span><br><span class="line">        HttpURLConnection conn = (HttpURLConnection) serverUrl.openConnection();</span><br><span class="line">        conn.setRequestMethod(<span class="string">"GET"</span>);</span><br><span class="line">        <span class="comment">// 必须设置false，否则会自动redirect到Location的地址</span></span><br><span class="line">        conn.setInstanceFollowRedirects(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        conn.addRequestProperty(<span class="string">"Accept-Charset"</span>, <span class="string">"UTF-8;"</span>);</span><br><span class="line">        conn.addRequestProperty(<span class="string">"User-Agent"</span>, <span class="string">"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.2.8) Firefox/3.6.8"</span>);</span><br><span class="line">        conn.connect();</span><br><span class="line">        String location = conn.getHeaderField(<span class="string">"Location"</span>);</span><br><span class="line">        <span class="keyword">int</span> code = conn.getResponseCode();</span><br><span class="line">        <span class="keyword">if</span> (code == <span class="number">301</span> || code == <span class="number">302</span>) &#123;</span><br><span class="line">            location = findLink(location);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            location = conn.getURL().toString();</span><br><span class="line">        &#125;</span><br><span class="line">        result = location;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="用nodejs实现获取301或302跳转后的url">用NodeJs实现获取301或302跳转后的URL</span></h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> request = <span class="built_in">require</span>(<span class="string">'request'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> find_link = <span class="function"><span class="keyword">function</span> (<span class="params">link, collback</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> f = <span class="function"><span class="keyword">function</span> (<span class="params">link</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> options = &#123;</span><br><span class="line">            url: link,</span><br><span class="line">            followRedirect: <span class="literal">false</span>,</span><br><span class="line">            headers : &#123;</span><br><span class="line">                <span class="string">'Content-Type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</span><br><span class="line">                <span class="string">'Accept-Charset'</span>: <span class="string">'UTF-8;'</span>,</span><br><span class="line">                <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.2.8) Firefox/3.6.8'</span>,</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        request(options, <span class="function"><span class="keyword">function</span> (<span class="params">error, response, body</span>) </span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.log(response.statusCode);</span><br><span class="line">            <span class="keyword">if</span> (response.statusCode == <span class="number">301</span> || response.statusCode == <span class="number">302</span>) &#123;</span><br><span class="line">                <span class="keyword">var</span> location = response.headers.location;</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">'location: '</span> + location);</span><br><span class="line">                f(location);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//console.log(body);</span></span><br><span class="line">                collback(link);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f(link);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">find_link(<span class="string">"http://a.m.taobao.com/i538372076663.htm?&amp;sid=7ac494a5aa270ce9562feadef7423650"</span>, <span class="function"><span class="keyword">function</span>(<span class="params">link</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(link);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3&gt;&lt;span id=&quot;301永久重定向&quot;&gt;301永久重定向&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span id=&quot;定义&quot;&gt;定义&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;code&gt;301 Moved Permanently 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使
      
    
    </summary>
    
      <category term="http" scheme="http://calfgz.github.io/categories/http/"/>
    
    
      <category term="Java" scheme="http://calfgz.github.io/tags/Java/"/>
    
      <category term="http" scheme="http://calfgz.github.io/tags/http/"/>
    
      <category term="NodeJs" scheme="http://calfgz.github.io/tags/NodeJs/"/>
    
  </entry>
  
  <entry>
    <title>安装ElasticSearch head插件,Kibana和X-Pack</title>
    <link href="http://calfgz.github.io//blog/2018/02/elasticsearch-plugin-install-head.html"/>
    <id>http://calfgz.github.io//blog/2018/02/elasticsearch-plugin-install-head.html</id>
    <published>2018-02-02T08:45:47.000Z</published>
    <updated>2019-04-28T07:38:07.343Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="head插件简介">Head插件简介</span></h2><p>ElasticSearch-head是一个H5编写的ElasticSearch集群操作和管理工具，可以对集群进行傻瓜式操作。</p><ul><li>显示集群的拓扑,并且能够执行索引和节点级别操作</li><li>搜索接口能够查询集群中原始json或表格格式的检索数据</li><li>能够快速访问并显示集群的状态</li><li>有一个输入窗口,允许任意调用RESTful API。这个接口包含几个选项,可以组合在一起以产生有趣的结果;</li><li>5.0版本之前可以通过plugin名安装，5.0之后可以独立运行。</li></ul><h2><span id="head插件安装">Head插件安装</span></h2><h4><span id="安装nodejs">安装NodeJs</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下载nodejs</span></span><br><span class="line">[root@170 ~]# wget https://npm.taobao.org/mirrors/node/v9.5.0/node-v9.5.0-linux-x64.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash">解压</span></span><br><span class="line">[root@170 ~]# tar -zxvf node-v9.5.0-linux-x64.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash">配置环境变量</span></span><br><span class="line">[root@170 ~]# vi /etc/profile</span><br><span class="line">export NODE_HOME=/usr/nodejs/node-v9.5.0-linux-x64</span><br><span class="line">export NODE_PATH=$NODE_HOME/lib/node_modules</span><br><span class="line">export PATH=$PATH:$NODE_HOME/bin</span><br><span class="line"><span class="meta">#</span><span class="bash">保存执行生效</span></span><br><span class="line">[root@170 ~]# source /etc/profile</span><br></pre></td></tr></table></figure><h4><span id="安装head插件">安装Head插件</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下载</span></span><br><span class="line">[root@170 ~]# wget https://github.com/mobz/elasticsearch-head/archive/master.zip</span><br><span class="line"><span class="meta">#</span><span class="bash">解压</span></span><br><span class="line">[root@170 ~]# unzip -zxvf master.zip</span><br><span class="line">[root@170 ~]# cd elasticsearch-head-master</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">使用淘宝的镜像库进行下载，速度很快</span></span><br><span class="line">[root@170 ~]# npm config set registry https://registry.npm.taobao.org</span><br><span class="line"><span class="meta">#</span><span class="bash">安装grunt</span></span><br><span class="line">[root@170 ~]# npm install -g grunt-cil</span><br><span class="line"><span class="meta">#</span><span class="bash">检查是否安装成功</span></span><br><span class="line">[root@170 ~]# grunt -version</span><br><span class="line"><span class="meta">#</span><span class="bash">执行安装head</span></span><br><span class="line">[root@170 ~]# npm install</span><br></pre></td></tr></table></figure><p>安装过程中出现错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Please report this full log at https://github.com/Medium/phantomjs</span><br><span class="line">npm ERR! Darwin 15.0.0</span><br><span class="line">npm ERR! argv &quot;/usr/local/bin/node&quot; &quot;/usr/local/bin/npm&quot; &quot;install&quot;</span><br><span class="line">npm ERR! node v4.4.3</span><br><span class="line">npm ERR! npm  v3.10.9</span><br><span class="line">npm ERR! code ELIFECYCLE</span><br><span class="line">npm ERR! phantomjs-prebuilt@2.1.14 install: `node install.js`</span><br><span class="line">npm ERR! Exit status 1</span><br><span class="line">npm ERR! </span><br><span class="line">npm ERR! Failed at the phantomjs-prebuilt@2.1.14 install script &apos;node install.js</span><br></pre></td></tr></table></figure><p>解决方案：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#忽略脚本继续进行安装</span><br><span class="line">[root@170 ~]# npm install phantomjs-prebuilt@2.1.14 --ignore-scripts</span><br></pre></td></tr></table></figure><p>安装完成。</p><h4><span id="启动head插件">启动Head插件</span></h4><p>修改Gruntfile.js,打开这个js文件，默认文件中是没有hostname属性的，我们需要手动添加。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@170 ~]# vi Gruntfile.js</span><br><span class="line">connect: &#123;</span><br><span class="line">        server: &#123;</span><br><span class="line">               options: &#123;</span><br><span class="line">                       port: <span class="number">9100</span>,</span><br><span class="line">                       base: <span class="string">'.'</span>,</span><br><span class="line">                       keepalive: <span class="literal">true</span>,</span><br><span class="line">                       hostname: <span class="string">'*'</span></span><br><span class="line">                &#125;</span><br><span class="line">                &#125;</span><br><span class="line">         &#125;</span><br></pre></td></tr></table></figure><p>保存。</p><p>修改ElasticSearch 的启动配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@170 ~]# vi ./config/elasticsearch.yml</span><br><span class="line">#在文件末尾添加即可</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br></pre></td></tr></table></figure><p>保存后重启ElasticSearch</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#查看进程</span><br><span class="line">[root@170 ~]# jps</span><br><span class="line">#结束进程</span><br><span class="line">[root@170 ~]# kill -9 pid</span><br><span class="line">#重启</span><br><span class="line">[root@170 ~]# su es</span><br><span class="line">[es@170 ~]# ./bin/elasticsearch -d</span><br><span class="line"></span><br><span class="line">#切回到head的主目录，执行如下命令</span><br><span class="line">[root@170 ~]# cd elasticsearch-head-master</span><br><span class="line">[root@170 ~]# grunt server</span><br></pre></td></tr></table></figure><p>访问localhost:9100成功。</p><h2><span id="kibana-及-x-pack-下载安装">Kibana 及 x-pack 下载安装</span></h2><h4><span id="安装-es-插件-x-pack">安装 ES 插件 x-pack</span></h4><p>安装 插件 x-pack</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd elasticsearch-6.1.3/</span><br><span class="line">// 安装 X-Pack</span><br><span class="line">bin/elasticsearch-plugin install x-pack</span><br></pre></td></tr></table></figure><p>设置 Xpack 安全验证为 false：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim config/elasticsearch.yml</span><br></pre></td></tr></table></figure><p>并添加下面配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xpack.security.enabled: false</span><br></pre></td></tr></table></figure><p>并启动 ES：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch</span><br><span class="line"></span><br><span class="line">或者后台启动</span><br><span class="line">./bin/elasticsearch -d</span><br></pre></td></tr></table></figure><h4><span id="下载安装-kibana-插件-x-pack">下载安装 Kibana 插件 x-pack</span></h4><p>解压 - 然后安装 插件 x-pack</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://artifacts.elastic.co/downloads/kibana/kibana-6.1.3-linux-x86_64.tar.gz</span><br><span class="line">tar -zxvf kibana-6.1.3-linux-x86_64.tar.gz</span><br><span class="line">cd kibana-6.1.3-linux-x86_64/</span><br><span class="line"></span><br><span class="line">// 安装 X-Pack</span><br><span class="line">bin/kibana-plugin install x-pack</span><br></pre></td></tr></table></figure><h4><span id="配置-kibana-并启动">配置 Kibana 并启动</span></h4><p>设置 Xpack 安全验证为 false：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim config/kibana.yml</span><br></pre></td></tr></table></figure><p>并添加下面配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xpack.security.enabled: false</span><br></pre></td></tr></table></figure><p>并启动 Kibana：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./bin/kibanah</span><br><span class="line"></span><br><span class="line">或者后台启动</span><br><span class="line">nohup ./bin/kibana &amp;</span><br></pre></td></tr></table></figure><p>必须注意：先启动 ES，再启动 Kibana。</p><p>如果后台启动注意，关闭命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep &apos;elastic&apos;</span><br><span class="line">kill -9 pid</span><br></pre></td></tr></table></figure><p>启动成功后，打开网页访问 127.0.0.1:5601 ， 默认账号为：elasti，密码为 changeme。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;head插件简介&quot;&gt;Head插件简介&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;ElasticSearch-head是一个H5编写的ElasticSearch集群操作和管理工具，可以对集群进行傻瓜式操作。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;显示集群的拓扑,并且能够执行索引和
      
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>Linux安装ElasticSearch</title>
    <link href="http://calfgz.github.io//blog/2018/02/linux-install-elasticsearch.html"/>
    <id>http://calfgz.github.io//blog/2018/02/linux-install-elasticsearch.html</id>
    <published>2018-02-02T07:56:29.000Z</published>
    <updated>2019-04-28T07:38:07.343Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="安装配置jdk8">安装配置JDK8</span></h2><h4><span id="下载jdk并解压缩">下载JDK并解压缩</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@170 ~]# wget http://download.oracle.com/otn-pub/java/jdk/8u161-b12/2f38c3b165be4555a1fa6e98c45e0808/jdk-8u161-linux-x64.tar.gz</span><br><span class="line">[root@170 ~]# tar -zxvf jdk-8u161-linux-x64.tar.gz -C /usr/java</span><br></pre></td></tr></table></figure><h4><span id="编辑环境变量">编辑环境变量</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@170 ~]# vi /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash">增加配置</span></span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_144</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="meta">#</span><span class="bash">保存后执行生效</span></span><br><span class="line">[root@170 ~]# source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash">查看JDK版本</span></span><br><span class="line">[root@170 ~]# java -version</span><br></pre></td></tr></table></figure><h2><span id="安装配置elasticsearch">安装配置ElasticSearch</span></h2><h4><span id="下载并解压缩">下载并解压缩</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@170 ~]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.1.3.tar.gz</span><br><span class="line">[root@170 ~]# tar -zxvf elasticsearch-6.1.3.tar.gz</span><br></pre></td></tr></table></figure><h4><span id="创建新用户">创建新用户</span></h4><p>从5.0开始，ElasticSearch 安全级别提高了，不允许采用root帐号启动，所以我们要添加一个用户。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">创建用户组</span></span><br><span class="line">[root@170 ~]# groupadd es</span><br><span class="line"><span class="meta">#</span><span class="bash">创建用户</span></span><br><span class="line">[root@170 ~]# useradd es -g es -p es</span><br><span class="line"><span class="meta">#</span><span class="bash">修改es目录权限</span></span><br><span class="line">[root@170 ~]# chown es:es elasticsearch-6.1.3 -R</span><br></pre></td></tr></table></figure><h4><span id="修改系统配置">修改系统配置</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1.解决：(max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144])  </span><br><span class="line">   </span><br><span class="line">[root@170 ~]# vim /etc/sysctl.conf  </span><br><span class="line"><span class="meta">#</span><span class="bash">增加</span></span><br><span class="line">vm.max_map_count=262144  </span><br><span class="line">[root@170 ~]# sysctl -p  #生效  </span><br><span class="line">   </span><br><span class="line">2.解决 :(max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536] max number of threads [1024] for user [lishang] likely too low, increase to at least [2048])  </span><br><span class="line"></span><br><span class="line">[root@170 ~]# vim /etc/security/limits.conf  </span><br><span class="line"><span class="meta">#</span><span class="bash">增加</span></span><br><span class="line">*  hard nofile 65536  </span><br><span class="line">*  soft nofile 65536  </span><br><span class="line"></span><br><span class="line">[root@170 ~]# su - es #切换用户生效limits.conf的配置</span><br></pre></td></tr></table></figure><h4><span id="启动">启动</span></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@170 ~]# su es</span><br><span class="line">[es@170 ~]# cd elasticsearch-6.1.3</span><br><span class="line"><span class="meta">#</span><span class="bash">启动</span></span><br><span class="line">[es@170 ~]# ./bin/elasticsearch</span><br><span class="line"><span class="meta">#</span><span class="bash">后台运行</span></span><br><span class="line">[es@170 ~]# ./bin/elasticsearch -d</span><br><span class="line"><span class="meta">#</span><span class="bash">验证</span></span><br><span class="line">[es@170 ~]# curl localhost:9200</span><br></pre></td></tr></table></figure><h4><span id="设置远程访问">设置远程访问</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@170 ~]# vi config/elasticsearch.yml</span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line"></span><br><span class="line">#查看进程</span><br><span class="line">[root@170 ~]# jps</span><br><span class="line">#结束进程</span><br><span class="line">[root@170 ~]# kill -9 pid</span><br><span class="line">#重启</span><br><span class="line">[root@170 ~]# su es</span><br><span class="line">[es@170 ~]# ./bin/elasticsearch -d</span><br></pre></td></tr></table></figure><p>done!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;安装配置jdk8&quot;&gt;安装配置JDK8&lt;/span&gt;&lt;/h2&gt;&lt;h4&gt;&lt;span id=&quot;下载jdk并解压缩&quot;&gt;下载JDK并解压缩&lt;/span&gt;&lt;/h4&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cla
      
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch中Index和Type的区别</title>
    <link href="http://calfgz.github.io//blog/2018/02/elasticsearch-index-type.html"/>
    <id>http://calfgz.github.io//blog/2018/02/elasticsearch-index-type.html</id>
    <published>2018-02-02T03:24:04.000Z</published>
    <updated>2019-04-28T07:38:07.343Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="背景">背景</span></h2><p>对于 ES 的新用户来说，有一个常见的问题：要存储一批新的数据时，应该在已有 index 里新建一个 type，还是给它新建一个 index？要想回答这个问题，我们必须先理解这两者是怎么实现的。<br>过去，我们为了让 ES 更容易理解，经常用关系型数据库做一个比喻： index 就像关系型数据库里的 database, type 就像 database 里的 table。但是这并不正确。由于两种数据库存储数据的方式是如此不同，任何比喻都是没有意义的。这种比喻往往会导致对 type 的滥用。</p><h2><span id="index-是什么">Index 是什么</span></h2><p>Index 存储在多个分片中，其中每一个分片都是一个独立的 Lucene Index。这就应该能提醒你，添加新 index 应该有个限度：每个 Lucene Index 都需要消耗一些磁盘，内存和文件描述符。因此，一个大的 index 比多个小 index 效率更高：Lucene Index 的固定开销被摊分到更多文档上了。<br>另一个重要因素是你准备怎么搜索你的数据。在搜索时，每个分片都需要搜索一次， 然后 ES 会合并来自所有分片的结果。例如，你要搜索 10 个 index，每个 index 有 5 个分片，那么协调这次搜索的节点就需要合并 5x10=50 个分片的结果。这也是一个你需要注意的地方：如果有太多分片的结果需要合并，或者你发起了一个结果巨大的搜索请求，合并任务会需要大量 CPU 和内存资源。这是第二个让 index 少一些的理由。</p><h2><span id="type-是什么">Type 是什么</span></h2><p>使用 type 允许我们在一个 index 里存储多种类型的数据，这样就可以减少 index 的数量了。在使用时，向每个文档加入 _type 字段，在指定 type 搜索时就会被用于过滤。使用 type 的一个好处是，搜索一个 index 下的多个 type，和只搜索一个 type 相比没有额外的开销 —— 需要合并结果的分片数量是一样的。<br>但是，这也是有限制的：<br>不同 type 里的字段需要保持一致。例如，一个 index 下的不同 type 里有两个名字相同的字段，他们的类型（string, date 等等）和配置也必须相同。<br>只在某个 type 里存在的字段，在其他没有该字段的 type 中也会消耗资源。这是 Lucene Index 带来的常见问题：它不喜欢稀疏。由于连续文档之间的差异太大，稀疏的 posting list 的压缩效率不高。这个问题在 doc value 上更为严重：为了提高速度，doc value 通常会为每个文档预留一个固定大小的空间，以便文档可以被高速检索。这意味着，如果 Lucene 确定它需要一个字节来存储某个数字类型的字段，它同样会给没有这个字段的文档预留一个字节。未来版本的 ES 会在这方面做一些改进，但是我仍然建议你在建模的时候尽量避免稀疏。[1]<br>得分是由 index 内的统计数据来决定的。也就是说，一个 type 中的文档会影响另一个 type 中的文档的得分。<br>这意味着，只有同一个 index 的中的 type 都有类似的映射 (mapping) 时，才应该使用 type。否则，使用多个 type 可能比使用多个 index 消耗的资源更多。</p><h2><span id="我应该用哪个">我应该用哪个</span></h2><p>这是个困难的问题，它的答案取决于你用的硬件、数据和用例。首先你要明白 type 是有用的，因为它能减少 ES 需要管理的 Lucene Index 的数量。但是也有另外一种方式可以减少这个数量：创建 index 的时候让它的分片少一些。例如，与其在一个 index 里塞上 5 个 type，不如创建 5 个只有一个分片的 index。<br>在你做决定的时候可以问自己下面几个问题：</p><ul><li>你需要使用父子文档吗？如果需要，只能在一个 index 里建立多个 type。</li><li>你的文档的映射是否相似？如果不相似，使用多个 index。</li><li>如果你的每个 type 都有足够多的文档，Lucene Index 的开销可以被分摊掉，你就可以安全的使用多个 index 了。如果有必要的话，可以把分片数量设小一点。</li><li>如果文档不够多，你可以考虑把文档放进一个 index 里的多个 type 里，甚至放进一个 type 里。</li></ul><p>总之，你可能有点惊讶，因为 type 的使用场景没有你想象的多，这是正确的。由于我们上面提到原因，在一个 index 中使用多个 type 的情景其实很少。如果你的数据有不同的映射，那就给他们分配不同的 index。但是请记住，如果不需要很高的写入吞吐量，或者存储的文档数量不多，你可以通过减少 index 的分片来使集群中的分片数量保持合理。</p><p>[1] posting list 和 doc value 都是 Lucene 的压缩技术，原理是保存后一个文档和前一个文档的差异，而不是完整的文档。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;背景&quot;&gt;背景&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;对于 ES 的新用户来说，有一个常见的问题：要存储一批新的数据时，应该在已有 index 里新建一个 type，还是给它新建一个 index？要想回答这个问题，我们必须先理解这两者是怎么实现的。&lt;br&gt;过去，我
      
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="http://calfgz.github.io/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>Linux下运行SpringBoot Jar包Shell脚本</title>
    <link href="http://calfgz.github.io//blog/2017/10/linux-start-springboot.html"/>
    <id>http://calfgz.github.io//blog/2017/10/linux-start-springboot.html</id>
    <published>2017-10-30T02:34:21.000Z</published>
    <updated>2019-04-28T07:38:07.342Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="背景">背景</span></h2><p>SpringBoot项目打成Jar包后是直接用<code>java -jar</code>命令行来运行的，放到Linux服务器上作为应用服务来运行时启动、停止、重启都特别麻烦。专门写了个<code>Shell</code>脚本方便在Linux服务器上对SpringBoot项目的Jar包进行启动、停止、重启操作。</p><h2><span id="shell脚本">Shell脚本</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Linux startup script <span class="keyword">for</span> Spring Boot App</span></span><br><span class="line"></span><br><span class="line">. /etc/rc.d/init.d/functions</span><br><span class="line"><span class="meta">#</span><span class="bash"> jdk 目录</span></span><br><span class="line">JAVA_HOME=/usr/java/jdk1.8.0_144</span><br><span class="line"><span class="meta">#</span><span class="bash"> jar 包目录</span></span><br><span class="line">JAR_HOME=/data/springcloud/server</span><br><span class="line"></span><br><span class="line">export JAVA_HOME JAR_HOME</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> jar 包名</span></span><br><span class="line">JAR_NAME="server-1.0.jar"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务端口号</span></span><br><span class="line">SERVER_PORT=9001</span><br><span class="line"></span><br><span class="line">JAVA=$JAVA_HOME/bin/java</span><br><span class="line"></span><br><span class="line">LANG=zh_CN.GBK</span><br><span class="line">export LANG</span><br><span class="line"></span><br><span class="line">ARGS="--server.port=$SERVER_PORT"</span><br><span class="line"></span><br><span class="line">force_stop() &#123;</span><br><span class="line">        ps auxwww|grep $JAR_NAME &gt;/dev/null</span><br><span class="line">        if [ $? = 0 ]; then</span><br><span class="line">                echo "force stop..."</span><br><span class="line">        PID=$(ps -ef | grep $JAR_NAME | grep -v grep | awk '&#123; print $2 &#125;')</span><br><span class="line">          if [ -n "$PID" ];then</span><br><span class="line">                kill -9 $PID</span><br><span class="line">                if [ $? = 0 ];then</span><br><span class="line">                  action $"Force stop server PID:$PID :"  /bin/true</span><br><span class="line">                else</span><br><span class="line">                  action $"Force stop server PID:$PID :" /bin/false</span><br><span class="line">                fi</span><br><span class="line">          else</span><br><span class="line">                echo "no PID found,the server has been stopped."</span><br><span class="line">          fi</span><br><span class="line">        else</span><br><span class="line">                echo "Process keyword: $JAR_NAME not found.NO Server started?"</span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case "$1" in</span><br><span class="line">  start)</span><br><span class="line">        ## clear jvm-log</span><br><span class="line">        test -e "$JAR_HOME/logs/app.log" &amp;&amp; /bin/cp -f $JAR_HOME/logs/app.log $JAR_HOME/logs/app.log.$(date "+%Y%m%d%H%M%S")</span><br><span class="line">        test -e "$JAR_HOME/logs/app.log" &amp;&amp; cat /dev/null &gt;$JAR_HOME/logs/app.log</span><br><span class="line"></span><br><span class="line">        nohup $JAVA -jar $JAR_HOME/$JAR_NAME $ARGS &gt; /dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">        ret=$?</span><br><span class="line"></span><br><span class="line">        if [ $ret -eq 0 ]; then</span><br><span class="line">        action $"Starting $JAR_NAME: " /bin/true</span><br><span class="line">        else</span><br><span class="line">        action $"Starting $JAR_NAME: " /bin/false</span><br><span class="line">        cat $JAR_HOME/logs/start.info</span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">        ;;</span><br><span class="line">  stop)</span><br><span class="line">    force_stop</span><br><span class="line"></span><br><span class="line">        ;;</span><br><span class="line">  restart)</span><br><span class="line">        $0 stop</span><br><span class="line">        $0 start</span><br><span class="line">        ;;</span><br><span class="line">  *)</span><br><span class="line">        echo "Usage: $0 &#123;start|stop|restart&#125;"</span><br><span class="line">        exit 1</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><h2><span id="使用">使用</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">./server.sh start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止</span></span><br><span class="line">./server.sh stop</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启</span></span><br><span class="line">./server.sh restart</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;背景&quot;&gt;背景&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;SpringBoot项目打成Jar包后是直接用&lt;code&gt;java -jar&lt;/code&gt;命令行来运行的，放到Linux服务器上作为应用服务来运行时启动、停止、重启都特别麻烦。专门写了个&lt;code&gt;Shell&lt;
      
    
    </summary>
    
      <category term="Linux" scheme="http://calfgz.github.io/categories/Linux/"/>
    
    
      <category term="SpringBoot" scheme="http://calfgz.github.io/tags/SpringBoot/"/>
    
      <category term="Linux" scheme="http://calfgz.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>如何在Linux安装RabbitMQ</title>
    <link href="http://calfgz.github.io//blog/2017/10/linux-instll-rabbitmq.html"/>
    <id>http://calfgz.github.io//blog/2017/10/linux-instll-rabbitmq.html</id>
    <published>2017-10-13T08:47:48.000Z</published>
    <updated>2019-04-28T07:38:07.342Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="安装erlang">安装Erlang</span></h2><h4><span id="下载erlang">下载Erlang</span></h4>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.rabbitmq.com/releases/erlang/erlang-18.2-1.el6.x86_64.rpm</span><br></pre></td></tr></table></figure><h4><span id="安装erlang">安装Erlang</span></h4>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ihv erlang-18.2-1.el6.x86_64.rpm</span><br></pre></td></tr></table></figure><h2><span id="安装rabbitmq">安装RabbitMQ</span></h2><h4><span id="下载rabbitmq">下载RabbitMQ</span></h4>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.6/rabbitmq-server-3.6.6-1.el7.noarch.rpm</span><br></pre></td></tr></table></figure><h4><span id="导入key文件">导入key文件</span></h4>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm --import http://www.rabbitmq.com/rabbitmq-signing-key-public.asc</span><br></pre></td></tr></table></figure><h4><span id="安装rabbitmq">安装RabbitMQ</span></h4>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y rabbitmq-server-3.6.6-1.el7.noarch.rpm</span><br></pre></td></tr></table></figure><p>   报错</p>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">error: Failed dependencies:</span><br><span class="line">socat is needed by rabbitmq-server-3.6.10-1.el6.noarch</span><br></pre></td></tr></table></figure><p>   解决</p>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.convirture.com/repos/deps/RHEL/6.x/x86_64/socat-1.7.1.3-1.el6.rf.x86_64.rpm</span><br><span class="line">rpm -ihv socat-1.7.1.3-1.el6.rf.x86_64.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash">再次安装 </span></span><br><span class="line">rpm -ihv rabbitmq-server-3.6.10-1.el6.noarch.rpm</span><br><span class="line">done!</span><br></pre></td></tr></table></figure><h2><span id="rabbitmq配置">RabbitMQ配置</span></h2>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">启动</span></span><br><span class="line">./rabbitmq-server -detached</span><br><span class="line"><span class="meta">#</span><span class="bash">查看服务状态</span></span><br><span class="line">./rabbitmqctl status</span><br><span class="line"><span class="meta">#</span><span class="bash">关闭服务</span></span><br><span class="line">./rabbitmqctl stop</span><br><span class="line"><span class="meta">#</span><span class="bash">启用网页插件</span></span><br><span class="line">./rabbitmq-plugins enable rabbitmq-management</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">远程访问配置</span></span><br><span class="line"><span class="meta">#</span><span class="bash">添加用户</span></span><br><span class="line">./rabbitmqctl add_user user user</span><br><span class="line"><span class="meta">#</span><span class="bash">添加权限</span></span><br><span class="line">./rabbitmqctl set_permissions -p "/" user ".*" ".*" ".*"</span><br><span class="line"><span class="meta">#</span><span class="bash">修改用户角色</span></span><br><span class="line">./rabbitmqctl set_user_tags user administrator</span><br><span class="line"><span class="meta">#</span><span class="bash">配置</span></span><br><span class="line">vi ./etc/rabbitmq/rabbitmq.config.example</span><br><span class="line">[</span><br><span class="line">  &#123;rabbit,</span><br><span class="line">  [</span><br><span class="line">    &#123;tct_listeners, [5672]&#125;,</span><br><span class="line">    &#123;loopback_users, ["user"]&#125;</span><br><span class="line">  ]&#125;</span><br><span class="line">].</span><br><span class="line"><span class="meta">#</span><span class="bash">访问</span></span><br><span class="line">http://localhost:15672</span><br></pre></td></tr></table></figure><p>done!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;安装erlang&quot;&gt;安装Erlang&lt;/span&gt;&lt;/h2&gt;&lt;h4&gt;&lt;span id=&quot;下载erlang&quot;&gt;下载Erlang&lt;/span&gt;&lt;/h4&gt;   &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
      <category term="Linux" scheme="http://calfgz.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://calfgz.github.io/tags/Linux/"/>
    
      <category term="RabbitMQ" scheme="http://calfgz.github.io/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>如何在无网络环境的Linux下安装Erlang</title>
    <link href="http://calfgz.github.io//blog/2017/10/linux-instll-erlang.html"/>
    <id>http://calfgz.github.io//blog/2017/10/linux-instll-erlang.html</id>
    <published>2017-10-13T08:33:38.000Z</published>
    <updated>2019-04-28T07:38:07.342Z</updated>
    
    <content type="html"><![CDATA[<p>最近要用到RabbitMQ，由于内部开发环境下的操作系统无法直接连外网，所有安装包都必须在其它机器 上下载好再上传上去安装，这里简单记录一下安装Erlang的具体步骤：</p><h4><span id="下载最新的erlang源码包">下载最新的Erlang源码包</span></h4>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://erlang.org/download/otp_src_20.1.tar.gz</span><br></pre></td></tr></table></figure><h4><span id="解压并安装">解压并安装</span></h4>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf otp_src_20.1.tar.gz</span><br><span class="line">cd otp_src_20.1</span><br><span class="line">./configure</span><br><span class="line">mark &amp;&amp; mark install</span><br></pre></td></tr></table></figure><h4><span id="安装完后输入erl得到以下界面表示安装成功">安装完后输入<code>erl</code>得到以下界面表示安装成功。</span></h4>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@dev170 /]# erl</span><br><span class="line">Erlang/OTP 20 [erts-9.1] [source] [64-bit] [smp:1:1] [ds:1:1:10] [async-threads:10] [hipe] [kernel-poll:false]</span><br><span class="line"></span><br><span class="line">Eshell V9.1  (abort with ^G)</span><br><span class="line">1&gt;</span><br></pre></td></tr></table></figure><p>   ​</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近要用到RabbitMQ，由于内部开发环境下的操作系统无法直接连外网，所有安装包都必须在其它机器 上下载好再上传上去安装，这里简单记录一下安装Erlang的具体步骤：&lt;/p&gt;
&lt;h4&gt;&lt;span id=&quot;下载最新的erlang源码包&quot;&gt;下载最新的Erlang源码包&lt;/sp
      
    
    </summary>
    
      <category term="Linux" scheme="http://calfgz.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://calfgz.github.io/tags/Linux/"/>
    
      <category term="Erlang" scheme="http://calfgz.github.io/tags/Erlang/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot 采用Sharding-JDBC 实现Mybaits的分库分表功能</title>
    <link href="http://calfgz.github.io//blog/2017/09/springboot-mybatis-sharding-jdbc.html"/>
    <id>http://calfgz.github.io//blog/2017/09/springboot-mybatis-sharding-jdbc.html</id>
    <published>2017-09-14T05:52:31.000Z</published>
    <updated>2019-04-28T07:38:07.342Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="背景">背景</span></h2><p>在开发大数据量的应用时为了减少单表数据量经常会使用到分库分表功能，以前对分库分表功能都是自己在代码上单独对需要分库分表的实体进行特殊逻辑处理。此种开发方式非常繁琐且很容易出问题。<br>业内其实也有很多比较成熟的解决方案，如：<code>Cobar</code>、<code>Cobar-client</code>、<code>TDDL</code>、<code>Sharding-JDBC</code>等，这次就拿当当网开源的Sharding-JDBC来实现基于Mybatis的分库分表功能。</p><h2><span id="sharding-jdbc简介">Sharding-JDBC简介</span></h2><p>Sharding-JDBC是当当网的开源产品，他直接封装JDBC API，可以理解为增强版的JDBC驱动，旧代码迁移成本几乎为零：</p><ul><li>可适用于任何基于java的ORM框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template或直接使用JDBC。</li><li>可基于任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid等。</li><li>理论上可支持任意实现JDBC规范的数据库。目前支持MySQL，Oracle，SQLServer和PostgreSQL。</li></ul><p>Sharding-JDBC定位为轻量级java框架，使用客户端直连数据库，以jar包形式提供服务，未使用中间层，无需额外部署，无其他依赖，DBA也无需改变原有的运维方式。采用”半理解”理念的SQL解析引擎，以达到性能与兼容性的最大平衡。</p><p>Sharding-JDBC功能灵活且全面：</p><ul><li>分片策略灵活，可支持=，BETWEEN，IN等多维度分片，也可支持多分片键共用。</li><li>SQL解析功能完善，支持聚合，分组，排序，Limit，TOP等查询，并且支持Binding Table以及笛卡尔积的表查询。</li><li>支持柔性事务(目前仅最大努力送达型)。</li><li>支持读写分离。</li><li>支持分布式生成全局主键。</li></ul><p>Sharding-JDBC配置多样：</p><ul><li>可支持YAML和Spring命名空间配置</li><li>灵活多样的inline方式</li></ul><h2><span id="sharding-jdbc与其它分库分表产品对比">Sharding-JDBC与其它分库分表产品对比</span></h2><p>以下是常见的分库分表产品和Sharding-JDBC的对比：</p><table><thead><tr><th>功能</th><th>Cobar</th><th>Cobar-client</th><th>TDDL</th><th>Sharding-JDBC</th></tr></thead><tbody><tr><td>分库</td><td>有</td><td>有</td><td>未开源</td><td>有</td></tr><tr><td>分表</td><td>无</td><td>无</td><td>未开源</td><td>有</td></tr><tr><td>中间层</td><td>是</td><td>否</td><td>否</td><td>否</td></tr><tr><td>ORM支持</td><td>任意</td><td>仅MyBatis</td><td>任意</td><td>任意</td></tr><tr><td>数据库支持</td><td>仅MySQL</td><td>任意</td><td>任意</td><td>任意</td></tr><tr><td>异构语言</td><td>可</td><td>仅Java</td><td>仅Java</td><td>仅Java</td></tr><tr><td>外部依赖</td><td>无</td><td>无</td><td>Diamond</td><td>无</td></tr></tbody></table><h2><span id="引入依赖">引入依赖</span></h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.github.calfgz<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>sharding-demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>sharding-demo<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>Demo project for Spring Boot Bybatis Sharding-jdbc<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.7.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">relativePath</span>/&gt;</span> <span class="comment">&lt;!-- lookup parent from repository --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project.reporting.outputEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.reporting.outputEncoding</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.spring.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- aigorithm jdbc --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.dangdang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>sharding-jdbc-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.dangdang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>sharding-jdbc-config-yaml<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">&lt;dependency&gt;</span></span><br><span class="line"><span class="comment">&lt;groupId&gt;com.dangdang&lt;/groupId&gt;</span></span><br><span class="line"><span class="comment">&lt;artifactId&gt;aigorithm-jdbc-self-id-generator&lt;/artifactId&gt;</span></span><br><span class="line"><span class="comment">&lt;version&gt;1.4.2&lt;/version&gt;</span></span><br><span class="line"><span class="comment">&lt;/dependency&gt;</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- mybatis --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.spring.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>tk.mybatis<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mapper-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.pagehelper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>pagehelper-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- druid --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><h2><span id="实现sharding-jdbc的配置">实现Sharding-JDBC的配置</span></h2><p>配置sharding jdbc有三种方式，可以用java代码配置，YAML配置和Spring xml配置，这里使用YAML配置方式。</p><p>新建sharding.yml配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">dataSource:</span><br><span class="line">  ds_0: !!org.apache.commons.dbcp.BasicDataSource</span><br><span class="line">    driverClassName: com.mysql.jdbc.Driver</span><br><span class="line">    url: jdbc:mysql://localhost:3306/ds_yaml_0</span><br><span class="line">    username: root</span><br><span class="line">    password: </span><br><span class="line">  ds_1: !!org.apache.commons.dbcp.BasicDataSource</span><br><span class="line">    driverClassName: com.mysql.jdbc.Driver</span><br><span class="line">    url: jdbc:mysql://localhost:3306/ds_yaml_1</span><br><span class="line">    username: root</span><br><span class="line">    password: </span><br><span class="line">  </span><br><span class="line">tables:</span><br><span class="line">  sc_user:</span><br><span class="line">    actualTables: sc_user_$&#123;0..5&#125;</span><br><span class="line">    tableStrategy:</span><br><span class="line">      shardingColumns: id</span><br><span class="line">      algorithmExpression: sc_user_$&#123;id.longValue() % 6&#125;</span><br><span class="line"></span><br><span class="line">bindingTables:</span><br><span class="line">  - tableNames: sc_user</span><br><span class="line"></span><br><span class="line">#默认数据库分片策略</span><br><span class="line">defaultDatabaseStrategy:</span><br><span class="line">  shardingColumns: id</span><br><span class="line">  algorithmExpression: ds_0</span><br><span class="line"></span><br><span class="line">props:</span><br><span class="line">  sql.show: true</span><br></pre></td></tr></table></figure></p><p>实现Sharding-JDBC的分库分表配置:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.github.calfgz.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.dangdang.ddframe.rdb.sharding.config.yaml.api.YamlShardingDataSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.ibatis.session.SqlSessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.mybatis.spring.SqlSessionFactoryBean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.core.io.ClassPathResource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.core.io.Resource;</span><br><span class="line"><span class="keyword">import</span> org.springframework.jdbc.datasource.DataSourceTransactionManager;</span><br><span class="line"><span class="keyword">import</span> org.springframework.transaction.PlatformTransactionManager;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.sql.DataSource;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> calf</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2017-09-15 10:10</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShardingConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> DataSource <span class="title">dataSource</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Resource resource = <span class="keyword">new</span> ClassPathResource(<span class="string">"sharding.yml"</span>);</span><br><span class="line">        File file = resource.getFile();</span><br><span class="line">        DataSource dataSource = <span class="keyword">new</span> YamlShardingDataSource(file);</span><br><span class="line">        <span class="keyword">return</span> dataSource;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SqlSessionFactory <span class="title">sqlSessionFactoryBean</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        SqlSessionFactoryBean sqlSessionFactoryBean = <span class="keyword">new</span> SqlSessionFactoryBean();</span><br><span class="line">        sqlSessionFactoryBean.setDataSource(dataSource());</span><br><span class="line">        <span class="keyword">return</span> sqlSessionFactoryBean.getObject();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> PlatformTransactionManager <span class="title">transactionManager</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> DataSourceTransactionManager(dataSource());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2><span id="具体实现">具体实现</span></h2><p>实体类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Table</span>(name = <span class="string">"sc_user"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> <span class="keyword">implements</span> <span class="title">Serializable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">6356423424942543731L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Id</span></span><br><span class="line">    <span class="keyword">long</span> id;</span><br><span class="line">    String name;</span><br><span class="line">    <span class="keyword">int</span> sex;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Mapper类:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserMapper</span> <span class="keyword">extends</span> <span class="title">MyMapper</span>&lt;<span class="title">User</span>&gt; </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Service类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserService</span> <span class="keyword">extends</span> <span class="title">BaseService</span>&lt;<span class="title">User</span>&gt; </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>通用Service类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseService</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">protected</span> Mapper&lt;T&gt; mapper;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取通用Mapper</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Mapper&lt;T&gt; <span class="title">getMapper</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据主键查询实体类</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">selectByKey</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.selectByPrimaryKey(key);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 新增实体类，不采用数据库默认值，所有字段写入数据库,包括null字段</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> entity</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">save</span><span class="params">(T entity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.insert(entity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 新增实体类，空字段不写入数据库，采用数据库默认值</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> entity</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveSelective</span><span class="params">(T entity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.insertSelective(entity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据主键删除实体类</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">delete</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.deleteByPrimaryKey(key);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据主键更新实体类，所有字段写入数据库,包括null字段</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> entity</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(T entity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.updateByPrimaryKey(entity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据主键更新实体类，只更新不为空的字段</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> entity</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">updateSelective</span><span class="params">(T entity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.updateByPrimaryKeySelective(entity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据examplt条件查找List</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> example</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;T&gt; <span class="title">selectByExample</span><span class="params">(Object example)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.selectByExample(example);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询所有列表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;T&gt; <span class="title">selectAll</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mapper.selectAll();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Controller类实现REST接口：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.github.calfgz.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io.github.calfgz.model.User;</span><br><span class="line"><span class="keyword">import</span> io.github.calfgz.service.UserService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> calf</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2017-09-14 17:32</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/users"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    UserService userService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;User&gt; <span class="title">getList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userService.selectAll();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">detail</span><span class="params">(@PathVariable(name = <span class="string">"id"</span>, required = <span class="keyword">true</span>)</span> <span class="keyword">long</span> id) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userService.selectByKey(id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">create</span><span class="params">(User user)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userService.save(user);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PutMapping</span>(<span class="string">"/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">update</span><span class="params">(@PathVariable(name = <span class="string">"id"</span>, required = <span class="keyword">true</span>)</span> <span class="keyword">long</span> id, User user) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userService.updateSelective(user);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>测试ok! done!!!</p><p>源码查看：<a href="https://github.com/calfgz/sharding-demo" target="_blank" rel="noopener">github</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;背景&quot;&gt;背景&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;在开发大数据量的应用时为了减少单表数据量经常会使用到分库分表功能，以前对分库分表功能都是自己在代码上单独对需要分库分表的实体进行特殊逻辑处理。此种开发方式非常繁琐且很容易出问题。&lt;br&gt;业内其实也有很多比较成熟
      
    
    </summary>
    
      <category term="SpringBoot" scheme="http://calfgz.github.io/categories/SpringBoot/"/>
    
    
      <category term="SpringBoot" scheme="http://calfgz.github.io/tags/SpringBoot/"/>
    
      <category term="Mybatis" scheme="http://calfgz.github.io/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>缓存在分布式系统中的应用[转]</title>
    <link href="http://calfgz.github.io//blog/2017/08/architecture-cache.html"/>
    <id>http://calfgz.github.io//blog/2017/08/architecture-cache.html</id>
    <published>2017-08-25T07:31:59.000Z</published>
    <updated>2019-04-28T07:38:07.341Z</updated>
    
    <content type="html"><![CDATA[<p>缓存是分布式系统中的重要组件，主要解决高并发，大数据场景下，热点数据访问的性能问题。提供高性能的数据快速访问。</p><p>本文是介绍缓存的原理，缓存的分类，缓存的设计，CDN缓存（原理，架构参考和技术实践），反向代理缓存（原理，Squid架构实践和常用代理缓存之间的比较）。本文主要是自己的学习总结和网络文章摘录，供学习之用。</p><h2><span id="缓存概述">缓存概述</span></h2><hr><p>缓存是分布式系统中的重要组件，主要解决高并发，大数据场景下，热点数据访问的性能问题。提供高性能的数据快速访问。</p><h3><span id="缓存的原理">缓存的原理</span></h3><ol><li>将数据写入/读取速度更快的存储（设备）；</li><li>将数据缓存到离应用最近的位置；</li><li>将数据缓存到离用户最近的位置。</li></ol><h3><span id="缓存分类">缓存分类</span></h3><p>在分布式系统中，缓存的应用非常广泛，从部署角度有以下几个方面的缓存应用。</p><ol><li>CDN缓存；</li><li>反向代理缓存；</li><li>分布式Cache；</li><li>本地应用缓存；</li></ol><h3><span id="缓存媒介">缓存媒介</span></h3><ul><li>常用中间件：Varnish，Nginx，Squid，Memcache，Redis，Ehcache等；</li><li>缓存的内容：文件，数据，对象；</li><li>缓存的介质：CPU，内存（本地，分布式），磁盘（本地，分布式）</li></ul><h3><span id="缓存设计">缓存设计</span></h3><p>缓存设计需要解决以下几个问题：</p><ol><li>缓存什么？<br> 哪些数据需要缓存：1.热点数据；2.静态资源；</li><li>缓存的位置？<br> CDN，反向代理，分布式缓存服务器，本机（内存，硬盘）</li><li>如何缓存的问题？<br> 过期策略<pre><code>- 固定时间：比如指定缓存的时间是30分钟；- 相对时间：比如最近10分钟内没有访问的数据；</code></pre> 同步机制<pre><code>- 实时写入；（推）- 异步刷新；（推拉）</code></pre></li></ol><h2><span id="cdn缓存">CDN缓存</span></h2><hr><p>CDN主要解决将数据缓存到离用户最近的位置，一般缓存静态资源文件（页面，脚本，图片，视频，文件等）。国内网络异常复杂，跨运营商的网络访问会很慢。为了解决跨运营商或各地用户访问问题，可以在重要的城市，部署CDN应用。使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。</p><h3><span id="cnd原理">CND原理</span></h3><p>CDN的基本原理是广泛采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区或网络中，在用户访问网站时，利用全局负载技术将用户的访问指向距离最近的工作正常的缓存服务器上，由缓存服务器直接响应用户请求。</p><h4><span id="未部署cdn应用前">未部署CDN应用前</span></h4><p><img src="/images/architecture-cache/001.png" alt="缓存在分布式系统中的应用-未部署CDN应用前"></p><p>网络请求路径：</p><ul><li>请求：本机网络（局域网）——》运营商网络——》应用服务器机房</li><li>响应：应用服务器机房——》运营商网络——》本机网络（局域网）</li></ul><p>在不考虑复杂网络的情况下，从请求到响应需要经过3个节点，6个步骤完成一次用户访问操作。</p><h4><span id="部署cdn应用后">部署CDN应用后</span></h4><p><img src="/images/architecture-cache/002.png" alt="缓存在分布式系统中的应用-部署CDN应用后"></p><p>网络路径：</p><ul><li>请求：本机网络（局域网）——》运营商网络</li><li>响应：运营商网络——》本机网络（局域网）</li></ul><p>在不考虑复杂网络的情况下，从请求到响应需要经过2个节点，2个步骤完成一次用户访问操作。</p><p>与不部署CDN服务相比，减少了1个节点，4个步骤的访问。极大的提高的系统的响应速度。</p><h3><span id="cdn优缺点">CDN优缺点</span></h3><h4><span id="优点摘自百度百科">优点（摘自百度百科）</span></h4><ol><li>本地Cache加速：提升访问速度，尤其含有大量图片和静态页面站点；</li><li>镜像服务：消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量；</li><li>远程加速：远程访问用户根据DNS负载均衡技术智能自动选择Cache服务器，选择最快的Cache服务器，加快远程访问的速度；</li><li>带宽优化：自动生成服务器的远程Mirror（镜像）cache服务器，远程用户访问时从cache服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点WEB服务器负载等功能。</li><li>集群抗攻击：广泛分布的CDN节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种D.D.o.S攻击对网站的影响，同时保证较好的服务质量。</li></ol><h4><span id="缺点">缺点</span></h4><ol><li>动态资源缓存，需要注意实时性；<br> 解决：主要缓存静态资源，动态资源建立多级缓存或准实时同步；</li><li>如何保证数据的一致性和实时性需要权衡考虑；<br> 解决：<pre><code>- 设置缓存失效时间（1个小时，最终一致性）；- 数据版本号；</code></pre></li></ol><h3><span id="cnd架构参考">CND架构参考</span></h3><p>摘自《云宙视频CDN系统》<br><img src="/images/architecture-cache/003.jpg" alt="缓存在分布式系统中的应用-CDN架构参考"></p><h3><span id="cnd技术实践">CND技术实践</span></h3><p>目前，中小型互联网公司，综合成本考虑，一般租用第三方CDN服务，大型互联网公司，采用自建或第三方结合的方式。比如淘宝刚开始使用第三方的，当流量很大后，第三方公司无法支撑其CDN流量，淘宝最后采用自建CDN的方式实现。</p><p>淘宝CDN，如下图（来自网络）：<br><img src="/images/architecture-cache/004.png" alt="缓存在分布式系统中的应用-淘宝CDN"></p><h2><span id="反向代理缓存">反向代理缓存</span></h2><p>反向代理是指在网站服务器机房部署代理服务器，实现负载均衡，数据缓存，安全控制等功能。</p><h3><span id="缓存原理">缓存原理</span></h3><p>反向代理位于应用服务器机房，处理所有对WEB服务器的请求。如果用户请求的页面在代理服务器上有缓冲的话，代理服务器直接将缓冲内容发送给用户。如果没有缓冲则先向WEB服务器发出请求，取回数据，本地缓存后再发送给用户。通过降低向WEB服务器的请求数，从而降低了WEB服务器的负载。</p><p><img src="/images/architecture-cache/005.png" alt="缓存在分布式系统中的应用-反向代理缓存"></p><p>反向代理一般缓存静态资源，动态资源转发到应用服务器处理。常用的缓存应用服务器有Varnish，Ngnix，Squid。</p><h3><span id="squid示例">Squid示例</span></h3><p>Squid 反向代理一般只缓存静态资源，动态程序默认不缓存。根据从 WEB 服务器返回的 HTTP 头标记来缓冲静态页面。有四个最重要 HTTP 头标记：</p><ul><li>Last-Modified: 告诉反向代理页面什么时间被修改</li><li>Expires: 告诉反向代理页面什么时间应该从缓冲区中删除</li><li>Cache-Control: 告诉反向代理页面是否应该被缓冲</li><li>Pragma: 用来包含实现特定的指令，最常用的是 Pragma:no-cache</li></ul><p><img src="/images/architecture-cache/006.jpg" alt="缓存在分布式系统中的应用-反向代理Spuid缓存"></p><p>Squid 反向代理加速网站实例</p><ol><li>通过DNS的轮询技术，将客户端的请求分发给其中一台 Squid 反向代理服务器处理；</li><li>如果这台 Squid 缓存了用户的请求资源，则将请求的资源直接返回给用户；</li><li>否则这台 Squid 将没有缓存的请求根据配置的规则发送给邻居 Squid 和后台的 WEB 服务器处理；</li><li>这样既减轻后台 WEB 服务器的负载，又提高整个网站的性能和安全性。</li></ol><h3><span id="代理缓存比较">代理缓存比较</span></h3><p>常用的代理缓存有Varnish，Squid，Ngnix，简单比较如下：</p><ol><li>varnish和squid是专业的cache服务，nginx需要第三方模块支持；</li><li>Varnish采用内存型缓存，避免了频繁在内存、磁盘中交换文件，性能比Squid高；</li><li>Varnish由于是内存cache，所以对小文件如css,js,小图片啥的支持很棒，后端的持久化缓存可以采用的是Squid或ATS；</li><li>Squid功能全而大，适合于各种静态的文件缓存，一般会在前端挂一个HAProxy或nginx做负载均衡跑多个实例；</li><li>Nginx采用第三方模块ncache做的缓冲，性能基本达到varnish，一般作为反向代理使用，可以实现简单的缓存。</li></ol><h2><span id="分布式缓存">分布式缓存</span></h2><hr><p>CDN,反向代理缓存，主要解决静态文件，或用户请求资源的缓存，数据源一般为静态文件或动态生成的文件（有缓存头标识）。</p><p>分布式缓存，主要指缓存用户经常访问数据的缓存，数据源为数据库。一般起到热点数据访问和减轻数据库压力的作用。</p><p>目前分布式缓存设计，在大型网站架构中是必备的架构要素。常用的中间件有Memcache，Redis。</p><h3><span id="memcached">Memcached</span></h3><p>Memcached是一个高性能，分布式内存对象缓存系统，通过在内存里维护一个统一的巨大的hash表，它能够用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等。简单的说就是将数据调用到内存中，然后从内存中读取，从而大大提高读取速度。</p><p>Memcached特性：</p><ol><li>使用物理内存作为缓存区，可独立运行在服务器上。每个进程最大2G，如果想缓存更多的数据，可以开辟更多的memcache进程（不同端口）或者使用分布式memcache进行缓存，将数据缓存到不同的物理机或者虚拟机上。</li><li>使用key-value的方式来存储数据，这是一种单索引的结构化数据组织形式，可使数据项查询时间复杂度为O(1)。</li><li>协议简单：基于文本行的协议，直接通过telnet在memcached服务器上可进行存取数据操作，简单，方便多种缓存参考此协议；</li><li>基于libevent高性能通信：Libevent是一套利用C开发的程序库，它将BSD系统的kqueue,Linux系统的epoll等事件处理功能封装成一个接口，与传统的select相比，提高了性能。</li><li>内置的内存管理方式：所有数据都保存在内存中，存取数据比硬盘快，当内存满后，通过LRU算法自动删除不使用的缓存，但没有考虑数据的容灾问题，重启服务，所有数据会丢失。</li><li>分布式：各个memcached服务器之间互不通信，各自独立存取数据，不共享任何信息。服务器并不具有分布式功能，分布式部署取决于memcache客户端。</li><li>缓存策略：Memcached的缓存策略是LRU（最近最少使用）到期失效策略。在memcached内存储数据项时，可以指定它在缓存的失效时间，默认为永久。当memcached服务器用完分配的内时，失效的数据被首先替换，然后也是最近未使用的数据。在LRU中，memcached使用的是一种Lazy Expiration策略，自己不会监控存入的key/vlue对是否过期，而是在获取key值时查看记录的时间戳，检查key/value对空间是否过期，这样可减轻服务器的负载。</li></ol><h4><span id="memcached工作原理">Memcached工作原理</span></h4><p><img src="/images/architecture-cache/007.png" alt="缓存在分布式系统中的应用-Memcached工作原理"></p><p>MemCache的工作流程如下：</p><ol><li>先检查客户端的请求数据是否在memcached中，如有，直接把请求数据返回，不再对数据库进行任何操作；</li><li>如果请求的数据不在memcached中，就去查数据库，把从数据库中获取的数据返回给客户端，同时把数据缓存一份到memcached中（memcached客户端不负责，需要程序实现）；</li><li>每次更新数据库的同时更新memcached中的数据，保证一致性；</li><li>当分配给memcached内存空间用完之后，会使用LRU（Least Recently Used，最近最少使用）策略加上到期失效策略，失效数据首先被替换，然后再替换掉最近未使用的数据。</li></ol><h4><span id="memcached集群">Memcached集群</span></h4><p>memcached 虽然称为 “ 分布式 ” 缓存服务器，但服务器端并没有 “ 分布式 ” 功能。每个服务器都是完全独立和隔离的服务。 memcached 的分布式，是由客户端程序实现的。</p><p>当向memcached集群存入/取出key value时，memcached客户端程序根据一定的算法计算存入哪台服务器，然后再把key value值存到此服务器中。</p><p>存取数据分二步走，第一步，选择服务器，第二步存取数据。</p><p><img src="/images/architecture-cache/008.png" alt="缓存在分布式系统中的应用-Memcached集群"></p><h4><span id="分布式算法consistent-hashing">分布式算法(Consistent Hashing)：</span></h4><p>选择服务器算法有两种，一种是根据余数来计算分布，另一种是根据散列算法来计算分布。</p><h5><span id="余数算法">余数算法：</span></h5><p>先求得键的整数散列值，再除以服务器台数，根据余数确定存取服务器。</p><ul><li>优点：计算简单，高效；</li><li>缺点：在memcached服务器增加或减少时，几乎所有的缓存都会失效。</li></ul><h5><span id="散列算法一致性hash">散列算法：（一致性Hash）</span></h5><p>先算出memcached服务器的散列值，并将其分布到0到2的32次方的圆上，然后用同样的方法算出存储数据的键的散列值并映射至圆上，最后从数据映射到的位置开始顺时针查找，将数据保存到查找到的第一个服务器上，如果超过2的32次方，依然找不到服务器，就将数据保存到第一台memcached服务器上。<br><img src="/images/architecture-cache/009.jpg" alt="缓存在分布式系统中的应用-一致性Hash算法"></p><p>如果添加了一台memcached服务器，只在圆上增加服务器的逆时针方向的第一台服务器上的键会受到影响。</p><p>一致性Hash算法：解决了余数算法增加节点命中大幅额度降低的问题，理论上，插入一个实体节点，平均会影响到：虚拟节点数 /2 的节点数据的命中。</p><h3><span id="redis">Redis</span></h3><p>Redis 是一个开源（BSD许可）的，基于内存的，多数据结构存储系统。可以用作数据库、缓存和消息中间件。 支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。</p><p>内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（high availability）。</p><h4><span id="redis常用数据类型">Redis常用数据类型</span></h4><h5><span id="string">String</span></h5><blockquote><ul><li>常用命令：set,get,decr,incr,mget 。</li><li>应用场景：String是最常用的一种数据类型，与Memcache的key value存储方式类似。</li><li>实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr,decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。</li></ul></blockquote><h5><span id="hash">Hash</span></h5><blockquote><ul><li>常用命令：hget,hset,hgetall 。</li><li>应用场景：以存储一个用户信息对象数据，为例：<br><img src="/images/architecture-cache/010.png" alt="缓存在分布式系统中的应用-Hash存储"></li><li>实现方式：Redis Hash对应的Value，内部实际就是一个HashMap，实际这里会有2种不同实现。</li></ul><ol><li>Hash的成员比较少时Redis为了节省内存会采用类似一维数 组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap；</li><li>当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。</li></ol></blockquote><h5><span id="list">List</span></h5><blockquote><ul><li>常用命令：lpush,rpush,lpop,rpop,lrange。</li><li>应用场景：<br>Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现。</li><li>实现方式：<br>Redis list的实现为一个双向链表，可以支持反向查找和遍历，方便操作。不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。</li></ul></blockquote><h5><span id="set">Set</span></h5><blockquote><ul><li>常用命令：sadd,spop,smembers,sunion。</li><li>应用场景：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。</li><li>实现方式：set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。</li></ul></blockquote><h5><span id="sorted-set">Sorted set</span></h5><blockquote><ul><li>常用命令：zadd,zrange,zrem,zcard；</li><li>使用场景：<br>Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。</li><li>实现方式：<br>Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的 是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。</li></ul></blockquote><h4><span id="redis集群">Redis集群</span></h4><h5><span id="通过keepalived实现的高可用方案">通过keepalived实现的高可用方案</span></h5><p><img src="/images/architecture-cache/011.png" alt="缓存在分布式系统中的应用-Redis高可用方案"></p><p>切换流程：</p><ol><li>当Master挂了后，VIP漂移到Slave；Slave 上keepalived 通知redis 执行：slaveof no one ,开始提供业务</li><li>当Master起来后，VIP 地址不变，Master的keepalived 通知redis 执行slaveof slave IP host ，开始作为从同步数据</li><li>依次类推</li></ol><p>主从同时Down机情况：</p><ol><li>非计划性，不做考虑，一般也不会存在这种问题</li><li>计划性重启，重启之前通过运维手段SAVE DUMP 主库数据；需要注意顺序：<ol><li>关闭其中一台机器上所有redis，是得master全部切到另外一台机器（多实例部署，单机上既有主又有从的情况）；并关闭机器</li><li>依次dump主上redis服务</li><li>关闭主</li><li>启动主，并等待数据load完毕</li><li>启动从<br>6.删除DUMP 文件（避免重启加载慢）</li></ol></li></ol><h5><span id="使用twemproxy-实现集群方案">使用Twemproxy 实现集群方案</span></h5><p>由twitter开源的c版本proxy，同时支持memcached和redis，目前最新版本为：0.2.4，持续开发中;<a href="https://github.com/twitter/twemproxy" target="_blank" rel="noopener">https://github.com/twitter/twemproxy</a> .twitter用它主要减少前端与缓存服务间网络连接数。</p><p>特点：快、轻量级、减少后端Cache Server连接数、易配置、支持ketama、modula、random、常用hash 分片算法。</p><p><img src="/images/architecture-cache/012.png" alt="缓存在分布式系统中的应用-集群"></p><p>这里使用keepalived实现高可用主备方案，解决proxy单点问题；</p><p>优点：</p><ol><li>对于客户端而言，redis集群是透明的，客户端简单，遍于动态扩容</li><li>Proxy为单点、处理一致性hash时，集群节点可用性检测不存在脑裂问题</li><li>高性能，CPU密集型，而redis节点集群多CPU资源冗余，可部署在redis节点集群上，不需要额外设备</li></ol><h3><span id="memcache与redis的比较">Memcache与Redis的比较</span></h3><ol><li>数据结构：Memcache只支持key value存储方式，Redis支持更多的数据类型，比如Key value，hash，list，set，zset；</li><li>多线程：Memcache支持多线程，redis支持单线程；CPU利用方面Memcache优于redis；</li><li>持久化：Memcache不支持持久化，Redis支持持久化；</li><li>内存利用率：memcache高，redis低（采用压缩的情况下比memcache高）；</li><li>过期策略：memcache过期后，不删除缓存，会导致下次取数据数据的问题，Redis有专门线程，清除缓存数据；</li></ol><h2><span id="本地缓存">本地缓存</span></h2><hr><p>本地缓存是指应用内部的缓存，标准的分布式系统，一般有多级缓存构成。本地缓存是离应用最近的缓存，一般可以将数据缓存到硬盘或内存。</p><h3><span id="硬盘缓存">硬盘缓存</span></h3><p>将数据缓存到硬盘到，读取时从硬盘读取。原理是直接读取本机文件，减少了网络传输消耗，比通过网络读取数据库速度更快。可以应用在对速度要求不是很高，但需要大量缓存存储的场景。</p><h3><span id="内存缓存">内存缓存</span></h3><p>直接将数据存储到本机内存中，通过程序直接维护缓存对象，是访问速度最快的方式。</p><h2><span id="缓存架构示例">缓存架构示例</span></h2><hr><p><img src="/images/architecture-cache/013.png" alt="缓存在分布式系统中的应用-缓存架构示例"></p><p>职责划分：</p><ul><li>CDN：存放HTML,CSS,JS等静态资源；</li><li>反向代理：动静分离，只缓存用户请求的静态资源；</li><li>分布式缓存：缓存数据库中的热点数据；</li><li>本地缓存：缓存应用字典等常用数据；</li></ul><p>请求过程：</p><ol><li>浏览器向客户端发起请求，如果CDN有缓存则直接返回；</li><li>如果CDN无缓存，则访问反向代理服务器；</li><li>如果反向代理服务器有缓存则直接返回；</li><li>如果反向代理服务器无缓存或动态请求，则访问应用服务器；</li><li>应用服务器访问本地缓存；如果有缓存，则返回代理服务器，并缓存数据；（动态请求不缓存）</li><li>如果本地缓存无数据，则读取分布式缓存；并返回应用服务器；应用服务器将数据缓存到本地缓存（部分）；</li><li>如果分布式缓存无数据，则应用程序读取数据库数据，并放入分布式缓存；</li></ol><h2><span id="数据一致性">数据一致性</span></h2><p>缓存是在数据持久化之前的一个节点，主要是将热点数据放到离用户最近或访问速度更快的介质中，加快数据的访问，减小响应时间。</p><p>因为缓存属于持久化数据的一个副本，因此不可避免的会出现数据不一致问题。导致脏读或读不到数据的情况。数据不一致，一般是因为网络不稳定或节点故障导致。根据数据的操作顺序，主要有以下几种情况。</p><h3><span id="场景介绍">场景介绍</span></h3><ol><li>先写缓存，再写数据库<br> 如下图：<br> <img src="/images/architecture-cache/014.jpg" alt="缓存在分布式系统中的应用-先写缓存，再写数据库"></li></ol><p>假如缓存写成功，但写数据库失败或响应延迟，则下次读取（并发读）缓存时，就出现脏读；</p><ol start="2"><li>先写数据库，再写缓存<br> 如下图：<br> <img src="/images/architecture-cache/015.jpg" alt="缓存在分布式系统中的应用-先写数据库，再写缓存"></li></ol><p>假如写数据库成功，但写缓存失败，则下次读取（并发读）缓存时，则读不到数据；</p><ol start="3"><li><p>缓存异步刷新<br> 指数据库操作和写缓存不在一个操作步骤中，比如在分布式场景下，无法做到同时写缓存或需要异步刷新（补救措施）时候。</p><p> <img src="/images/architecture-cache/016.jpg" alt="缓存在分布式系统中的应用-异步刷新缓存"></p></li></ol><p>此种情况，主要考虑数据写入和缓存刷新的时效性。比如多久内刷新缓存，不影响用户对数据的访问。</p><h3><span id="解决方法">解决方法</span></h3><p>第一个场景：</p><p>这个写缓存的方式，本身就是错误的，需要改为先写持久化介质，再写缓存的方式。</p><p>第二个场景：</p><ol><li>根据写入缓存的响应来进行判断，如果缓存写入失败，则回滚数据库操作；此种方法增加了程序的复杂度，不建议采用；</li><li>缓存使用时，假如读缓存失败，先读数据库，再回写缓存的方式实现。</li></ol><p>第三个场景：</p><ol><li>首先确定，哪些数据适合此类场景；</li><li>根据经验值确定合理的数据不一致时间，用户数据刷新的时间间隔；</li></ol><h3><span id="其他方法">其他方法</span></h3><ol><li>超时：设置合理的超时时间；</li><li>刷新：定时刷新一定范围内（根据时间，版本号）的数据；</li></ol><p>以上是简化数据读写场景，实际中会分为：</p><ol><li>缓存与数据库之间的一致性；</li><li>多级缓存之前的一致性；</li><li>缓存副本之前的一致性。</li></ol><h2><span id="缓存高可用">缓存高可用</span></h2><hr><p>业界有两种理论，第一套缓存就是缓存，临时存储数据的，不需要高可用。第二种缓存逐步演化为重要的存储介质，需要做高可用。</p><p>本人的看法是，缓存是否高可用，需要根据实际的场景而定。临界点是是否对后端的数据库造成影响。</p><p>具体的决策依据需要根据，集群的规模（数据，缓存），成本（服务器，运维），系统性能（并发量，吞吐量，响应时间）等方面综合评价。</p><h3><span id="解决方法">解决方法</span></h3><p>缓存的高可用，一般通过分布式和复制实现。分布式实现数据的海量缓存，复制实现缓存数据节点的高可用。架构图如下：</p><p><img src="/images/architecture-cache/017.jpg" alt="缓存在分布式系统中的应用-高可用"></p><p>其中，分布式采用一致性Hash算法，复制采用异步复制。</p><h3><span id="其他方法">其他方法</span></h3><ol><li>复制双写：缓存节点的复制，由异步改为双写，只有两份都写成功，才算成功。</li><li>虚拟层：一致性Hash存在，假如其中一个HASH环不可用，数据会写入临近的环，当HASH可用时，数据又写入正常的HASH环，会导致数据偏移问题。这种情况，可以考虑在HASH环前面加一个虚拟层实现。</li><li>多级缓存：比如一级使用本地缓存，二级采用分布式Cahce，三级采用分布式Cache+本地持久化；</li></ol><p>方式很多，需要根据业务场景灵活选择。</p><h2><span id="缓存雪崩">缓存雪崩</span></h2><hr><p>雪崩是指当大量缓存失效时，导致大量的请求访问数据库，导致数据库服务器，无法抗住请求或挂掉的情况。</p><p>解决方法：</p><ol><li>合理规划缓存的失效时间；</li><li>合理评估数据库的负载压力；</li><li>对数据库进行过载保护或应用层限流；</li><li>多级缓存设计，缓存高可用；</li></ol><h2><span id="缓存穿透">缓存穿透</span></h2><hr><p>缓存一般是Key，value方式存在，当某一个Key不存在时会查询数据库，假如这个Key，一直不存在，则会频繁的请求数据库，对数据库造成访问压力。</p><p>解决方法：</p><ol><li>对结果为空的数据也进行缓存，当此key有数据后，清理缓存；</li><li>一定不存在的key，采用布隆过滤器，建立一个大的Bitmap中，查询时通过该bitmap过滤；</li></ol><h2><span id="参考资料">参考资料</span></h2><hr><p>以下是本次分享参考的资料和推荐大家参考的资料。</p><p><a href="http://www.mamicode.com/info-detail-1120932.html" target="_blank" rel="noopener">MemCache超详细解读</a><br><a href="http://www.36dsj.com/archives/43950" target="_blank" rel="noopener">缓存与数据库一致性保证</a><br><a href="http://www.111cn.net/sys/linux/58748.htm" target="_blank" rel="noopener">HASH环和虚拟节点</a><br><a href="http://blog.csdn.net/cutesource/article/details/5848253" target="_blank" rel="noopener">让memcached分布式</a></p><h3><span id="cnd资料">CND资料</span></h3><p><a href="http://blog.sina.com.cn/s/blog_4adf62ab0100tjld.html" target="_blank" rel="noopener">淘宝CDN系统架构</a><br><a href="http://kb.cnblogs.com/page/199235/" target="_blank" rel="noopener">天猫浏览型应用的CDN静态化架构演变【经典】</a><br><a href="http://wenku.baidu.com/link?url=oAT72EEemiRnH2Iy2Bg4phHXsRmSlN_WHd4jH7kiDb4TqYMIyCR3v7oUhKMj9GqN7W1qwu1K4tQNyD6NKtuQ7o7aT3JIujcd_QjRf34BtKO" target="_blank" rel="noopener">ChinaCache CDN简介</a></p><h3><span id="反向代理资料">反向代理资料</span></h3><p><a href="http://my.oschina.net/u/267384/blog/173149" target="_blank" rel="noopener">squid反向代理</a></p><h3><span id="分布式缓存资料">分布式缓存资料</span></h3><p><a href="http://369369.blog.51cto.com/319630/833234/" target="_blank" rel="noopener">Memcache知识点梳理</a><br><a href="http://wenku.baidu.com/link?url=Qx4JYNgBJN0pqREImt1mZr625sj03AJoCWsIwDZlFQfi1iyejCb0feqG0gov3FLcrtEioJ3fU-4zj0H6VKPXWONYVZaAyX-HPWXDbRxyqF7" target="_blank" rel="noopener">memcache学习总结-wish</a><br><a href="http://1006836709.iteye.com/blog/1997381" target="_blank" rel="noopener">memcache 分布式，算法实现</a><br><a href="http://blog.csdn.net/a600423444/article/details/8944601" target="_blank" rel="noopener">分析Redis架构设计</a><br><a href="http://www.cnblogs.com/lulu/archive/2013/06/10/3130878.html" target="_blank" rel="noopener">Redis 集群方案</a><br><a href="http://blog.sina.com.cn/s/blog_7f37ddde0101021q.html" target="_blank" rel="noopener">Redis常用数据类型</a></p><p>转载: <a href="http://www.cnblogs.com/itfly8/p/5562610.html" target="_blank" rel="noopener">ITFLY8架构师之家</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;缓存是分布式系统中的重要组件，主要解决高并发，大数据场景下，热点数据访问的性能问题。提供高性能的数据快速访问。&lt;/p&gt;
&lt;p&gt;本文是介绍缓存的原理，缓存的分类，缓存的设计，CDN缓存（原理，架构参考和技术实践），反向代理缓存（原理，Squid架构实践和常用代理缓存之间的比较
      
    
    </summary>
    
      <category term="大型分布式网站架构" scheme="http://calfgz.github.io/categories/%E5%A4%A7%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="网站架构" scheme="http://calfgz.github.io/tags/%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式架构" scheme="http://calfgz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="Cache" scheme="http://calfgz.github.io/tags/Cache/"/>
    
      <category term="Memcached" scheme="http://calfgz.github.io/tags/Memcached/"/>
    
      <category term="Redis" scheme="http://calfgz.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>分布式消息队列[转]</title>
    <link href="http://calfgz.github.io//blog/2017/08/architecture-mq.html"/>
    <id>http://calfgz.github.io//blog/2017/08/architecture-mq.html</id>
    <published>2017-08-25T01:31:59.000Z</published>
    <updated>2019-04-28T07:38:07.342Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="消息队列概述">消息队列概述</span></h2><hr><p>消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。</p><p>目前在生产环境，使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。</p><h2><span id="消息队列应用场景">消息队列应用场景</span></h2><hr><p>以下介绍消息队列在实际应用中常用的使用场景。异步处理，应用解耦，流量削锋和消息通讯四个场景。</p><h3><span id="异步处理">异步处理</span></h3><p>场景说明：用户注册后，需要发注册邮件和注册短信。<br>传统的做法有两种</p><ul><li>串行的方式；</li><li>并行方式。</li></ul><ol><li>串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。（架构KKQ：466097527，欢迎加入）</li></ol><p><img src="/images/architecture-mq/001.png" alt="分布式消息队列-串行异步消息"></p><ol start="2"><li>并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。</li></ol><p><img src="/images/architecture-mq/002.png" alt="分布式消息队列-并行异步消息"></p><p>假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。</p><p>因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。</p><p>小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？</p><p>引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下：</p><p><img src="/images/architecture-mq/003.png" alt="分布式消息队列-异步消息改造"></p><p>按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。</p><h3><span id="应用解耦">应用解耦</span></h3><p>场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图：（架构KKQ：466097527，欢迎加入）</p><p><img src="/images/architecture-mq/004.png" alt="分布式消息队列-应用解耦"></p><p>传统模式的缺点：</p><ol><li>假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；</li><li>订单系统与库存系统耦合；</li></ol><p>如何解决以上问题呢？引入应用消息队列后的方案，如下图：</p><p><img src="/images/architecture-mq/005.png" alt="分布式消息队列-应用解耦"></p><ul><li>订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。</li><li>库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。</li><li>假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。</li></ul><h3><span id="流量削锋">流量削锋</span></h3><p>流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p><p>应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。</p><ol><li>可以控制活动的人数；</li><li>可以缓解短时间内高流量压垮应用；</li></ol><p><img src="/images/architecture-mq/006.png" alt="分布式消息队列-流量削锋"></p><ol><li>用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；</li><li>秒杀业务根据消息队列中的请求信息，再做后续处理。</li></ol><h3><span id="日志处理">日志处理</span></h3><p>日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下：（架构KKQ：466097527，欢迎加入）</p><p><img src="/images/architecture-mq/007.png" alt="分布式消息队列-日志处理"></p><ul><li>日志采集客户端，负责日志数据采集，定时写受写入Kafka队列；</li><li>Kafka消息队列，负责日志数据的接收，存储和转发；</li><li>日志处理应用：订阅并消费kafka队列中的日志数据；</li></ul><p>以下是新浪kafka日志处理应用案例：<br>转自（<a href="http://cloud.51cto.com/art/201507/484338.htm）" target="_blank" rel="noopener">http://cloud.51cto.com/art/201507/484338.htm）</a></p><p><img src="/images/architecture-mq/008.png" alt="分布式消息队列-Kafka日志处理"></p><ol><li>Kafka：接收用户日志的消息队列。</li><li>Logstash：做日志解析，统一成JSON输出给Elasticsearch。</li><li>Elasticsearch：实时日志分析服务的核心技术，一个schemaless，实时的数据存储服务，通过index组织数据，兼具强大的搜索和统计功能。</li><li>Kibana：基于Elasticsearch的数据可视化组件，超强的数据可视化能力是众多公司选择ELK stack的重要原因。</li></ol><p>EEE 消息通讯</p><p>消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。</p><p>点对点通讯：<br><img src="/images/architecture-mq/009.png" alt="分布式消息队列-消息通讯"></p><p>客户端A和客户端B使用同一队列，进行消息通讯。</p><p>聊天室通讯：<br><img src="/images/architecture-mq/010.png" alt="分布式消息队列-聊天室通讯"></p><p>客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。</p><p>以上实际是消息队列的两种消息模式，点对点或发布订阅模式。模型为示意图，供参考。</p><h2><span id="消息中间件示例">消息中间件示例</span></h2><hr><h3><span id="电商系统">电商系统</span></h3><p><img src="/images/architecture-mq/011.jpg" alt="分布式消息队列-电商系统"></p><p>消息队列采用高可用，可持久化的消息中间件。比如ActiveMQ，RabbitMQ，RocketMq。</p><ol><li>应用将主干逻辑处理完成后，写入消息队列。消息发送是否成功可以开启消息的确认模式。（消息队列返回消息接收成功状态后，应用再返回，这样保障消息的完整性）</li><li>扩展流程（发短信，配送处理）订阅队列消息。采用推或拉的方式获取消息并处理。</li><li>消息将应用解耦的同时，带来了数据一致性问题，可以采用最终一致性方式解决。比如主数据写入数据库，扩展应用根据消息队列，并结合数据库方式实现基于消息队列的后续处理。</li></ol><h3><span id="日志收集系统">日志收集系统</span></h3><p><img src="/images/architecture-mq/012.jpg" alt="分布式消息队列-日志收集系统"></p><p>分为Zookeeper注册中心，日志收集客户端，Kafka集群和Storm集群（OtherApp）四部分组成。</p><ul><li>Zookeeper注册中心，提出负载均衡和地址查找服务；</li><li>日志收集客户端，用于采集应用系统的日志，并将数据推送到kafka队列；</li><li>Kafka集群：接收，路由，存储，转发等消息处理；</li><li>Storm集群：与OtherApp处于同一级别，采用拉的方式消费队列中的数据；</li></ul><h2><span id="jms消息服务">JMS消息服务</span></h2><hr><p>讲消息队列就不得不提JMS 。JMS（JAVA Message Service,java消息服务）API是一个消息服务的标准/规范，允许应用程序组件基于JavaEE平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。</p><p>在EJB架构中，有消息bean可以无缝的与JM消息服务集成。在J2EE架构模式中，有消息服务者模式，用于实现消息与应用直接的解耦。</p><h3><span id="消息模型">消息模型</span></h3><p>在JMS标准中，有两种消息模型P2P（Point to Point）,Publish/Subscribe(Pub/Sub)。</p><h4><span id="p2p模式">P2P模式</span></h4><p><img src="/images/architecture-mq/013.png" alt="分布式消息队列-P2P模式"></p><p>P2P模式包含三个角色：消息队列（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。</p><p>P2P的特点</p><ul><li>每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)</li><li>发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列</li><li>接收者在成功接收消息之后需向队列应答成功</li></ul><p>如果希望发送的每个消息都会被成功处理的话，那么需要P2P模式。（架构KKQ：466097527，欢迎加入）</p><h4><span id="pubsub模式">Pub/sub模式</span></h4><p><img src="/images/architecture-mq/014.png" alt="分布式消息队列-Pub/Sub模式"></p><p>包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 。多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。</p><p>Pub/Sub的特点</p><ul><li>每个消息可以有多个消费者</li><li>发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。</li><li>为了消费消息，订阅者必须保持运行的状态。</li></ul><p>为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。</p><p>如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型。</p><h3><span id="消息消费">消息消费</span></h3><p>在JMS中，消息的产生和消费都是异步的。对于消费来说，JMS的消息者可以通过两种方式来消费消息。</p><ol><li><p>同步<br> 订阅者或接收者通过receive方法来接收消息，receive方法在接收到消息之前（或超时之前）将一直阻塞；</p></li><li><p>异步<br> 订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的onMessage方法。</p></li></ol><p>JNDI：Java命名和目录接口,是一种标准的Java命名系统接口。可以在网络上查找和访问服务。通过指定一个资源名称，该名称对应于数据库或命名服务中的一个记录，同时返回资源连接建立所必须的信息。</p><p>JNDI在JMS中起到查找和访问发送目标或消息来源的作用。（架构KKQ：466097527，欢迎加入）</p><h3><span id="jms编程模型">JMS编程模型</span></h3><h4><span id="connectionfactory">ConnectionFactory</span></h4><p>创建Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。</p><h4><span id="destination">Destination</span></h4><p>Destination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的Destination是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的Destination也是某个队列或主题（即消息来源）。<br>所以，Destination实际上就是两种类型的对象：Queue、Topic可以通过JNDI来查找Destination。</p><h4><span id="connection">Connection</span></h4><p>Connection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。</p><h4><span id="session">Session</span></h4><p>Session是操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。</p><h4><span id="消息的生产者">消息的生产者</span></h4><p>消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。</p><h4><span id="消息消费者">消息消费者</span></h4><p>消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。</p><h4><span id="messagelistener">MessageListener</span></h4><p>消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。</p><p>深入学习JMS对掌握JAVA架构，EJB架构有很好的帮助，消息中间件也是大型分布式系统必须的组件。本次分享主要做全局性介绍，具体的深入需要大家学习，实践，总结，领会。</p><h2><span id="常用消息队列">常用消息队列</span></h2><hr><p>一般商用的容器，比如WebLogic，JBoss，都支持JMS标准，开发上很方便。但免费的比如Tomcat，Jetty等则需要使用第三方的消息中间件。本部分内容介绍常用的消息中间件（Active MQ,Rabbit MQ，Zero MQ,Kafka）以及他们的特点。</p><h3><span id="activemq">ActiveMQ</span></h3><p>ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。</p><p>ActiveMQ特性如下：</p><ol><li>多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP</li><li>完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)</li><li>对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性</li><li>通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上</li><li>支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA</li><li>支持通过JDBC和journal提供高速的消息持久化</li><li>从设计上保证了高性能的集群，客户端-服务器，点对点</li><li>支持Ajax</li><li>支持与Axis的整合</li><li>可以很容易得调用内嵌JMS provider，进行测试</li></ol><h3><span id="rabbitmq">RabbitMQ</span></h3><p>RabbitMQ是流行的开源消息队列系统，用erlang语言开发。RabbitMQ是AMQP（高级消息队列协议）的标准实现。支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX，持久化。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。</p><p>结构图如下：<br><img src="/images/architecture-mq/015.png" alt="分布式消息队列-RabbitMQ"></p><p>几个重要概念：</p><ul><li>Broker：简单来说就是消息队列服务器实体。</li><li>Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。</li><li>Queue：消息队列载体，每个消息都会被投入到一个或多个队列。</li><li>Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来。</li><li>Routing Key：路由关键字，exchange根据这个关键字进行消息投递。</li><li>Vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。</li><li>Producer：消息生产者，就是投递消息的程序。</li><li>Consumer：消息消费者，就是接受消息的程序。</li><li>Channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。</li></ul><p>消息队列的使用过程，如下：</p><ol><li>客户端连接到消息队列服务器，打开一个channel。</li><li>客户端声明一个exchange，并设置相关属性。</li><li>客户端声明一个queue，并设置相关属性。</li><li>客户端使用routing key，在exchange和queue之间建立好绑定关系。</li><li>客户端投递消息到exchange。</li></ol><p>exchange接收到消息后，就根据消息的key和已经设置的binding，进行消息路由，将消息投递到一个或多个队列里。</p><h3><span id="zeromq">ZeroMQ</span></h3><p>号称史上最快的消息队列，它实际类似于Socket的一系列接口，他跟Socket的区别是：普通的socket是端到端的（1:1的关系），而ZMQ却是可以N：M 的关系，人们对BSD套接字的了解较多的是点对点的连接，点对点连接需要显式地建立连接、销毁连接、选择协议（TCP/UDP）和处理错误等，而ZMQ屏蔽了这些细节，让你的网络编程更为简单。ZMQ用于node与node间的通信，node可以是主机或者是进程。</p><p>引用官方的说法： “ZMQ(以下ZeroMQ简称ZMQ)是一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。现在还未看到它们的成功。但是，它无疑是极具前景的、并且是人们更加需要的“传统”BSD套接字之上的一 层封装。ZMQ让编写高性能网络应用程序极为简单和有趣。”</p><p>特点是：</p><ul><li>高性能，非持久化；</li><li>跨平台：支持Linux、Windows、OS X等。</li><li>多语言支持； C、C++、Java、.NET、Python等30多种开发语言。</li><li>可单独部署或集成到应用中使用；</li><li>可作为Socket通信库使用。</li></ul><p>与RabbitMQ相比，ZMQ并不像是一个传统意义上的消息队列服务器，事实上，它也根本不是一个服务器，更像一个底层的网络通讯库，在Socket API之上做了一层封装，将网络通讯、进程通讯和线程通讯抽象为统一的API接口。支持“Request-Reply “，”Publisher-Subscriber“，”Parallel Pipeline”三种基本模型和扩展模型。</p><p>ZeroMQ高性能设计要点：</p><ol><li><p>无锁的队列模型<br> 对于跨线程间的交互（用户端和session）之间的数据交换通道pipe，采用无锁的队列算法CAS；在pipe两端注册有异步事件，在读或者写消息到pipe的时，会自动触发读写事件。</p></li><li><p>批量处理的算法<br>对于传统的消息处理，每个消息在发送和接收的时候，都需要系统的调用，这样对于大量的消息，系统的开销比较大，zeroMQ对于批量的消息，进行了适应性的优化，可以批量的接收和发送消息。</p></li><li><p>多核下的线程绑定，无须CPU切换<br>区别于传统的多线程并发模式，信号量或者临界区， zeroMQ充分利用多核的优势，每个核绑定运行一个工作者线程，避免多线程之间的CPU切换开销。</p></li></ol><h3><span id="kafka">Kafka</span></h3><p>Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群机来提供实时的消费。</p><p>Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：</p><ul><li>通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。（文件追加的方式写入数据，过期的数据定期删除）</li><li>高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。</li><li>支持通过Kafka服务器和消费机集群来分区消息。</li><li>支持Hadoop并行数据加载。</li></ul><p>Kafka相关概念</p><ul><li>Broker<br>  Kafka集群包含一个或多个服务器，这种服务器被称为broker[5]</li><li>Topic<br>  每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</li><li>Partition<br>  Parition是物理上的概念，每个Topic包含一个或多个Partition.</li><li>Producer<br>  负责发布消息到Kafka broker</li><li>Consumer<br>  消息消费者，向Kafka broker读取消息的客户端。</li><li>Consumer Group<br>  每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li></ul><p>一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用。</p><hr><p>参考资料（可参考资料）：</p><p><a href="http://blog.sina.com.cn/s/blog_3fba24680100r777.html" target="_blank" rel="noopener">Jms</a><br><a href="http://blog.csdn.net/jiuqiyuliang/article/details/46701559" target="_blank" rel="noopener">深入浅出JMS(一)–JMS基本概念</a><br><a href="http://baike.baidu.com/link?url=s2cU-QgOsXan7j0AM5qxxlmruz6WEeBQXX-Bbk0O3F5jt9Qts2uYQARxQxl7CBT2SO2NF2VkzX_XZLqU-CTaPa" target="_blank" rel="noopener">RabbitMQ</a><br><a href="http://blog.csdn.net/sun305355024sun/article/details/41913105" target="_blank" rel="noopener">RabbitMQ</a><br><a href="http://www.searchtb.com/2012/08/zeromq-primer.html" target="_blank" rel="noopener">ZeroMQ</a><br><a href="http://blog.csdn.net/yangbutao/article/details/8498790" target="_blank" rel="noopener">ZeroMQ</a><br><a href="http://wenku.baidu.com/link?url=yYoiZ_pYPCuUxEsGQvMMleY08bcptZvwF3IMHo2W1i-ti66YXXPpLLJBGXboddwgGBnOehHiUdslFhtz7RGZYkrtMQQ02DV5sv9JFF4LZnK" target="_blank" rel="noopener">ZeroMQ</a><br><a href="http://baike.baidu.com/link?url=qQXyqvPQ1MVrw9WkOGSGEfSX1NHy4unsgc4ezzJwU94SrPuVnrKf2tbm4SllVaN3ArGGxV_N5hw8JTT2-lw4QK" target="_blank" rel="noopener">Kafka</a><br><a href="http://www.infoq.com/cn/articles/apache-kafka/" target="_blank" rel="noopener">Kafka</a><br><a href="http://www.mincoder.com/article/3942.shtml" target="_blank" rel="noopener">Kafka</a></p><p>转载: <a href="http://www.cnblogs.com/itfly8/p/5155983.html" target="_blank" rel="noopener">ITFLY8架构师之家</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;&lt;span id=&quot;消息队列概述&quot;&gt;消息队列概述&lt;/span&gt;&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。实现高性能，高可用，可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。&lt;/p&gt;
&lt;p&gt;目前在
      
    
    </summary>
    
      <category term="大型分布式网站架构" scheme="http://calfgz.github.io/categories/%E5%A4%A7%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="RabbitMQ" scheme="http://calfgz.github.io/tags/RabbitMQ/"/>
    
      <category term="网站架构" scheme="http://calfgz.github.io/tags/%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式架构" scheme="http://calfgz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"/>
    
      <category term="MQ" scheme="http://calfgz.github.io/tags/MQ/"/>
    
      <category term="Kafka" scheme="http://calfgz.github.io/tags/Kafka/"/>
    
  </entry>
  
</feed>
